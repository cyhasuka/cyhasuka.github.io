<!doctype html><html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta><title>Nvidia GPU &amp; 算能Sophon TPU 算子耗时分析 - CuiYuhao&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="CuiYuhao&#039;s Blog"><meta name="msapplication-TileImage" content="/img/webicon.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="CuiYuhao&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="1、Nvidia GPU该分析方法适合onnx模型或trt模型，NV的工具栏较为易用，可使用 trtexec 命令直接输出算子耗时。注意，有些易于优化计算的算子（例如 Conv+Relu 、Conv+BN+Relu），会作为一个算子集计算，此时无法直接读取到每个独立算子的耗时。 首先需要安装Nvidia TensorRT库、CUDA ToolKit（没这俩咋玩呀），然后使用trtexec命令行工具"><meta property="og:type" content="blog"><meta property="og:title" content="Nvidia GPU &amp; 算能Sophon TPU 算子耗时分析"><meta property="og:url" content="https://cyhasuka.github.io/posts/186ec257/"><meta property="og:site_name" content="CuiYuhao&#039;s Blog"><meta property="og:description" content="1、Nvidia GPU该分析方法适合onnx模型或trt模型，NV的工具栏较为易用，可使用 trtexec 命令直接输出算子耗时。注意，有些易于优化计算的算子（例如 Conv+Relu 、Conv+BN+Relu），会作为一个算子集计算，此时无法直接读取到每个独立算子的耗时。 首先需要安装Nvidia TensorRT库、CUDA ToolKit（没这俩咋玩呀），然后使用trtexec命令行工具"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cyhasuka.github.io/img/og_image.png"><meta property="article:published_time" content="2024-04-12T02:30:05.000Z"><meta property="article:modified_time" content="2024-05-24T07:06:40.799Z"><meta property="article:author" content="cyhasuka"><meta property="article:tag" content="Linux"><meta property="article:tag" content="自动驾驶"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="NVIDIA"><meta property="article:tag" content="Sophon算能"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://cyhasuka.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://cyhasuka.github.io/posts/186ec257/"},"headline":"Nvidia GPU & 算能Sophon TPU 算子耗时分析","image":["https://cyhasuka.github.io/img/og_image.png"],"datePublished":"2024-04-12T02:30:05.000Z","dateModified":"2024-05-24T07:06:40.799Z","author":{"@type":"Person","name":"cyhasuka"},"publisher":{"@type":"Organization","name":"CuiYuhao's Blog","logo":{"@type":"ImageObject","url":"https://cyhasuka.github.io/img/toplogo.jpg"}},"description":"1、Nvidia GPU该分析方法适合onnx模型或trt模型，NV的工具栏较为易用，可使用 trtexec 命令直接输出算子耗时。注意，有些易于优化计算的算子（例如 Conv+Relu 、Conv+BN+Relu），会作为一个算子集计算，此时无法直接读取到每个独立算子的耗时。 首先需要安装Nvidia TensorRT库、CUDA ToolKit（没这俩咋玩呀），然后使用trtexec命令行工具"}</script><link rel="canonical" href="https://cyhasuka.github.io/posts/186ec257/"><link rel="icon" href="/img/webicon.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><script>!function(){function e(){if(!location.hash)return;const e="#"+CSS.escape(location.hash.substring(1)),t=document.querySelector(`.tabs a[href="${e}"]`);if(!t)return;const n=t.parentElement.parentElement;Array.from(n.children).forEach(e=>e.classList.remove("is-active")),Array.from(n.querySelectorAll("a")).map(e=>document.getElementById(e.getAttribute("href").substring(1))).forEach(e=>e.classList.add("is-hidden")),t&&t.parentElement.classList.add("is-active");const r=document.querySelector(e);r&&r.classList.remove("is-hidden")}e(),window.addEventListener("hashchange",e,!1)}()</script><meta name="generator" content="Hexo 7.0.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0OCIgaGVpZ2h0PSI0OCIgdmlld0JveD0iMCAwIDI0IDI0Ij48Y2lyY2xlIGN4PSI0IiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgaWQ9InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAiIGF0dHJpYnV0ZU5hbWU9InIiIGJlZ2luPSIwO3N2Z1NwaW5uZXJzM0RvdHNTY2FsZTEuZW5kLTAuMjVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNnMiIGR1cj0iMC43NXMiIHZhbHVlcz0iMzsuMjszIi8+PC9jaXJjbGU+PGNpcmNsZSBjeD0iMjAiIGN5PSIxMiIgcj0iMyIgZmlsbD0iY3VycmVudENvbG9yIj48YW5pbWF0ZSBpZD0ic3ZnU3Bpbm5lcnMzRG90c1NjYWxlMSIgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNDVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjwvc3ZnPg==" data-original="/img/toplogo.jpg" alt="CuiYuhao&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/index">首页</a><a class="navbar-item" href="/archives">文章</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/posts/c0297c2d">留言板</a><a class="navbar-item" href="/about">个人简介</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="我的GitHub" href="https://github.com/cyhasuka"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2024-04-12T02:30:05.000Z" title="4/12/2024, 10:30:05 AM">2024-04-12</time>发表</span><span class="level-item"><time datetime="2024-05-24T07:06:40.799Z" title="5/24/2024, 3:06:40 PM">2024-05-24</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%86%99%E7%82%B9%E6%95%99%E7%A8%8B/">写点教程</a></span><span class="level-item">完整阅读约22 分钟 (3337个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">Nvidia GPU &amp; 算能Sophon TPU 算子耗时分析</h1><div class="content"><h2 id="1、Nvidia-GPU"><a href="#1、Nvidia-GPU" class="headerlink" title="1、Nvidia GPU"></a>1、Nvidia GPU</h2><p>该分析方法适合onnx模型或trt模型，NV的工具栏较为易用，可使用 trtexec 命令直接输出算子耗时。注意，有些易于优化计算的算子（例如 Conv+Relu 、Conv+BN+Relu），会作为一个算子集计算，此时无法直接读取到每个独立算子的耗时。</p><p>首先需要安装Nvidia TensorRT库、CUDA ToolKit（没这俩咋玩呀），然后使用trtexec命令行工具进行推理。</p><p>示例命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trtexec --onnx=pfe+backbone_v12.onnx --loadInputs=input.1 --fp16 --exportProfile=bmap_dbg.json --verbose</span><br></pre></td></tr></table></figure><p>其中，<code>--onnx</code>参数指定onnx文件路径，<code>--loadInputs</code>参数指定输入层name，<code>--fp16</code>选项指定启用FP16推理。后面的两个参数为用于分析推理过程，<code>--exportProfile</code>参数用于将每个算子层的耗时及占比信息存入.json文件， <code>--verbose</code>参数用于输出详细日志目录。</p><span id="more"></span><p>以下是全部参数详细说明，版本不符可以使用<code>--help</code>参数，大致内容相似：</p><details><summary><b>单击展开</b></summary><br><b>1.1 Model Option 模型选项</b><br>–uff : UFF模型文件名<br>–onnx : ONNX模型文件名<br>–model : Caffe模型文件名，模式时无模型，使用随机权重<br>–deploy : Caffe prototxt 文件名<br>–output : 输出名称（可多次指定）；UFF和Caffe至少需要一个输出<br>–uffInput : 输入blob名称及其维度（X、Y、Z=C、H、W），可以多次指定；UFF型号至少需要一个<br>–uffNHWC : 设置输入是否在NHWC布局中而不是NCHW中（在–uffInput中使用X、Y、Z=H、W、C顺序）<br><br><b>1.2 Build Options 构建选项</b><br>–maxBatch ： 设置最大批处理大小并构建隐式批处理引擎（默认值=1）<br>–explicitBatch ：构建引擎时使用显式批量大小（默认 = 隐式）<br>–minShapes=spec ： 使用提供的最小 shape 的配置文件构建动态 shape<br>–optShapes=spec ： 使用提供的 opt shape 的配置文件构建动态 shape<br>–maxShapes=spec ： 使用提供的最大 shape 的配置文件构建动态 shape<br>–minShapesCalib=spec ： 使用提供的最小 shape 的配置文件校准动态 shape<br>–optShapesCalib=spec ： 使用提供的 opt shape 的配置文件校准动态 shape<br>–maxShapesCalib=spec ：使用提供的最大 shape 的配置文件校准动态 shape<br>注意：必须提供所有三个 min、opt 和 max shape 。但是，如果只提供了 opt shape ，那么它将被扩展，以便将最小 shape 和最大 shape 设置为与 opt shape 相同的值。此外，使用 动态 shape 意味着显式批处理。 输入名称可以用转义单引号括起来（例如：‘Input:0’）。示例输入 shape 规范：input0:1x3x256x256,input1:1x3x128x128 每个输入 shape 都作为键值对提供，其中 key 是输入名称 值是用于该输入的维度（包括批次维度）。 每个键值对都使用冒号 (😃 分隔键和值。 可以通过逗号分隔的键值对提供多个输入 shape 。<br>–inputIOFormats=spec ： 每个输入张量的类型和格式（默认所有输入为fp32:chw）<br>注意：如果指定此选项，请按照与网络输入ID相同的顺序为所有输入设置逗号分隔的类型和格式（即使只有一个输入需要指定IO格式）或设置一次类型和格式以进行广播。<br>–outputIOFormats=spec : 每个输出张量的类型和格式（默认所有输入为fp32:chw）<br>注意：如果指定此选项，请按照与网络输出ID相同的顺序为所有输出设置逗号分隔的类型和格式（即使只有一个输出需要指定IO格式）或设置一次类型和格式以进行广播。<br>–workspace=N ： 以M为单位设置工作区大小（默认值 = 16）<br>–noBuilderCache : 在构建器中禁用时序缓存（默认是启用时序缓存）<br>–nvtxMode=mode : 指定 NVTX 注释详细程度。 mode ::= default|verbose|none<br>–minTiming=M : 设置内核选择中使用的最小迭代次数（默认值 = 1）<br>–avgTiming=M : 为内核选择设置每次迭代的平均次数（默认值 = 8）<br>–noTF32 : 禁用 tf32 精度（默认是启用 tf32，除了 fp32）<br>–refit : 将引擎标记为可改装。这将允许检查引擎内的可改装层和重量。<br>–fp16 ： 除 fp32 外，启用 fp16 精度（默认 = 禁用）<br>–int8 : 除 fp32 外，启用 int8 精度（默认 = 禁用）<br>–best : 启用所有精度以达到最佳性能（默认 = 禁用）<br>–calib= : 读取INT8校准缓存文件<br>–safe : 仅测试安全受限流中可用的功能<br>–saveEngine= : 保存序列化模型的文件名<br>–loadEngine= ： 加载序列化模型的文件名<br>–tacticSources=tactics ： 通过从默认策略源（默认 = 所有可用策略）中添加 (+) 或删除 (-) 策略来指定要使用的策略。<br><br><b>1.3 Inference Options 推理选项</b><br>–batch=N ： 为隐式批处理引擎设置批处理大小（默认值 = 1）<br>–shapes=spec ： 为动态 shape 推理输入设置输入 shape 。<br>注意：使用动态 shape 意味着显式批处理。 输入名称可以用转义的单引号括起来（例如：‘Input:0’）。 示例输入 shape 规范：input0:1x3x256x256, input1:1x3x128x128 每个输入 shape 都作为键值对提供，其中键是输入名称，值是用于该输入的维度（包括批次维度）。 每个键值对都使用冒号 (😃 分隔键和值。 可以通过逗号分隔的键值对提供多个输入 shape 。<br>–loadInputs=spec ：从文件加载输入值（默认 = 生成随机输入）。 输入名称可以用单引号括起来（例如：‘Input:0’）<br>–iterations=N ： 至少运行 N 次推理迭代（默认值 = 10）<br>–warmUp=N ： 在测量性能之前运行 N 毫秒以预热（默认值 = 200）<br>–duration=N ： 运行至少 N 秒挂钟时间的性能测量（默认值 = 3）<br>–sleepTime=N ： 延迟推理以启动和计算之间的 N 毫秒间隔开始（默认 = 0）<br>–streams=N ： 实例化 N 个引擎以同时使用（默认值 = 1）<br>–exposeDMA ： 串行化进出设备的 DMA 传输。 （默认 = 禁用）<br>–noDataTransfers ： 在推理过程中，请勿将数据传入和传出设备。 （默认 = 禁用）<br>–useSpinWait ： 主动同步 GPU 事件。 此选项可能会减少同步时间，但会增加 CPU 使用率和功率（默认 = 禁用）<br>–threads ： 启用多线程以驱动具有独立线程的引擎（默认 = 禁用）<br>–useCudaGraph ： 使用 cuda 图捕获引擎执行，然后启动推理（默认 = 禁用）<br>–separateProfileRun ： 不要在基准测试中附加分析器； 如果启用分析，将执行第二次分析运行（默认 = 禁用）<br>–buildOnly ： 跳过推理性能测量（默认 = 禁用）<br><br><b>1.4 Build and Inference Batch Options 构建和推理批处理选项</b><br>使用隐式批处理时，引擎的最大批处理大小（如果未指定）设置为推理批处理大小； 使用显式批处理时，如果仅指定 shape 用于推理，它们也将在构建配置文件中用作 min/opt/max； 如果只为构建指定了 shape ，则 opt shape 也将用于推理； 如果两者都被指定，它们必须是兼容的； 如果启用了显式批处理但都未指定，则模型必须为所有输入提供完整的静态维度，包括批处理大小<br><br><b>1.5 Reporting Options 报告选项</b><br>–verbose ： 使用详细日志记录（默认值 = false）<br>–avgRuns=N ： 报告 N 次连续迭代的平均性能测量值（默认值 = 10）<br>–percentile=P ： 报告 P 百分比的性能 P=(0~100)，0 代表最大性能，100 代表最小性能；（默认 = 99%））<br>–dumpRefit ： 从可改装引擎打印可改装层和重量<br>–dumpOutput ： 打印最后一次推理迭代的输出张量（默认 = 禁用）<br>–dumpProfile ： 每层打印配置文件信息（默认 = 禁用）<br>–exportTimes= ： 将计时结果写入 json 文件（默认 = 禁用）<br>–exportOutput= ： 将输出张量写入 json 文件（默认 = 禁用）<br>–exportProfile= ： 将每层的配置文件信息写入 json 文件（默认 = 禁用）<br><br><b>1.6 System Options 系统选项</b><br>–device=N ：选择 cuda 设备 N（默认 = 0）<br>–useDLACore=N ： 为支持 DLA 的层选择 DLA 核心 N（默认 = 无）<br>–allowGPUFallback ： 启用 DLA 后，允许 GPU 回退不受支持的层（默认 = 禁用）<br>–plugins ： 要加载的插件库 (.so)（可以多次指定）<br><br><b>1.7 Help 帮助</b><br>–help, -h ： 打印以上帮助信息<br><br></details><p>执行完成后，会在当前目录生成一个json文件，内容包含：算子层名称、共计执行时间（运行时间与重复运行次数相关，非单次执行时间）、平均单次执行时间、占用率。</p><p>输出示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span> <span class="attr">&quot;count&quot;</span> <span class="punctuation">:</span> <span class="number">252</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">,</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;Reformatting CopyNode for Input Tensor 0 to Pad_0 + Conv_1 + Relu_2&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;timeMs&quot;</span> <span class="punctuation">:</span> <span class="number">75.319</span><span class="punctuation">,</span> <span class="attr">&quot;averageMs&quot;</span> <span class="punctuation">:</span> <span class="number">0.298885</span><span class="punctuation">,</span> <span class="attr">&quot;percentage&quot;</span> <span class="punctuation">:</span> <span class="number">6.04541</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">,</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;Pad_0 + Conv_1 + Relu_2&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;timeMs&quot;</span> <span class="punctuation">:</span> <span class="number">52.394</span><span class="punctuation">,</span> <span class="attr">&quot;averageMs&quot;</span> <span class="punctuation">:</span> <span class="number">0.207913</span><span class="punctuation">,</span> <span class="attr">&quot;percentage&quot;</span> <span class="punctuation">:</span> <span class="number">4.20535</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">,</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;Conv_3 + Relu_4&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;timeMs&quot;</span> <span class="punctuation">:</span> <span class="number">44.4168</span><span class="punctuation">,</span> <span class="attr">&quot;averageMs&quot;</span> <span class="punctuation">:</span> <span class="number">0.176257</span><span class="punctuation">,</span> <span class="attr">&quot;percentage&quot;</span> <span class="punctuation">:</span> <span class="number">3.56507</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">,</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;Conv_5 + Relu_6&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;timeMs&quot;</span> <span class="punctuation">:</span> <span class="number">43.1007</span><span class="punctuation">,</span> <span class="attr">&quot;averageMs&quot;</span> <span class="punctuation">:</span> <span class="number">0.171035</span><span class="punctuation">,</span> <span class="attr">&quot;percentage&quot;</span> <span class="punctuation">:</span> <span class="number">3.45944</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">,</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;Conv_7 + Relu_8&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;timeMs&quot;</span> <span class="punctuation">:</span> <span class="number">42.7234</span><span class="punctuation">,</span> <span class="attr">&quot;averageMs&quot;</span> <span class="punctuation">:</span> <span class="number">0.169537</span><span class="punctuation">,</span> <span class="attr">&quot;percentage&quot;</span> <span class="punctuation">:</span> <span class="number">3.42915</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">,</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;Conv_9 + Relu_10&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;timeMs&quot;</span> <span class="punctuation">:</span> <span class="number">16.1732</span><span class="punctuation">,</span> <span class="attr">&quot;averageMs&quot;</span> <span class="punctuation">:</span> <span class="number">0.0641793</span><span class="punctuation">,</span> <span class="attr">&quot;percentage&quot;</span> <span class="punctuation">:</span> <span class="number">1.29812</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><p>上面仅是简单分析算子簇耗时，其实NV还提供了很多分析工具，例如NVIDIA Nsight™ Systems，它可以通过多种方式配置，以仅报告程序执行的一部分的时序信息，或者也可以将传统的 CPU 采样配置文件信息与 GPU 信息一起报告。</p><h2 id="2、Sophon-TPU"><a href="#2、Sophon-TPU" class="headerlink" title="2、Sophon TPU"></a>2、Sophon TPU</h2><p>算能TPU提供了TPU Profile工具，帮助完成算子分析。TPU内部主要由MCU、GDMA、TIU三个engine来完成工作。</p><p>MCU在BM1684X上是一个单核的A53处理器，通过firmware固件程序完成向GDMA、TIU两个engine下发命令、驱动通信、简单计算等具体功能，实现了算子的具体逻辑。</p><p>GDMA和TIU是实际的执行引擎，GDMA用于Global mem与Local mem之间传输数据，实现了1D、矩阵、4D等数据搬运功能；TIU对local mem中的数据执行密集计算命令，包括卷积、矩阵乘法、算术等原子操作。</p><h3 id="2-1、分析流程"><a href="#2-1、分析流程" class="headerlink" title="2.1、分析流程"></a>2.1、分析流程</h3><p>简述分析流程，若程序在X86架构服务器完成编译，在边缘计算盒推理，分析主要分为六步。若编译推理在同域内进行，可省去数据拷贝流程，分为四步。</p><blockquote><p>[服务器] 程序生成mlir -&gt; [服务器] mlir转bmodel -&gt; [服务器] bmodel拷贝至SE7-&gt;[SE7] 运行生成data文件-&gt;[SE7] 结果拷回服务器 -&gt; [服务器] data转换为HTML profile可视化</p></blockquote><ul><li><p><strong>[服务器] 程序生成mlir</strong></p><ul><li><p>首先进入docker环境，source运行环境</p></li><li><p>```</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /workspace/tpu-mlir_v1.3.140-g3180ff37-20231116/envsetup.sh</span><br></pre></td></tr></table></figure></li><li><p>生成mlir文件，需要更改onnx模型对应shape及输出节点名</p></li><li>```<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_transform.py --model_name pp_bmap --model_def ./pfe+backbone_v12.onnx --input_shapes [[1,40,512,512]] --keep_aspect_ratio --output_names &#x27;273&#x27;,&#x27;320&#x27;,&#x27;367&#x27;,&#x27;414&#x27;,&#x27;461&#x27;,&#x27;508&#x27;,&#x27;542&#x27; --mlir bmap_dbg_1.mlir</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>[服务器] mlir转bmodel</strong></p><ul><li><p>在上一步基础上，运行model_deploy</p></li><li><p>注意，默认情况下，会将算子融合成算子簇来计算，优化推理效率。如果需要对单独算子进行评估，命令需要加<code>--disable_layer_group</code>参数来禁用算子融合操作。</p></li><li><p>```</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_deploy.py --mlir bmap_dbg_1.mlir --quantize F16 --chip bm1684x --test_input ../concat_in_f32.npz --test_reference ../concat_top_outputs.npz --debug --compare_all --model bmap_dbg_2_F16F32.bmodel --quantize_table qtable_con --disable_layer_group</span><br></pre></td></tr></table></figure></li><li><p>将生成的bmodel拷贝至SE7等边缘计算设备 (可选)</p></li></ul></li><li><p><strong>[SE7] 运行生成data文件</strong></p><ul><li><p>```</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 通过环境变量(BMRUNTIME_ENABLE_PROFILE)使能profile, 生成二进制数据</span><br><span class="line">BMRUNTIME_ENABLE_PROFILE=1 bmrt_test --bmodel bmap_dbg_2_F16F32.bmodel</span><br></pre></td></tr></table></figure></li><li><p>使能profile运行会生成一个<code>bmprofile_data-1</code>的文件夹，内部包含运行数据</p></li><li><p>将该文件夹拷贝至服务器（可选）</p></li></ul></li><li><p><strong>[服务器] data转换为HTML profile可视化</strong></p><ul><li><p>```</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tpu_profile.py --arch BM1684X bmprofile_data-1 out_dir</span><br></pre></td></tr></table></figure></li><li><p>运行会生成<code>out_dir</code>文件夹，内部包含json数据和html文件，浏览器打开即可查看数据。</p><ul><li><p>tips：docker与主机拷贝命令</p></li><li><p>```</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker cp se7:/workspace/concat/layer/bmprofile_out_1 /home/username/</span><br></pre></td></tr></table></figure></li><li><p>退出docker：ctrl+D</p></li></ul></li></ul></li></ul><p>生成时序图数据后，可按需查看并分析。详细说明请见tpu-mlir官方说明 :</p><p><a target="_blank" rel="noopener" href="https://tpumlir.org/zh-cn/2023/09/18/analyse-tpu-performance-with-tpu-profile.html">TPU Profile工具使用及分析 | TPUMLIR 开源工具链项目 | 通用 AI 编译器工具链项目，高效将模型编译生成 TPU 执行代码</a></p></div><div class="article-licensing box"><div class="licensing-title"><p>Nvidia GPU &amp; 算能Sophon TPU 算子耗时分析</p><p><a href="https://cyhasuka.github.io/posts/186ec257/">https://cyhasuka.github.io/posts/186ec257/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>cyhasuka</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-04-12</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-05-24</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Linux/">Linux</a><a class="link-muted mr-2" rel="tag" href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/">自动驾驶</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="link-muted mr-2" rel="tag" href="/tags/NVIDIA/">NVIDIA</a><a class="link-muted mr-2" rel="tag" href="/tags/Sophon%E7%AE%97%E8%83%BD/">Sophon算能</a></div></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/c87c0f5d/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">根据LLM参数量估算显存/内存占用</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/5ae3bedd/"><span class="level-item">ONNX算子简介</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content twikoo" id="twikoo"></div><script src="/js/twikoo.all.min.js"></script><script>twikoo.init({envId:"https://cyhasuka.netlify.app/.netlify/functions/twikoo",lang:"zh-CN"})</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0OCIgaGVpZ2h0PSI0OCIgdmlld0JveD0iMCAwIDI0IDI0Ij48Y2lyY2xlIGN4PSI0IiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgaWQ9InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAiIGF0dHJpYnV0ZU5hbWU9InIiIGJlZ2luPSIwO3N2Z1NwaW5uZXJzM0RvdHNTY2FsZTEuZW5kLTAuMjVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNnMiIGR1cj0iMC43NXMiIHZhbHVlcz0iMzsuMjszIi8+PC9jaXJjbGU+PGNpcmNsZSBjeD0iMjAiIGN5PSIxMiIgcj0iMyIgZmlsbD0iY3VycmVudENvbG9yIj48YW5pbWF0ZSBpZD0ic3ZnU3Bpbm5lcnMzRG90c1NjYWxlMSIgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNDVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjwvc3ZnPg==" data-original="/img/profilewbp.webp" alt="Yuhao Cui"></figure><p class="title is-size-4 is-block" style="line-height:inherit">Yuhao Cui</p><p class="is-size-6 is-block">Lidar Perception Algorithm &amp; Robotics</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Suzhou,China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">20</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">19</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/cyhasuka" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/cyhasuka"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Mail" href="mailto:mail@cuiyuhao.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="GMail" href="mailto:cyhasuka@gmail.com"><i class="fab fa-google"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E5%86%99%E7%82%B9%E6%95%99%E7%A8%8B/"><span class="level-start"><span class="level-item">写点教程</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%86%99%E7%82%B9%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">写点笔记</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9D%A5%E7%82%B9%E5%B9%B2%E8%B4%A7/"><span class="level-start"><span class="level-item">来点干货</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%8E%A9%E7%89%A9%E6%9C%89%E5%BF%97/"><span class="level-start"><span class="level-item">玩物有志</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time datetime="2025-01-22T10:10:20.000Z">2025-01-22</time></p><p class="title"><a href="/posts/11f6a109/">【踩坑笔记】Nvidia T4计算卡在Windows服务器使用docker</a></p><p class="categories"><a href="/categories/%E5%86%99%E7%82%B9%E7%AC%94%E8%AE%B0/">写点笔记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2025-01-08T09:28:16.000Z">2025-01-08</time></p><p class="title"><a href="/posts/a11b1e0f/">【论文阅读】清华&amp;理想汽车 DriveVLM :自动驾驶与VLM大模型的融合</a></p><p class="categories"><a href="/categories/%E5%86%99%E7%82%B9%E7%AC%94%E8%AE%B0/">写点笔记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2024-11-04T09:15:05.000Z">2024-11-04</time></p><p class="title"><a href="/posts/530cb732/">docker容器签出及迁移流程</a></p><p class="categories"><a href="/categories/%E5%86%99%E7%82%B9%E7%AC%94%E8%AE%B0/">写点笔记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2024-09-02T06:43:32.000Z">2024-09-02</time></p><p class="title"><a href="/posts/20d2b052/">高速下载 HuggingFace大模型（支持断点续传、多线程）</a></p><p class="categories"><a href="/categories/%E6%9D%A5%E7%82%B9%E5%B9%B2%E8%B4%A7/">来点干货</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2024-07-19T08:26:20.000Z">2024-07-19</time></p><p class="title"><a href="/posts/d650b297/">CentOS yum install 报错：Could not retrieve mirrorlist *** 的解决方法</a></p><p class="categories"><a href="/categories/%E5%86%99%E7%82%B9%E7%AC%94%E8%AE%B0/">写点笔记</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">文章</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/"><span class="level-start"><span class="level-item">2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Autoware/"><span class="tag">Autoware</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NVIDIA/"><span class="tag">NVIDIA</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROG/"><span class="tag">ROG</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sophon%E7%AE%97%E8%83%BD/"><span class="tag">Sophon算能</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%96%E8%AE%BE/"><span class="tag">外设</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87/"><span class="tag">存储设备</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95/"><span class="tag">感知算法</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%91%84%E5%83%8F%E5%A4%B4/"><span class="tag">摄像头</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE/"><span class="tag">激光雷达</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"><span class="tag">环境部署</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/"><span class="tag">系统安装</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%B3%BB%E7%BB%9F%E9%97%AE%E9%A2%98/"><span class="tag">系统问题</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/"><span class="tag">网络设备</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"><span class="tag">自动驾驶</span><span class="tag">6</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0OCIgaGVpZ2h0PSI0OCIgdmlld0JveD0iMCAwIDI0IDI0Ij48Y2lyY2xlIGN4PSI0IiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgaWQ9InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAiIGF0dHJpYnV0ZU5hbWU9InIiIGJlZ2luPSIwO3N2Z1NwaW5uZXJzM0RvdHNTY2FsZTEuZW5kLTAuMjVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNnMiIGR1cj0iMC43NXMiIHZhbHVlcz0iMzsuMjszIi8+PC9jaXJjbGU+PGNpcmNsZSBjeD0iMjAiIGN5PSIxMiIgcj0iMyIgZmlsbD0iY3VycmVudENvbG9yIj48YW5pbWF0ZSBpZD0ic3ZnU3Bpbm5lcnMzRG90c1NjYWxlMSIgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNDVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjwvc3ZnPg==" data-original="/img/toplogo.jpg" alt="CuiYuhao&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 cyhasuka</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客,<span id="busuanzi_value_site_pv">0</span>次访问</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="知识共享" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY 4.0" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="我的GitHub" href="https://github.com/cyhasuka"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn")</script><script>var IcarusThemeSettings={article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load",()=>{window.cookieconsent.initialise({type:"info",theme:"edgeless",static:!1,position:"bottom-left",content:{message:"我们会使用Cookies来改善您的体验。",dismiss:"知道了！",allow:"允许使用Cookies",deny:"拒绝",link:"了解更多",policy:"Cookies政策",href:"https://www.cookiesandyou.com/"},palette:{popup:{background:"#edeff5",text:"#838391"},button:{background:"#4b81e8"}}})})</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load",()=>{"function"==typeof $.fn.lightGallery&&$(".article").lightGallery({selector:".gallery-item"}),"function"==typeof $.fn.justifiedGallery&&($(".justified-gallery > p > .gallery-item").length&&$(".justified-gallery > p > .gallery-item").unwrap(),$(".justified-gallery").justifiedGallery())})</script><script src="/js/main.js" defer></script><script src="/js/chuckle-post-ai.min.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",(function(){loadInsight({contentUrl:"/content.json"},{hint:"想要查找什么...",untitled:"(无标题)",posts:"文章",pages:"页面",categories:"分类",tags:"标签"})}))</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,d=o();function o(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=o());for(var e,i=0;i<d.length;i++)0<=(e=(e=d[i]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,a,n,o=d[i];e=function(){d=d.filter(function(t){return o!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(o)},(t=o).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,n=t.getAttribute("data-original"),a.onload=function(){t.src=n,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=n},t.src!==n&&(a.src=n)))}()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)}(this);</script></body></html>