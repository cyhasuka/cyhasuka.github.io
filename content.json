{"posts":[{"title":"CentOS yum install 报错：Could not retrieve mirrorlist *** 的解决方法","text":"有时使用 yum install 给 linux 服务器安装包的时候会有上述报错，原因是该镜像网址无法访问。 Centos 7 自 2024 年 7 月 1 日 已达到 EOL（生命周期结束），因此 mirrorlist.centos.org 镜像站已停止运行。如果报错包含该镜像站，可以通过下面的命令更改所有包含该镜像站的地址到 vault.centos.org。 123sed -i s/mirror.centos.org/vault.centos.org/g /etc/yum.repos.d/*.reposed -i s/^#.*baseurl=http/baseurl=http/g /etc/yum.repos.d/*.reposed -i s/^mirrorlist=http/#mirrorlist=http/g /etc/yum.repos.d/*.repo 如果报错包含其他镜像站，可将无法访问的镜像站暂时屏蔽，需要时再处理. 12cd /etc/yum.repos.dmv microsoft.repo microsoft.repo.bak &lt;= 仅为示例，换成无法访问的repo","link":"/posts/d650b297/"},{"title":"FastPillars-论文笔记-激光雷达点云感知算法","text":"12论文链接：https://arxiv.org/abs/2302.02367github：https://github.com/StiphyJay/FastPillars 1 引言目前基于激光雷达的主流方法分为基于点云的方法和基于体素的方法。前者能保留最多的几何信息，但逐点查询和遍历较为耗时；后者使用3D/2D卷积处理体素化点云，但用于提高效率的3D稀疏卷积对实际部署不友好。 PointPillars作为deploy-friendly的方法，使用对部署有利的2D卷积。但由于其使用最大池化提取每个柱体内点的特征，无法获取细粒度特征，影响最终性能（特别是对于小物体）。此外，其neck网络FPN直接融合多尺度特征，缺少充分的特征交互。尽管PillarNet提高了PointPillars的性能，但其使用了部署困难的稀疏卷积。 论文提出FastPillars，基于标准卷积，容易部署。网络包含4个部分：piller柱体编码、特征提取、特征融合和3D边界框回归。对于piller编码，提出最大-注意力柱体编码（MAPE）模块，在不引入额外计算时间的情况下自动学习局部几何模式。对于特征提取，提出紧凑而高效的主干网络CRVNet。特征融合模块中，通过层次融合不同尺度和感受野的特征丰富语义特征。3D边界框回归使用基于中心的方法。 2 相关工作3D目标检测中的工业级轻量网络结构：YOLO系列使用CSPNet，在独立的两个分支中处理部分特征，达到更丰富的梯度组合，从而减小存储和计算并提高性能。 RepVGG使用重参数化结构，使用3个分支替代VGG中的Conv-BN-ReLU结构，以帮助优化；推理时使用重参数化将3个分支合并以提高推理速度。 3 论文方法网络包含4个部分：柱体编码、特征提取、特征融合和3D边界框回归。 3.1 最大-注意力柱体编码（MAPE）本文的MAPE包含三个单元：点编码单元、最大池化编码单元和注意力池化编码单元。记非空柱体i内的点集为 （5表示3维位置、反射强度和相对时间戳）。 点编码：首先使用各点与柱体中心的偏移量 以及各点坐标与最小坐标的偏移量 增强各点的特征，得到 。 注意此处与PointPillars不同，不会为了保证各柱体点数相同而丢弃任何点。然后使用MLP将各点映射到高维空间得到 。最大池化编码：使用最大池化聚合柱体内点的特征，得到 。 注意力池化编码：用于保留细粒度信息。使用MLP处理柱体内的点得到注意力分数 ，然后根据加权求和： 其中 。 最后，平均与得到 ，其包含了柱体内的全局信息和细粒度局部信息。MAPE能极大提升小物体的检测能力。 3.2 CRVNet主干基于CSPNet和RepVGG，本文提出CRVNet，基于VGG或ResNet34搭建模型，其基本结构单元如下图所示。使用CSP结构能实现紧凑而高效的网络。由于单路径网络的计算代价和参数量会随模型容量指数增加，本文引入RepBlock。推理时，每个RepBlock会被转化为卷积+激活函数的形式（称为RepConv），以减小推理时间。 3.3 Neck与基于中心的HeadNeck使用PillarNet的设计，融合主干网络多尺度特征。回归头在CenterPoint的基础上添加IoU分支，估计预测边界框和真实边界框的IoU，并使用IoU感知的修正函数减小分类与回归预测的间隙。修正的置信度分数按下式计算，并用于NMS后处理： 其中为预测置信度分数，为预测IoU，。 分类与回归预测的间隙/不一致性：分类分数最高的框不一定是最回归最准的框。 3.4 损失函数使用CenterPoint的损失函数。对于IoU预测，使用L1损失，回归目标被缩放到内；此外添加DIoU损失。总损失如下： 4 实验实施细节：使用随机翻转、旋转和缩放数据增广、GT增广（带衰退策略）；测试时使用双翻转数据增广。 4.1 主要结果4.1.1 定量评估在nuScenes测试集上，FastPillars能超过SOTA方法的性能，且能达到实时性。 4.1.2 与实时One-Stage方法比较与PillarNet比较，本文的方法有2倍的速度而精度相当。 4.2 消融实验4.2.1 最大-注意力柱体编码模块与最大池化相比，本文的MAPE模块能提高性能，且在小物体上的性能提升较大。这证明了MAPE能提取细粒度的局部集合信息。 补充材料B. MAPE不同池化操作的消融实验 与仅使用注意力池化或仅使用最大池化等方法相比，因其融合了主要特征和局部几何特征，本文的最大+注意力池化方法有目前最高的性能。","link":"/posts/26007bd4/"},{"title":"3D-NMS 算法及PCL &amp; CUDA实现","text":"1 NMS 简介NMS（Non Maximum Suppression）即非极大值抑制，广泛应用于传统的特征提取和深度学习的目标检测算法中。 NMS原理是通过筛选出局部极大值得到最优解。 在二维边缘提取中体现在提取边缘轮廓后将一些梯度方向变化率较小的点筛选掉，避免造成干扰。 在三维关键点检测中也起到重要作用，筛选掉特征中非局部极值。 在目标检测方面如Yolo和RCNN等模型中均有使用，可以将较小分数的输出框过滤掉,同样，在三维基于点云的目标检测模型中亦有使用。 2 实现2.1 PCL提取点云极大值特征点（C++实现）点云关键点特征提取算法经常会使用nms提取极大值点。 如3D SIFT关键点检测中需要计算尺度空间中像素点的26邻域的极值点。 1233D SWIFT算法原理参考： https://blog.csdn.net/lingyunxianhe/article/details/79063547https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf 12345678pcl::SIFTKeypoint&lt;pcl::PointXYZ, pcl::PointWithScale&gt; sift;pcl::PointCloud&lt;pcl::PointWithScale&gt; result;sift.setInputCloud(cloud_xyz);pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr tree(new pcl::search::KdTree&lt;pcl::PointXYZ&gt;());sift.setSearchMethod(tree); sift.setScales(0.01f, 7, 20);sift.setMinimumContrast(0.001f);sift.compute(result); 2.2 目标检测筛选bbox（CUDA实现）nms在深度学习领域常用于对 Bounding Box(bbox) 的得分进行极大值筛选，在rcnn，yolo, pointnet, pointpillars等二维、三维检测深度学习模型中广泛使用。 其算法流程大致为： 1：计算所有bbox的得分。 2：排序，依次与得分高的bbox的IoU进行对比，如果大于设定的阈值，就删除该框。 workflow：nmsLauncher -&gt; nms_kernel 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256#define THREADS_PER_BLOCK 16#define DIVUP(m, n) ((m) / (n) + ((m) % (n) &gt; 0))const float EPS = 1e-8;struct Point { float x, y; __device__ Point() {} __device__ Point(double _x, double _y){ x = _x, y = _y; } __device__ void set(float _x, float _y){ x = _x; y = _y; } __device__ Point operator +(const Point &amp;b)const{ return Point(x + b.x, y + b.y); } __device__ Point operator -(const Point &amp;b)const{ return Point(x - b.x, y - b.y); }};__device__ inline void rotate_around_center(const Point &amp;center, const float angle_cos, const float angle_sin, Point &amp;p){ // 将给定点围绕中心点旋转 float new_x = (p.x - center.x) * angle_cos + (p.y - center.y) * (-angle_sin) + center.x; float new_y = (p.x - center.x) * angle_sin + (p.y - center.y) * angle_cos + center.y; p.set(new_x, new_y);}__device__ inline int point_cmp(const Point &amp;a, const Point &amp;b, const Point &amp;center){ // 比较两点相对给定center极角大小 return atan2(a.y - center.y, a.x - center.x) &gt; atan2(b.y - center.y, b.x - center.x);}__device__ inline float cross(const Point &amp;a, const Point &amp;b){ return a.x * b.y - a.y * b.x;}__device__ inline float cross(const Point &amp;p1, const Point &amp;p2, const Point &amp;p0){ // 计算三点构成的两向量叉乘 return (p1.x - p0.x) * (p2.y - p0.y) - (p2.x - p0.x) * (p1.y - p0.y);}__device__ int check_rect_cross(const Point &amp;p1, const Point &amp;p2, const Point &amp;q1, const Point &amp;q2){ // 检查两矩形是否相交 int ret = min(p1.x,p2.x) &lt;= max(q1.x,q2.x) &amp;&amp; min(q1.x,q2.x) &lt;= max(p1.x,p2.x) &amp;&amp; min(p1.y,p2.y) &lt;= max(q1.y,q2.y) &amp;&amp; min(q1.y,q2.y) &lt;= max(p1.y,p2.y); return ret;}__device__ inline int check_in_box2d(const float *box, const Point &amp;p){ //params: (7) [x, y, z, dx, dy, dz, heading] const float MARGIN = 1e-2; float center_x = box[0], center_y = box[1]; float angle_cos = cos(-box[6]), angle_sin = sin(-box[6]); // 将点旋转到box的反方向 float rot_x = (p.x - center_x) * angle_cos + (p.y - center_y) * (-angle_sin); float rot_y = (p.x - center_x) * angle_sin + (p.y - center_y) * angle_cos; return (fabs(rot_x) &lt; box[3] / 2 + MARGIN &amp;&amp; fabs(rot_y) &lt; box[4] / 2 + MARGIN);}__device__ inline int intersection(const Point &amp;p1, const Point &amp;p0, const Point &amp;q1, const Point &amp;q0, Point &amp;ans){ // 快速检查两矩形是否相交，不相交此函数跳过 if (check_rect_cross(p0, p1, q0, q1) == 0) return 0; // 计算三点构成的两向量叉乘 float s1 = cross(q0, p1, p0); float s2 = cross(p1, q1, p0); float s3 = cross(p0, q1, q0); float s4 = cross(q1, p1, q0); if (!(s1 * s2 &gt; 0 &amp;&amp; s3 * s4 &gt; 0)) return 0; // 计算两线交点 float s5 = cross(q1, p1, p0); if(fabs(s5 - s1) &gt; EPS){ ans.x = (s5 * q0.x - s1 * q1.x) / (s5 - s1); ans.y = (s5 * q0.y - s1 * q1.y) / (s5 - s1); } else{ float a0 = p0.y - p1.y, b0 = p1.x - p0.x, c0 = p0.x * p1.y - p1.x * p0.y; float a1 = q0.y - q1.y, b1 = q1.x - q0.x, c1 = q0.x * q1.y - q1.x * q0.y; float D = a0 * b1 - a1 * b0; ans.x = (b0 * c1 - b1 * c0) / D; ans.y = (a1 * c0 - a0 * c1) / D; } return 1;}__device__ inline float box_overlap(const float *box_a, const float *box_b){ // params box_a: [x, y, z, dx, dy, dz, heading] // params box_b: [x, y, z, dx, dy, dz, heading] float a_angle = box_a[6], b_angle = box_b[6]; float a_dx_half = box_a[3] / 2, b_dx_half = box_b[3] / 2, a_dy_half = box_a[4] / 2, b_dy_half = box_b[4] / 2; float a_x1 = box_a[0] - a_dx_half, a_y1 = box_a[1] - a_dy_half; float a_x2 = box_a[0] + a_dx_half, a_y2 = box_a[1] + a_dy_half; float b_x1 = box_b[0] - b_dx_half, b_y1 = box_b[1] - b_dy_half; float b_x2 = box_b[0] + b_dx_half, b_y2 = box_b[1] + b_dy_half; Point center_a(box_a[0], box_a[1]); Point center_b(box_b[0], box_b[1]); Point box_a_corners[5]; box_a_corners[0].set(a_x1, a_y1); box_a_corners[1].set(a_x2, a_y1); box_a_corners[2].set(a_x2, a_y2); box_a_corners[3].set(a_x1, a_y2); Point box_b_corners[5]; box_b_corners[0].set(b_x1, b_y1); box_b_corners[1].set(b_x2, b_y1); box_b_corners[2].set(b_x2, b_y2); box_b_corners[3].set(b_x1, b_y2); float a_angle_cos = cos(a_angle), a_angle_sin = sin(a_angle); float b_angle_cos = cos(b_angle), b_angle_sin = sin(b_angle); for (int k = 0; k &lt; 4; k++){ rotate_around_center(center_a, a_angle_cos, a_angle_sin, box_a_corners[k]); rotate_around_center(center_b, b_angle_cos, b_angle_sin, box_b_corners[k]); } box_a_corners[4] = box_a_corners[0]; box_b_corners[4] = box_b_corners[0]; // 求直线交点 Point cross_points[16]; Point poly_center; int cnt = 0, flag = 0; poly_center.set(0, 0); for (int i = 0; i &lt; 4; i++){ for (int j = 0; j &lt; 4; j++){ flag = intersection(box_a_corners[i + 1], box_a_corners[i], box_b_corners[j + 1], box_b_corners[j], cross_points[cnt]); if (flag){ poly_center = poly_center + cross_points[cnt]; cnt++; } } } // 检查AB两矩形框的角点是否在彼此内部，若角点在彼此内部，则相互交叉 for (int k = 0; k &lt; 4; k++){ if (check_in_box2d(box_a, box_b_corners[k])){ poly_center = poly_center + box_b_corners[k]; cross_points[cnt] = box_b_corners[k]; cnt++; } if (check_in_box2d(box_b, box_a_corners[k])){ poly_center = poly_center + box_a_corners[k]; cross_points[cnt] = box_a_corners[k]; cnt++; } } poly_center.x /= cnt; poly_center.y /= cnt; // 冒泡法对顶点排序 Point temp; for (int j = 0; j &lt; cnt - 1; j++){ for (int i = 0; i &lt; cnt - j - 1; i++){ if (point_cmp(cross_points[i], cross_points[i + 1], poly_center)){ temp = cross_points[i]; cross_points[i] = cross_points[i + 1]; cross_points[i + 1] = temp; } } } // 计算重叠区域面积 float area = 0; for (int k = 0; k &lt; cnt - 1; k++){ area += cross(cross_points[k] - cross_points[0], cross_points[k + 1] - cross_points[0]); } return fabs(area) / 2.0;}__device__ inline float iou_bev(const float *box_a, const float *box_b){ // params box_a: [x, y, z, dx, dy, dz, heading] // params box_b: [x, y, z, dx, dy, dz, heading] float sa = box_a[3] * box_a[4]; float sb = box_b[3] * box_b[4]; float s_overlap = box_overlap(box_a, box_b); return s_overlap / fmaxf(sa + sb - s_overlap, EPS);}__global__ void nms_kernel(const int boxes_num, const float nms_overlap_thresh, const float *boxes, unsigned long long *mask){ /* params: boxes (N, 7) [x, y, z, dx, dy, dz, heading] 7 -------- 4 /| /| 6 -------- 5 . | | | | . 3 -------- 0 |/ |/ 2 -------- 1 params: mask (N, N/THREADS_PER_BLOCK_NMS) */ const int row_start = blockIdx.y; const int col_start = blockIdx.x; const int row_size = fminf(boxes_num - row_start * THREADS_PER_BLOCK_NMS, THREADS_PER_BLOCK_NMS); const int col_size = fminf(boxes_num - col_start * THREADS_PER_BLOCK_NMS, THREADS_PER_BLOCK_NMS); __shared__ float block_boxes[THREADS_PER_BLOCK_NMS * 7]; if (threadIdx.x &lt; col_size) { block_boxes[threadIdx.x * 7 + 0] = boxes[(THREADS_PER_BLOCK_NMS * col_start + threadIdx.x) * 7 + 0]; block_boxes[threadIdx.x * 7 + 1] = boxes[(THREADS_PER_BLOCK_NMS * col_start + threadIdx.x) * 7 + 1]; block_boxes[threadIdx.x * 7 + 2] = boxes[(THREADS_PER_BLOCK_NMS * col_start + threadIdx.x) * 7 + 2]; block_boxes[threadIdx.x * 7 + 3] = boxes[(THREADS_PER_BLOCK_NMS * col_start + threadIdx.x) * 7 + 3]; block_boxes[threadIdx.x * 7 + 4] = boxes[(THREADS_PER_BLOCK_NMS * col_start + threadIdx.x) * 7 + 4]; block_boxes[threadIdx.x * 7 + 5] = boxes[(THREADS_PER_BLOCK_NMS * col_start + threadIdx.x) * 7 + 5]; block_boxes[threadIdx.x * 7 + 6] = boxes[(THREADS_PER_BLOCK_NMS * col_start + threadIdx.x) * 7 + 6]; } __syncthreads(); if (threadIdx.x &lt; row_size) { const int cur_box_idx = THREADS_PER_BLOCK_NMS * row_start + threadIdx.x; const float *cur_box = boxes + cur_box_idx * 7; int i = 0; unsigned long long t = 0; int start = 0; if (row_start == col_start) { start = threadIdx.x + 1; } for (i = start; i &lt; col_size; i++) { if (iou_bev(cur_box, block_boxes + i * 7) &gt; nms_overlap_thresh){ t |= 1ULL &lt;&lt; i; } } const int col_blocks = DIVUP(boxes_num, THREADS_PER_BLOCK_NMS); mask[cur_box_idx * col_blocks + col_start] = t; }}void nmsLauncher(const float *boxes, unsigned long long * mask, int boxes_num, float nms_overlap_thresh){ dim3 blocks(DIVUP(boxes_num, THREADS_PER_BLOCK_NMS), DIVUP(boxes_num, THREADS_PER_BLOCK_NMS)); dim3 threads(THREADS_PER_BLOCK_NMS); nms_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(boxes_num, nms_overlap_thresh, boxes, mask);}","link":"/posts/764ef83/"},{"title":"Nvidia GPU &amp; 算能Sophon TPU 算子耗时分析","text":"1、Nvidia GPU该分析方法适合onnx模型或trt模型，NV的工具栏较为易用，可使用 trtexec 命令直接输出算子耗时。注意，有些易于优化计算的算子（例如 Conv+Relu 、Conv+BN+Relu），会作为一个算子集计算，此时无法直接读取到每个独立算子的耗时。 首先需要安装Nvidia TensorRT库、CUDA ToolKit（没这俩咋玩呀），然后使用trtexec命令行工具进行推理。 示例命令： 1trtexec --onnx=pfe+backbone_v12.onnx --loadInputs=input.1 --fp16 --exportProfile=bmap_dbg.json --verbose 其中，--onnx参数指定onnx文件路径，--loadInputs参数指定输入层name，--fp16选项指定启用FP16推理。后面的两个参数为用于分析推理过程，--exportProfile参数用于将每个算子层的耗时及占比信息存入.json文件， --verbose参数用于输出详细日志目录。 以下是全部参数详细说明，版本不符可以使用--help参数，大致内容相似： 单击展开 1.1 Model Option 模型选项 –uff : UFF模型文件名 –onnx : ONNX模型文件名 –model : Caffe模型文件名，模式时无模型，使用随机权重 –deploy : Caffe prototxt 文件名 –output : 输出名称（可多次指定）；UFF和Caffe至少需要一个输出 –uffInput : 输入blob名称及其维度（X、Y、Z=C、H、W），可以多次指定；UFF型号至少需要一个 –uffNHWC : 设置输入是否在NHWC布局中而不是NCHW中（在–uffInput中使用X、Y、Z=H、W、C顺序） 1.2 Build Options 构建选项 –maxBatch ： 设置最大批处理大小并构建隐式批处理引擎（默认值=1） –explicitBatch ：构建引擎时使用显式批量大小（默认 = 隐式） –minShapes=spec ： 使用提供的最小 shape 的配置文件构建动态 shape –optShapes=spec ： 使用提供的 opt shape 的配置文件构建动态 shape –maxShapes=spec ： 使用提供的最大 shape 的配置文件构建动态 shape –minShapesCalib=spec ： 使用提供的最小 shape 的配置文件校准动态 shape –optShapesCalib=spec ： 使用提供的 opt shape 的配置文件校准动态 shape –maxShapesCalib=spec ：使用提供的最大 shape 的配置文件校准动态 shape 注意：必须提供所有三个 min、opt 和 max shape 。但是，如果只提供了 opt shape ，那么它将被扩展，以便将最小 shape 和最大 shape 设置为与 opt shape 相同的值。此外，使用 动态 shape 意味着显式批处理。 输入名称可以用转义单引号括起来（例如：‘Input:0’）。示例输入 shape 规范：input0:1x3x256x256,input1:1x3x128x128 每个输入 shape 都作为键值对提供，其中 key 是输入名称 值是用于该输入的维度（包括批次维度）。 每个键值对都使用冒号 (😃 分隔键和值。 可以通过逗号分隔的键值对提供多个输入 shape 。 –inputIOFormats=spec ： 每个输入张量的类型和格式（默认所有输入为fp32:chw） 注意：如果指定此选项，请按照与网络输入ID相同的顺序为所有输入设置逗号分隔的类型和格式（即使只有一个输入需要指定IO格式）或设置一次类型和格式以进行广播。 –outputIOFormats=spec : 每个输出张量的类型和格式（默认所有输入为fp32:chw） 注意：如果指定此选项，请按照与网络输出ID相同的顺序为所有输出设置逗号分隔的类型和格式（即使只有一个输出需要指定IO格式）或设置一次类型和格式以进行广播。 –workspace=N ： 以M为单位设置工作区大小（默认值 = 16） –noBuilderCache : 在构建器中禁用时序缓存（默认是启用时序缓存） –nvtxMode=mode : 指定 NVTX 注释详细程度。 mode ::= default|verbose|none –minTiming=M : 设置内核选择中使用的最小迭代次数（默认值 = 1） –avgTiming=M : 为内核选择设置每次迭代的平均次数（默认值 = 8） –noTF32 : 禁用 tf32 精度（默认是启用 tf32，除了 fp32） –refit : 将引擎标记为可改装。这将允许检查引擎内的可改装层和重量。 –fp16 ： 除 fp32 外，启用 fp16 精度（默认 = 禁用） –int8 : 除 fp32 外，启用 int8 精度（默认 = 禁用） –best : 启用所有精度以达到最佳性能（默认 = 禁用） –calib= : 读取INT8校准缓存文件 –safe : 仅测试安全受限流中可用的功能 –saveEngine= : 保存序列化模型的文件名 –loadEngine= ： 加载序列化模型的文件名 –tacticSources=tactics ： 通过从默认策略源（默认 = 所有可用策略）中添加 (+) 或删除 (-) 策略来指定要使用的策略。 1.3 Inference Options 推理选项 –batch=N ： 为隐式批处理引擎设置批处理大小（默认值 = 1） –shapes=spec ： 为动态 shape 推理输入设置输入 shape 。 注意：使用动态 shape 意味着显式批处理。 输入名称可以用转义的单引号括起来（例如：‘Input:0’）。 示例输入 shape 规范：input0:1x3x256x256, input1:1x3x128x128 每个输入 shape 都作为键值对提供，其中键是输入名称，值是用于该输入的维度（包括批次维度）。 每个键值对都使用冒号 (😃 分隔键和值。 可以通过逗号分隔的键值对提供多个输入 shape 。 –loadInputs=spec ：从文件加载输入值（默认 = 生成随机输入）。 输入名称可以用单引号括起来（例如：‘Input:0’） –iterations=N ： 至少运行 N 次推理迭代（默认值 = 10） –warmUp=N ： 在测量性能之前运行 N 毫秒以预热（默认值 = 200） –duration=N ： 运行至少 N 秒挂钟时间的性能测量（默认值 = 3） –sleepTime=N ： 延迟推理以启动和计算之间的 N 毫秒间隔开始（默认 = 0） –streams=N ： 实例化 N 个引擎以同时使用（默认值 = 1） –exposeDMA ： 串行化进出设备的 DMA 传输。 （默认 = 禁用） –noDataTransfers ： 在推理过程中，请勿将数据传入和传出设备。 （默认 = 禁用） –useSpinWait ： 主动同步 GPU 事件。 此选项可能会减少同步时间，但会增加 CPU 使用率和功率（默认 = 禁用） –threads ： 启用多线程以驱动具有独立线程的引擎（默认 = 禁用） –useCudaGraph ： 使用 cuda 图捕获引擎执行，然后启动推理（默认 = 禁用） –separateProfileRun ： 不要在基准测试中附加分析器； 如果启用分析，将执行第二次分析运行（默认 = 禁用） –buildOnly ： 跳过推理性能测量（默认 = 禁用） 1.4 Build and Inference Batch Options 构建和推理批处理选项 使用隐式批处理时，引擎的最大批处理大小（如果未指定）设置为推理批处理大小； 使用显式批处理时，如果仅指定 shape 用于推理，它们也将在构建配置文件中用作 min/opt/max； 如果只为构建指定了 shape ，则 opt shape 也将用于推理； 如果两者都被指定，它们必须是兼容的； 如果启用了显式批处理但都未指定，则模型必须为所有输入提供完整的静态维度，包括批处理大小 1.5 Reporting Options 报告选项 –verbose ： 使用详细日志记录（默认值 = false） –avgRuns=N ： 报告 N 次连续迭代的平均性能测量值（默认值 = 10） –percentile=P ： 报告 P 百分比的性能 P=(0~100)，0 代表最大性能，100 代表最小性能；（默认 = 99%）） –dumpRefit ： 从可改装引擎打印可改装层和重量 –dumpOutput ： 打印最后一次推理迭代的输出张量（默认 = 禁用） –dumpProfile ： 每层打印配置文件信息（默认 = 禁用） –exportTimes= ： 将计时结果写入 json 文件（默认 = 禁用） –exportOutput= ： 将输出张量写入 json 文件（默认 = 禁用） –exportProfile= ： 将每层的配置文件信息写入 json 文件（默认 = 禁用） 1.6 System Options 系统选项 –device=N ：选择 cuda 设备 N（默认 = 0） –useDLACore=N ： 为支持 DLA 的层选择 DLA 核心 N（默认 = 无） –allowGPUFallback ： 启用 DLA 后，允许 GPU 回退不受支持的层（默认 = 禁用） –plugins ： 要加载的插件库 (.so)（可以多次指定） 1.7 Help 帮助 –help, -h ： 打印以上帮助信息 执行完成后，会在当前目录生成一个json文件，内容包含：算子层名称、共计执行时间（运行时间与重复运行次数相关，非单次执行时间）、平均单次执行时间、占用率。 输出示例： 123456789[ { &quot;count&quot; : 252 }, { &quot;name&quot; : &quot;Reformatting CopyNode for Input Tensor 0 to Pad_0 + Conv_1 + Relu_2&quot;, &quot;timeMs&quot; : 75.319, &quot;averageMs&quot; : 0.298885, &quot;percentage&quot; : 6.04541 }, { &quot;name&quot; : &quot;Pad_0 + Conv_1 + Relu_2&quot;, &quot;timeMs&quot; : 52.394, &quot;averageMs&quot; : 0.207913, &quot;percentage&quot; : 4.20535 }, { &quot;name&quot; : &quot;Conv_3 + Relu_4&quot;, &quot;timeMs&quot; : 44.4168, &quot;averageMs&quot; : 0.176257, &quot;percentage&quot; : 3.56507 }, { &quot;name&quot; : &quot;Conv_5 + Relu_6&quot;, &quot;timeMs&quot; : 43.1007, &quot;averageMs&quot; : 0.171035, &quot;percentage&quot; : 3.45944 }, { &quot;name&quot; : &quot;Conv_7 + Relu_8&quot;, &quot;timeMs&quot; : 42.7234, &quot;averageMs&quot; : 0.169537, &quot;percentage&quot; : 3.42915 }, { &quot;name&quot; : &quot;Conv_9 + Relu_10&quot;, &quot;timeMs&quot; : 16.1732, &quot;averageMs&quot; : 0.0641793, &quot;percentage&quot; : 1.29812 }] 上面仅是简单分析算子簇耗时，其实NV还提供了很多分析工具，例如NVIDIA Nsight™ Systems，它可以通过多种方式配置，以仅报告程序执行的一部分的时序信息，或者也可以将传统的 CPU 采样配置文件信息与 GPU 信息一起报告。 2、Sophon TPU算能TPU提供了TPU Profile工具，帮助完成算子分析。TPU内部主要由MCU、GDMA、TIU三个engine来完成工作。 MCU在BM1684X上是一个单核的A53处理器，通过firmware固件程序完成向GDMA、TIU两个engine下发命令、驱动通信、简单计算等具体功能，实现了算子的具体逻辑。 GDMA和TIU是实际的执行引擎，GDMA用于Global mem与Local mem之间传输数据，实现了1D、矩阵、4D等数据搬运功能；TIU对local mem中的数据执行密集计算命令，包括卷积、矩阵乘法、算术等原子操作。 2.1、分析流程简述分析流程，若程序在X86架构服务器完成编译，在边缘计算盒推理，分析主要分为六步。若编译推理在同域内进行，可省去数据拷贝流程，分为四步。 [服务器] 程序生成mlir -&gt; [服务器] mlir转bmodel -&gt; [服务器] bmodel拷贝至SE7-&gt;[SE7] 运行生成data文件-&gt;[SE7] 结果拷回服务器 -&gt; [服务器] data转换为HTML profile可视化 [服务器] 程序生成mlir 首先进入docker环境，source运行环境 ``` 1source /workspace/tpu-mlir_v1.3.140-g3180ff37-20231116/envsetup.sh 生成mlir文件，需要更改onnx模型对应shape及输出节点名 ```1model_transform.py --model_name pp_bmap --model_def ./pfe+backbone_v12.onnx --input_shapes [[1,40,512,512]] --keep_aspect_ratio --output_names '273','320','367','414','461','508','542' --mlir bmap_dbg_1.mlir [服务器] mlir转bmodel 在上一步基础上，运行model_deploy 注意，默认情况下，会将算子融合成算子簇来计算，优化推理效率。如果需要对单独算子进行评估，命令需要加--disable_layer_group参数来禁用算子融合操作。 ``` 1model_deploy.py --mlir bmap_dbg_1.mlir --quantize F16 --chip bm1684x --test_input ../concat_in_f32.npz --test_reference ../concat_top_outputs.npz --debug --compare_all --model bmap_dbg_2_F16F32.bmodel --quantize_table qtable_con --disable_layer_group 将生成的bmodel拷贝至SE7等边缘计算设备 (可选) [SE7] 运行生成data文件 ``` 12# 通过环境变量(BMRUNTIME_ENABLE_PROFILE)使能profile, 生成二进制数据BMRUNTIME_ENABLE_PROFILE=1 bmrt_test --bmodel bmap_dbg_2_F16F32.bmodel 使能profile运行会生成一个bmprofile_data-1的文件夹，内部包含运行数据 将该文件夹拷贝至服务器（可选） [服务器] data转换为HTML profile可视化 ``` 1tpu_profile.py --arch BM1684X bmprofile_data-1 out_dir 运行会生成out_dir文件夹，内部包含json数据和html文件，浏览器打开即可查看数据。 tips：docker与主机拷贝命令 ``` 1sudo docker cp se7:/workspace/concat/layer/bmprofile_out_1 /home/username/ 退出docker：ctrl+D 生成时序图数据后，可按需查看并分析。详细说明请见tpu-mlir官方说明 : TPU Profile工具使用及分析 | TPUMLIR 开源工具链项目 | 通用 AI 编译器工具链项目，高效将模型编译生成 TPU 执行代码","link":"/posts/186ec257/"},{"title":"NVIDIA GPU 架构与 CUDA 算力","text":"使用NVCC编译时，Gencodes（’-gencode‘）后带arch和code参数。arch标志（’arch‘）指定了CUDA文件将被编译的英伟达（NVIDIA®）GPU架构名称，code标志（’code‘）指定了GPU算力。例如 （’-gencode arch=compute_75,code=sm_75‘） 以下是 NVIDIA GPU 架构名称及其算力对照表： Fermi † Kepler † Maxwell ‡ Pascal Volta Turing Ampere Ada Hopper Blackwell sm_20 sm_30 sm_50 sm_60 sm_70 sm_75 sm_80 sm_89 sm_90 sm_95 sm_35 sm_52 sm_61 sm_72(Xavier) sm_86 sm_90a (Thor) sm_37 sm_53 sm_62 sm_87 (Orin) † 从 CUDA 9 和 11 开始，Fermi 和 Kepler 已被弃用‡ 自 CUDA 11.6 起，Maxwell 已被弃用 Q&amp;A1. 何时应使用不同的 “gencodes “或 “cuda arch”？编译 CUDA 代码时，应始终只编译一个与最常用的 GPU 显卡相匹配的 “-arch“标志。这将加快运行速度，因为代码生成将在编译过程中进行。如果只提及 “-gencode“，却省略了 “-arch“标志，那么 GPU 代码生成将在 JIT 编译器上由 CUDA 驱动程序完成。 如果想加快 CUDA 编译速度，就需要减少无关的 “-gencode“标志。不过，有时可能希望通过添加更全面的 “-gencode“标记来获得更好的 CUDA 向后兼容性。 在继续之前，请先确定 GPU 和 安装的 CUDA 版本。 2. CUDA 版本与 GPU 核心架构详细列表Fermi 架构 (CUDA 3.2 至 CUDA 8)从CUDA 9开始，kepler架构已被弃用，CUDA10开始完全停止支持. SM20 -&gt; SM_20, compute_30 –GeForce 400, 500, 600, GT-630. ** Kepler 架构 (CUDA 5 至 CUDA 10)从CUDA 11开始，kepler架构已被弃用. SM30 -&gt; SM_30, compute_30 –Kepler 架构 (e.g. generic Kepler, GeForce 700, GT-730). SM35 -&gt; SM_35, compute_35 –Tesla K40. SM37 -&gt;SM_37, compute_37 –Tesla K80. Maxwell 架构 (CUDA 6 至 CUDA 11)从CUDA 11开始，Maxwell架构已被弃用. SM50 -&gt;SM_50, compute_50 –Tesla/Quadro M 系列. SM52 -&gt;SM_52, compute_52 –Quadro M6000 , GeForce 900, GTX-970, GTX-980, GTX Titan X. SM53 -&gt;SM_53, compute_53 –Tegra (Jetson) TX1 / Tegra X1, Drive CX, Drive PX, Jetson Nano. Pascal 架构 (CUDA 8 至今) SM60 or SM_60, compute_60 –Quadro GP100, Tesla P100, DGX-1 (Generic Pascal) SM61 or SM_61, compute_61–GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030 (GP108), GT 1010 (GP108) Titan Xp, Tesla P40, Tesla P4, NVIDIA Drive PX2 SM62 or SM_62, compute_62 –NVIDIA Drive PX2, Tegra (Jetson) TX2 Volta 架构 (CUDA 9 至今) SM70 or SM_70, compute_70 –DGX-1 with Volta, Tesla V100, GTX 1180 (GV104), Titan V, Quadro GV100 SM72 or SM_72, compute_72 –Jetson AGX Xavier, Drive AGX Pegasus, Xavier NX Turing 架构 (CUDA 10 至今) SM75 or SM_75, compute_75 –GTX/RTX Turing – GTX 1660 Ti, RTX 2060, RTX 2070, RTX 2080, Titan RTX, Quadro RTX 4000, Quadro RTX 5000, Quadro RTX 6000, Quadro RTX 8000, Quadro T1000/T2000, Tesla T4 Ampere 架构 (CUDA 11.1 至今) SM80 or SM_80, compute_80 –NVIDIA A100 (“Tesla” 命名从此代开始停用 – GA100), NVIDIA DGX-A100 SM86 or SM_86, compute_86 – (CUDA 11.1 onwards)Tesla GA10x cards, RTX Ampere – RTX 3080, GA102 – RTX 3090, RTX A2000, A3000, RTX A4000, A5000, A6000, NVIDIA A40, GA106 – RTX 3060, GA104 – RTX 3070, GA107 – RTX 3050, RTX A10, RTX A16, RTX A40, A2 Tensor Core GPU SM87 or SM_87, compute_87 – (CUDA 11.4 onwards, 采用 PTX ISA 7.4 / 驱动程序 r470 及更新版本）- 该项仅适用于 Jetson AGX Orin 和 Drive AGX Orin “与计算能力为 8.0 的设备相比，计算能力为 8.6 的设备每个 SM 每个周期的 FP32 操作量增加了 2 倍。虽然为 8.0 编译的二进制文件可以在 8.6 上原样运行，但建议明确为 8.6 进行编译，以便从增加的 FP32 吞吐量中获益。.“ https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#improved_fp32 Ada Lovelace 架构 (CUDA 11.8 至今) SM89 or SM_89, compute_89 –NVIDIA GeForce RTX 4090, RTX 4080, RTX 4070, RTX 4060, RTX 6000 Ada, Tesla L40, L40s Ada, L4 Ada Hopper 架构 (CUDA 12 至今) SM90 or SM_90, compute_90 –NVIDIA H100 (GH100), NVIDIA H200 SM90a or SM_90a, compute_90a – (适用于 PTX ISA 8.0 版）- 为 wgmma 和 setmaxnreg 等功能添加了加速功能。英伟达™（NVIDIA®）CUTLASS 需要此功能。 Blackwell 架构 (CUDA 12 至今) SM95 or SM_95, compute_95 –NVIDIA B100 (GB100) 3. GCC 中的 nvcc``gencode 和 arch 标志示例注意：如果在生产环境中，部署的计算卡是固定的型号，不需要兼容性时，如A100，nvcc生成时建议固定指定算力数据，可以最大程度保证算力不会浪费。 根据 NVIDIA 提供的信息： nvcc 的 -gencode= 命令行选项中的 arch= 指定前端编译目标，并且必须始终是 PTX 版本。code= 指定后端编译目标，可以是 cubin 或 PTX，也可以是两者。生成的二进制文件将只保留 code= 指定的后端目标版本；至少有一个版本必须是 PTX，以提供 Ampere 兼容性。 在 CUDA 7.0 上生成 GCC 的示例flag，可最大程度地兼容该时代的所有显卡： -arch=sm_30 \\ -gencode=arch=compute_20,code=sm_20 \\ -gencode=arch=compute_30,code=sm_30 \\ -gencode=arch=compute_50,code=sm_50 \\ -gencode=arch=compute_52,code=sm_52 \\ -gencode=arch=compute_52,code=compute_52 在 CUDA 8.1 上生成的示例flag，可与 Volta 之前的显卡实现最大程度的兼容性： -arch=sm_30 \\ -gencode=arch=compute_20,code=sm_20 \\ -gencode=arch=compute_30,code=sm_30 \\ -gencode=arch=compute_50,code=sm_50 \\ -gencode=arch=compute_52,code=sm_52 \\ -gencode=arch=compute_60,code=sm_60 \\ -gencode=arch=compute_61,code=sm_61 \\ -gencode=arch=compute_61,code=compute_61 在 CUDA 9.2 上生成的示例标志，可与 Volta 显卡实现最大兼容性： -arch=sm_50 \\-gencode=arch=compute_50,code=sm_50 \\-gencode=arch=compute_52,code=sm_52 \\-gencode=arch=compute_60,code=sm_60 \\-gencode=arch=compute_61,code=sm_61 \\-gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 在CUDA 10.1上生成的样本标志，与 V100 和 T4 图灵卡具有最大兼容性： -arch=sm_50 -gencode=arch=compute_50,code=sm_50 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 \\-gencode=arch=compute_75,code=compute_75 在CUDA 11.0上生成的标记示例，与 V100 和 T4 图灵卡具有最大兼容性： -arch=sm_52 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 \\-gencode=arch=compute_80,code=sm_80 \\-gencode=arch=compute_80,code=compute_80 在CUDA 11.7上生成，与 V100 和 T4 显卡具有最大兼容性，但也支持较新的 RTX 3080 和 Drive AGX Orin： -arch=sm_52 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 \\-gencode=arch=compute_80,code=sm_80 \\-gencode=arch=compute_86,code=sm_86 \\-gencode=arch=compute_87,code=sm_87-gencode=arch=compute_86,code=compute_86 在CUDA 11.4上生成的示例标志，可使 RTX 3080 显卡发挥最佳性能： -arch=sm_80 -gencode=arch=compute_80,code=sm_80 \\-gencode=arch=compute_86,code=sm_86 \\-gencode=arch=compute_87,code=sm_87 \\-gencode=arch=compute_86,code=compute_86 使用 GeForce RTX 4080、L40s、L4 和 RTX A6000 Ada 显卡在 CUDA 12 上生成最佳性能的示例标志： -arch=sm_89 -gencode=arch=compute_89,code=sm_89 \\-gencode=arch=compute_89,code=compute_89 在 CUDA12（PTX ISA 版本 8.0）上生成的示例标记，可与英伟达 H100 和 H200（Hopper）图形处理器实现最佳性能，且不向下兼容前几代产品： -arch=sm_90 -gencode=arch=compute_90,code=sm_90 \\-gencode=arch=compute_90a,code=sm_90a \\-gencode=arch=compute_90a,code=compute_90a 为 Hopper GPU 增加更多兼容性和一些向后兼容性： -arch=sm_52 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_87,code=sm_87 \\-gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_90,code=compute_90 4. 在 PyTorch 中使用 TORCH_CUDA_ARCH_LIST如果使用的是 PyTorch，可以在安装时使用 TORCH_CUDA_ARCH_LIST 环境变量设置架构，例如： TORCH_CUDA_ARCH_LIST=&quot;7.0 7.5 8.0 8.6&quot; python3 setup.py install 请注意，虽然你可以在这个变量中指定每一个架构，但每一个都会延长编译时间，因为内核必须针对每一个架构进行编译。 也可以在指定的最新架构上添加后缀 +PTX 来告诉 PyTorch 生成与较新的显卡向前兼容的 PTX 代码： TORCH_CUDA_ARCH_LIST=&quot;7.0 7.5 8.0 8.6+PTX&quot; python3 build_my_extension.py 5. 使用 Cmake 编译 TensorRT如果使用 CMAKE 编译 TensorRT，请去掉 sm_ 和 compute_ 前缀，只提及计算能力。 以 Tesla V100 和 Volta 显卡为例：cmake &lt;...&gt; `-DGPU_ARCHS=&quot;70&quot;` 以英伟达 RTX 2070 和特斯拉 T4 为例：cmake &lt;...&gt; -DGPU_ARCHS=&quot;75&quot; NVIDIA A100 示例：cmake &lt;...&gt; `-DGPU_ARCHS=&quot;80&quot;` 以英伟达™（NVIDIA®）RTX 3080 和 A100 一起使用为例：cmake &lt;...&gt; -DGPU_ARCHS=&quot;80 86&quot; NVIDIA H100 示例：cmake &lt;...&gt; -DGPU_ARCHS=&quot;90&quot; 6. 使用 Cmake 编译 CUTLASS 和 Hopper GH100cmake .. -DCUTLASS_NVCC_ARCHS=90a 7. Value ‘sm_86’ is not defined for option ‘gpu-architecture’如果出现类似下面的错误： 1nvcc fatal : Value 'sm_86' is not defined for option 'gpu-architecture'. 可能安装了旧版本的 CUDA 和/或驱动程序。升级到较新的驱动程序，至少 450.36.06 或更高版本，以支持 A100、RTX 3080等 sm_8x 显卡。 8. CUDA runtime error: operation not supported如果收到类似下面这样的 std::runtime_error（runtime error）： 1CUDA runtime error：operation not supported 显卡不支持生成的runtime code。 使用 nvidia-smi 查看显卡和驱动程序版本。然后，尝试匹配生成代码，生成适合显卡的正确的runtime code。","link":"/posts/8a630bae/"},{"title":"Rplidar A3使用教程（在A2基础上）","text":"rplidar A3的ID与a2相同，均为10c4:ea60，串口文件中配置过A2可以直接换a3在工作空间下git rplidar最新软件包 1git clone https://github.com/ncnynl/rplidar_ros.git 编译工作空间编译通过后运行 1roslaunch rplidar_ros view_rplidar_a3.launch 若出现激光图即安装成功。注意事项：A3的波特率为256000，不可调低，否则报错无法运行贴一段launch文件中的代码作参考 123456789&lt;node name=&quot;rplidarNode&quot; pkg=&quot;rplidar_ros&quot; type=&quot;rplidarNode&quot; output=&quot;screen&quot;&gt; &lt;param name=&quot;serial_port&quot; type=&quot;string&quot; value=&quot;/dev/rplidar&quot;/&gt; &lt;param name=&quot;serial_baudrate&quot; type=&quot;int&quot; value=&quot;256000&quot;/&gt; &lt;!--波特率为256000--&gt; &lt;param name=&quot;frame_id&quot; type=&quot;string&quot; value=&quot;laser&quot;/&gt; &lt;param name=&quot;inverted&quot; type=&quot;bool&quot; value=&quot;false&quot;/&gt; &lt;param name=&quot;angle_compensate&quot; type=&quot;bool&quot; value=&quot;true&quot;/&gt; &lt;param name=&quot;scan_mode&quot; type=&quot;string&quot; value=&quot;Sensitivity&quot;/&gt; &lt;!--雷达工作模式--&gt; &lt;remap from=&quot;scan&quot; to=&quot;scan_raw&quot;/&gt;&lt;/node&gt; 由于雷达兼容，在原程序中修改一下雷达参数即可使用RPlidar A3.","link":"/posts/2aff5314/"},{"title":"Ubuntu 18.04 安装RealSense D435教程","text":"1.更新内核运行代码1uname -r 如果&gt;=4.4.0-50的版本则ok，否则需要升级内核。 2.更新cmake（需要3.6以上版本）（需要科学上网）首先下载cmake-3.13.2.tar.gz :https://cmake.org/download/ 在主文件夹下新建tools/文件夹，将cmake-3.13.2.tar.gz解压之后放在tools/中，更改权限解压： 1sudo tar -zxvf cmake-3.13.2.tar.gz 赋权限：1sudo chmod -R 777 cmake-3.13.2安装gcc-c++:1234sudo apt-get install build-essentialsudo ./bootstrapsudo makesudo make install查看是否安装成功以及安装版本：1cmake --version 3.安装依赖1sudo apt-get install libusb-1.0-0-dev pkg-config libgtk-3-dev 4.下载realsense库（强烈建议科学上网！！否则请先下载好解压到目录）1sudo git clone https://github.com/IntelRealSense/librealsense.git 5.进入librealsense路径下，执行下列命令（cmake时科学上网）123mkdir build &amp;&amp; cd buildcmake ../cmake ../ -DBUILD_EXAMPLES=true 6.安装（安装之前务必确认cmake成功）1make &amp;&amp; sudo make install 7.切换到librealsense的路径下，安装Video4Linux视频内核驱动，不能插Realsense！！！！12sudo cp config/99-realsense-libusb.rules /etc/udev/rules.d/sudo udevadm control --reload-rules &amp;&amp; udevadm trigger 8.安装Openssl库：1sudo apt-get install libssl-dev 9.编译配置文件：1./scripts/patch-realsense-ubuntu-lts.sh 注意上面的配置文件，一定是lts版本！否则程序会崩！ 10.检查安装驱动是否成功完成后，插上Realsense，执行1sudo dmesg | tail -n 50无失败信息则安装驱动成功 11.运行例程检验进入librealsense/build/examples文件夹，执行12cd capture./rs-capture看到彩图和深度图即安装成功。//realsense官方ROS包的安装1.通过源码安装intel RealSense ROS（安装和使用可参考github： https://github.com/intel-ros/realsense ）2.git或粘贴到工作空间3.编译4.测试roslaunch realsense2_camera opensource_tracking.launch 可能会出现缺少包的情况，安装即可。 出现点云数据、摄像头数据即成功。 版本：ver1.1","link":"/posts/f7f75eef/"},{"title":"docker容器签出及迁移流程","text":"项目中，在测试环境服务器中部署了docker弄了一个ollama容器，现在需要迁移到生产环境服务器。如果不想重新配置，可将测试完成的ollama容器进行打包，保存为tar文件，传输到生产服务器中，使用load加载镜像，然后运行。具体过程如下： 将容器打包成镜像 命令：docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] options选项： -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。 例如： docker commit -a cuiyuhao -m &quot;Deploy ollama&quot; ollama ollama:v1.0 完成后，使用docker images可以看见该镜像。 打包镜像 命令：docker save [OPTIONS] IMAGE [IMAGE...] 例如：docker save -o ollama_v1_0.tar ollama:v1.0。这里的ollama:v1.0是刚打包的镜像 完成后，会在当前目录生成一个tar文件 scp传输镜像文件 命令：scp [OPTIONS] PACKFILE USER@IP:TARGET_LOCATION options选项： -r :传输文件夹； 例如：scp ollama_v1_0.tar root@10.11.12.13:/home/ollama 新服务器载入镜像 命令：docker load [OPTIONS] -option选项： –input,-i 指定导入的文件 –quiet,-q 精简输出信息 如：docker load --input ollama_v1_0.tar 完成后run容器或者使用docker-compose启动即可。","link":"/posts/530cb732/"},{"title":"Ubuntu双系统、ROS、软件安装教程","text":"一、win10下安装Ubuntu16.04双系统1、制作系统U盘下载Ubuntu16.04我们首先去Ubuntu官网下一个Ubuntu16.04的iso镜像文件。 利用软碟通制作在制作系统U盘的时候我们需要去下一个软件——软碟通，这个自己去百度搜索一下应该就能出来的。下载安装完以后，我们打开软碟通的界面打开刚刚下载的iso镜像文件的路径。 将iso文件加载完以后我们点开启动下的写入硬盘硬盘映像 然后选择我们自己的U盘，然后写入就行了（最好点上刻录校验） 等待写入完成以后，我们的安装U盘就制作好了。 2、磁盘分区我们右键点击此电脑，然后点击管理就进入了管理。然后点击存储进入磁盘管理。这时候可以看看哪个盘符剩余容量较多，便压缩哪个盘符。根据自己需要，压缩出Ubuntu的空间（一般100G足够）压缩完以后我们可以看到有个空余空间，这时候我们不要给它分配盘符，默认这样就行了。 3、进入BIOS设置U盘启动设置Secure Boot这个时候我们已经可以把win10关闭了，我们点击关机，然后再开机。我们在开机的时候一直按F2，就可以进入BIOS了（大多数电脑是按F2进入BIOS,Lenovo的笔记本是按Fn+F2）。（亲测华硕、玩家国度、戴尔部分电脑是长按F2进BIOS，ESC进系统选择项）进入BIOS以后，我们就来设置一下U盘启动了，我们进入Boot，如果Boot Mode是UEFI 我们就将下面的Secure Boot 设置Disable。如果Boot Mode是Legacy 那么我们就跳过这步。特别说明：如果Acer电脑发现不能将Secure Boot 设置成Disable，就得去Security里面设置一下 Supervisor password就行了，按F12选择系统。 将USB HDD置顶弄完了上面的，再将USB HDD放到最上面（Acer 笔记本是按F5和F6来控制上升和下降的，Dell笔记本是选到USB HDD上面按下Enter然后再移动到最上面的那个启动再按下Enter将最上面硬盘启动顶下去）设置完成以后按下ESC 保存一下就行了。 新式图形化界面BIOS设置（以笔者的华硕玩家国度笔记本为例）：右侧boot priority栏中，鼠标拖动右侧三条横线即可更改默认启动顺序，插入U盘后将usb项拖动之最顶端即可。按F7进入高级设置，鼠标点击上面的security栏，找到security boot项点击进入 将secure boot control项改为Disabled。 老式界面BIOS设置：UEFI 启动Legacy启动 （能不用尽量不要用这个方法安装） 4、安装Ubuntu安装前奏我们在上面步骤完成以后，将系统U盘插入电脑。然后开启电脑，即可进入U盘安装界面了，这个时候我们选择install Ubuntu即可然后就是选择语言了，我们选择自己合适的语言就行了，我们点击安装Ubuntu接下来就是连接WiFi，安装图形界面了，能不连尽量不连，否则会很慢这里最好要把图中的‘安装第三方软件’的勾点掉好了，到了最关键的一步了，这个时候系统会提示你是否与windows 10 共存，我们不要点击那个，我们选择其他选项，这样自己方便管理一些。注意:如果系统没提示你之前安装过windows 那么你的启动方式就错误了，你得回到BIOS页面下更改启动方式再次启动现在我们来对Ubuntu进行分区，在分区之前我先介绍一下Linux的文件系统 swap：用作虚拟内存，这个要和自己的物理内存一样大/：主要用来存放Linux系统文件/boot:存放linux内核，用来引导系统的，如果是Legacy启动就要设置引导，UEFI就不用设置这个（UEFI要设置EFI文件）/usr:存放用户程序，一般在/usr/bin中存放发行版提供的程序，用户自行安装的程序默认安装到/usr/local/bin中/home:存放用户文件 我们在看磁盘信息的时候可以发现自己当初没有分配的那个空闲磁盘，选中那个空闲磁盘，然后点击+ 号，开始分配。 设置swap分配swap，我们选择主分区，空间起始位置，大小和自己物理内存一样（我的是16G我就分配16384M），用于交换空间 设置引导（下面两个根据自己启动方式选择）设置EFI引导，我们选择逻辑分区，空间起始位置，用于EFI系统分区，大小设置500M即可注意：Legacy启动的话就没有efi引导项，Legacy启动要设置boot引导（UEFI启动不要设置以下引导项）设置Boot引导，我们选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/boot，大小设置200M（这里没有图演示，但是可以根据下图类推） 设置/分区设置/，我们选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/，大小根据自己分区大小设置，我这里设置的是10G。（比如分区给Ubuntu总共100G，推荐设置20G左右） 设置home分区设置home，我们选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/home，大小的话可以根据自身情况，但是这个最好设置大一点，总共100G的话大概分40G。（根据usr类推） 设置usr分区设置usr，我们选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/usr，大小的话剩余的空间就都给它了。 安装终章设置完所有以后，我们要将下面的安装启动器设备换成我们刚刚设置引导的那个盘UEFI引导类型就是efi，legacy引导挂载点就是/boot，设备号一定要对应（比如图中设备号为sda12），再三检查此项！！！！！然后出现这个，我们点继续就行了然后就是设置地方，语言和姓名以及密码。（密码尽量短，能一个字符就别两个，否则到时候用起来很麻烦，装好系统之后计算机名和用户名千万不可以改动！！）设置完以后我们等待安装就行了。 5、默认启动项设置安装完成后，会默认进入UBUNTU系统。如果要设置成默认进入windows系统，开机长按ESC进入Ubuntu的话，进入BIOS，将windows boot manager设置为第一选项。开机立即按住ESC键（不同的笔记本可能不同），进入系统选择项，按键盘上下键即可选择系统。 6、Ubuntu修改启动项等待时间1sudo gedit /etc/default/grub 找到GRUB_TIMEOUT=10那一行，这里的10就是等待的时间，按照自己的需要更改即可，我改成了1。然后保存退出，然后执行下一句命令使修改生效： 1sudo update-grub 7、Ubuntu、windows时间不统一修复新版本的Ubuntu使用systemd启动之后，时间也改成了由timedatectl来管理，此方法就不适用了。 1sudo timedatectl set-local-rtc 1 重启完成将硬件时间UTC改为CST，双系统时间保持一致。 先在ubuntu下更新一下时间，确保时间无误： 12sudo apt-get install ntpdatesudo ntpdate time.windows.com 然后将时间更新到硬件上： 1sudo hwclock --localtime --systohc 重新进入windows10，时间恢复正常了 二、ROS安装教程Ubuntu的一些小指令： 1234567Ctrl +alt + t //打开控制终端ctrl +shift + c //复制控制终端中的文字快的捷按键ctrl +shift + v //把文字粘贴至控制终端中的快捷按键sudo apt-get install +文件名 //下载文件sudo gedit+文件名 //编辑文件内容sudo dpkg –i //解压并安装压缩文件sudo apt update //更新文件 1、开源：（顺序为先开源再配置zsh再安装ros，）打开一个控制台（Ctrl＋Alt＋T），输入如下指令 1234$ sudo sh -c 'echo &quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list'//设置秘钥$ sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 0xB01FA116 2、安装On my zsh：参考网址：https://blog.csdn.net/hsd2012/article/details/54292192安装oh my zsh之前要先安装git 和zsh打开终端，输入： 12345678910 sudo apt-get install git//（安装git） sudo apt-get install zsh//（安装zsh） curl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh//（从网络源上获取oh my zsh） cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc//（创建配置文件） chsh -s /bin/zsh//（将zsh作为默认工具，替代原来默认的bash） 重启电脑，zsh就可以使用了！Zsh比默认的bash的好处在于，按一下tab补全命令，按双击tab出现备选项，方便使用 3.安装ROS首先确保系统软件处于最新版 1$ sudo apt-get update 然后我们就可以安装ROS了（此处安装的是至尊豪华全功能版） 1$ sudo apt-get install ros-kinetic-desktop-full 完成后，用以下指令来查看可使用的包： 1$ apt-cache search ros-kinetic 4.初始化ROS首先，初始化rosdep 12$ sudo rosdep init$ rosdep update 然后初始化环境变量：（注意是zshrc而不是bashrc） 12$ echo &quot;source /opt/ros/kinetic/setup.zsh&quot; &gt;&gt; ~/.zshrc$ source ~/.zshrc 最后，安装一个非常有用的插件： 1$ sudo apt-get install python-rosinstall 5、测试ROS1$ roscore 显示 started core service [/rosout] 了没有？如果没问题，恭喜你成功了。 三、Ubuntu中一些实用程序的安装1、 搜狗输入法1、下载文件打开官网 http://pinyin.sogou.com/linux ，点击自己对应的系统位数安装包，然后下载。 2、打开安装目录，调出终端。1sudo dpkg -i sogoupinyin_2.1.0.00826_amd64.deb （后面的是自己的安装包命令，更新了就和我的不一样了，如果出现安装出错，就重复该命令安装几次直到成功） 1sudo apt-get install -f 3、设置打开“系统设置“，点击”语言支持“，然后弹出下面的框图，点击”安装“。然后输入密码什么的，等一会儿就好 4、然后把里面的IBus改为fcitx，然后关掉，然后重启电脑。 5、重启电脑后，会看到屏幕右上角有企鹅输入fcitx。 6、然后右键点开，选择ConfigureFcitx。 7、然后点击弹出的框的左下方的”+“号，添加搜狗输入法，去掉那个只“显示当前语言”的选项，然后搜索框输入sog，你会发现搜狗输入法已经有了，选中输入法即可，然后关闭。 使用shift进行中英文切换 2、标题栏实时显示上下行网速、CPU及内存使用率终端执行以下命令 123456sudo add-apt-repository ppa:fossfreedom/indicator-sysmonitor//这里选择按enter键 sudo apt-get update sudo apt-get install indicator-sysmonitor //启动 indicator-sysmonitor &amp; //ctrl+c后台运行该程序 勾上Run on startup:， 这样就能开机启动了。切换到 Advanced 选项，可以对要显示的信息的格式进行设置。可以尝试设置其他格式，再Test，直到效果满意再点击保存。 3、网易云音乐1：先去官网下载最新版本的网易云http://music.163.com/#/download2：执行命令： sudo dpkg -i //（后接官网下载的软件包名） 3：如果报错了 ，执行以下命令 sudo apt-get -f install 4、安装显卡驱动要安装英伟达独立显卡驱动，按键盘上的windows键，输入‘fuj’找到附加驱动，选中第一个专有类型的显卡驱动，点击确定等待安装完成。 附录：版本信息版本：ver1.1整理撰写：cyhasuka","link":"/posts/f9549b06/"},{"title":"WiFi 6终章？ROG旗舰万兆路由GT-AX11000Pro开箱评测","text":"1、前言2022年10月19日，华硕发布了ROG GT-AX11000 Pro，京东实际到手价 3499 元。作为ROG玩家国度顶级路由器八爪鱼的最新款，华硕这款AX11000Pro已经是目前硬路由颜值+性能天花板。上一次体验华硕的八爪鱼还是华硕RT- AC5300，但可惜随着WiFi 6的降临，被后来的AX86U薄纱，这一次终于有机会可以再次用上最新款的八爪鱼。 ROG Rapture GT-AX11000 Pro 可以说是华硕三年多前推出的GT-AX11000的升级版。如果说后者是华硕进军Wi-Fi 6的第一步，那么这款GT-AX11000 Pro就是ROG玩家国度的三频路由器在Wi-Fi 6标准中的终极形态(目前国内Wi-Fi 7标准上线还是遥遥无期，而Wi-Fi 6E的6GHz频段未开放，估计近几年相应的设备支持也很难出现)。 2、简介因为文章比较长，在开头先简要介绍一下硬件配置。 此次的ROG GT-AX11000 Pro升级SoC到博通BCM4912，网络接口方面搭载1个万兆10G电口（自适应2.5G/1G，可配置WAN/LAN口）、一个2.5G/1G WAN口、4个千兆LAN口。另外搭载1个USB3.0、1个USB2.0接口。标配65瓦电源适配器。 上面前言里提到，这款ROG玩家国度的三频路由器是Wi-Fi 6标准中的终极形态。这是因为GT-AX11000 Pro支持5GHz频谱的最后一部分，即UNII-4 band。UNII-4也被称为5.9 GHz频段，是从802.11ax/WiFi 6频段的延伸，但它与6GHz频段的WiFi 6E无关。UNII-4共增加四个20MHz的Wi-Fi信道，关键是允许第三个160MHz宽的信道，在信号拥挤的地方可能会带来极大的便利。但可惜的是，目前，UNII-4只能在美国使用，国内此频段暂时还未开放给民用无线设备，也没有相应的设备可以使用这一频段。 目前支持UNII-4频段的路由器主要有下面几款： 华硕 ROG GT-AX11000 Pro (三频) 华硕 ZenWiFi Pro XT12 (三频) 华硕 ZenWifi XT9、XT8 (三频) 群辉 SynologyRT6600ax (三频) 群辉 Synology WRX560 (双频) 下面贴一张5GHz频段图，供大家参考。 3、外观一个字：大！ 毫不夸张的说，这款大眼睛摆在客厅电视柜，绝对是吸睛一步到位了（之前RT-AC5300八爪鱼放在客厅，亲戚朋友来都要先瞅上两眼哈哈） 长：约35.5cm 宽：约35.5cm 高（如下图，天线竖直）：约19cm 高（主机本体）：约6cm RT/GT-AC5300有一个小问题，就是他们的可拆卸式天线真的非常非常容易松动，用久了不小心碰一下就会倒。而可拆卸式的设计意义不大（起码是对我来说，毕竟谁天天没事拆天线嘞） 这次GT-AX11000 Pro的设计师显然也意识到这一问题。不可拆卸式的天线非常牢固，彻底解决了倒的问题。这一点绝对给好评。天线角度可调，并且方向可以左右旋转近180°。 硕大的ROG败家之眼Logo由数个小的“ROG”字符填满，外围边缘也可以RGB联动，夜晚下十分迷人。 网络接口方面搭载1个万兆10G电口（自适应2.5G/1G，可配置WAN/LAN口）、一个2.5G/1G WAN口、4个千兆LAN口。 有一点美中不足的是，当前官方固件、梅林固件均无法将2.5G WAN口设置为LAN口，对于目前的家庭千兆网络环境来说可能无法将其充分利用。如果能设置LAN1-4其中一个当做连接外网的WAN口，2.5G当做内网端口与NAS通信就好了。 电源接口、电源键（白点按下为开机）、两个USB 接口特写。下面章节中实测USB3.0读速高达230MB/s。 WPS、LED按钮特写。其中LED按钮在路由器后台可以自定义功能，包括游戏加速、DFS模式、LED开关、Aura神光同步等功能。 指示灯特写，其中10GE指示灯可以显示万兆端口状态，包括是否启用及数据吞吐等。 边角的散热孔旁有一个三角形切角设计，凹刻了三角形的logo 路由器底部大面积镂空设计，配合内部散热片有效散热。三角形、梯形的两块大型硅胶脚垫将路由器底部抬高，使空气对流，辅助散热。 铭牌特写，输入19.5V-3.33A 或 19V-3.42A。 标配充电器来自康舒科技，输入宽幅100-240V 1.7A 50-60Hz，输出+19.5V-3.33A。最大输出功率65W。 实测平均待机运行时功率及耗电量： 灯光关闭：约12W 每日用电约0.28度 灯光开启：约14W 每日用电约0.33度 包装内附说明书 4、硬件 4.1、硬件拓扑 SoC：BCM4912，4核心ARM Cortex A53 CPU，16nm工艺，2.0GHz主频 RAM：DDR4 1024MB FLASH：256MB PHY：10G PHY为BCM84891L 2.4G：BCM6715，FEM为SKY85331-11 5G1：BCM6715，FEM为SKY85743 5G2：BCM6715，FEM为SKY85743 下面硬件示意图供参考。 4.2、散热路由器整体采用被动散热，包括信号放大器在内的基本所有芯片均覆盖导热硅胶垫，使用铝制散热片辅助散热。 实际测试，运行一周时间，主SoC温度在50度左右，2.4G、5G温度在45度左右。（室内环境温度为21度，湿度35%） 4.3、端口1个2.5G WAN口，1个10GbE端口，4个千兆LAN口，1个USB3.0接口，1个USB2.0接口。 5、固件 5.1、华硕官方固件官方固件继承了ROG路由器一贯的风格，仪表板显示基本的无线状态、WAN IP、网络流量、游戏探测雷达、Aura RGB、LED按键绑定等功能。 三段电竞加速功能 电竞加速功能可以为游戏设备到服务器每一阶段提供可靠连接，其中一个5G频段在开启电竞模式后提供专属通道，最大程度保证游戏时连接质量。对于ROG设备有着ROG First最高优先级，配合游戏封包优化，可以给ROG玩家带来前所未有的流畅游戏延迟。且路由器内置网易UU加速器，可以轻松为PS5、Xbox、Switch等主机提供加速。对于手机设备，手机下载ASUS ROUTER app或者电脑路由页面即可开启电竞模式，提高设备优先级，最大程度降低ping值和丢包率。 游戏探测雷达功能，提供游戏服务器ping功能，寻找最优区服。 总体而言，对于一般没有特殊需求的用户，华硕官方固件功能已经足够强大，满足日常所需绰绰有余。 5.2、梅林固件由于华硕路由器开源了Asuswrt，梅林固件的开发者Eric Sauvageau（RMerl） 在此基础之上，开发了Asuswrt-Merlin 系统 ，主要目标是增强现有的Asuswrt固件，并修复一些已知的问题和限制，同时保持与原始固件相同的性能水平。此外，梅林固件支持很多新功能， 比如用户脚本，Cron定时任务，自定义路由配置文件，大容量硬盘，调整WiFi功率，软件中心 等等， 具体的可以去项目官网了解。 国内比较常见的梅林固件是KoolShare基于原版梅林固件改造过的（现在叫KoolCenter），其搭载的软件中心插件功能比较强大，进阶用户可以从中找到自己需要的网络工具。 此次刷机的固件为KoolCenter 2022年12月9日发布的梅林388.1_0版本。388版本固件官方较大的更新就是引入了wireguard支持，梅林388固件同样支持wg，但是还是以openvpn为主。 仪表板等布局基本相同，左上角的Powered by Asuswrt-Merlin 表明了固件身份。 插件WiFi Radar，可以探测路由器周围网络环境，查找周围所有的WiFi网络，显示信号干扰以便用户找到最佳信道，提升网络稳定性。 可以看出家里网络环境还是很好的，周围没有信号干扰的情况。 KoolShare梅林固件的软件中心页面，提供了很多实用的网络工具以及小插件，包括签到、搭建家用NAS及个人网站常用的内网穿透等等，有需要可以自行下载，傻瓜式操作。 6、性能测试 6.1、外网测试介绍一下家里的宽带环境。光纤入户，由光猫光电转换后使用路由器拨号。联通网络，签约上行1000Mbps，下行100Mbps，山东青岛地区。 首先，测试路由器无遮挡覆盖。为了更加接近实际应用场景，采用宽带测速而非信号强度测试，对大多数人来说结果更为直观。 使用10米6类网线将路由器延长放置于窗口（无玻璃等任何遮挡），按距离测试网速。可以看出，澳大利亚区在短距离和长距离都有优势，在中长距离会存在一定的弱势。但总体来说，5G频段有如此表现已经可圈可点，已经位于第一梯队，WiFi 6的波束成形等相关技术的应用也为长距离的测速表现提供了很好的帮助。 WAN口：2.5G（实际与光猫握手速率1G） 路由器地区：澳大利亚 连接频段：5G1 160MHz 测速设备：ROG 幻14 Win11 电池供电（更换网卡为Intel AX210） 测速软件：Speedtest 6.2、内网测试内网测试环境，有线连接使用7类网线连接PC端，统一使用万兆PCIE网卡连接路由器（网卡支持10G/2.5G/1G自动协商）。无线连接测试仍然使用ROG 幻14（网卡Intel AX210），距离路由器1.5米，无遮挡。 内网环境中，路由器基本可以跑满端口速率。特别的，在30分钟压力测试下，端口速率也没有明显掉速情况出现，稳定性还是不错的。 室内无线覆盖测试，为防止内网设备对测速结果造成瓶颈，使用绿联DX4600 NAS双2.5G链路聚合组成5G速率，调用其中固态硬盘PM981A进行读写测试。具体连接情况为：路由器10G端口连接万兆交换机，交换机端将NAS双2.5G链路聚合。 测试结果，路由器无遮挡的客厅网络环境最好，基本能达到满速率运行。而卫生间由于间隔一堵承重墙、一堵非承重墙，信号有所衰减，但对于实际上网体验来说仍然满足基本需求。 6.3、USB测试测试环境：使用固态U盘测试，文件系统为NTFS。测试时关闭路由器2.4G无线网络。分别测试万兆端口及两个5G频段下读取USB设备的速率。 7、体验总结作为ROG在国内发售的顶级路由器，功能非常齐全，支持AiMesh2.0、双线路接入、端口聚合等功能，SoC方面支持博通新一代Rangeboost Plus技术，智能识别干扰。而2.5G WAN口配合10GbE端口属于战未来的配置，对于现今的宽带环境而言，2.5G WAN口对于一般家庭来说意义有限，如果后期固件更新可以支持将其设置为LAN口，对于内网的使用体验来说反而会更好。 对于我个人的整体使用体验，之前家里使用的是AX86U(主)+AC5300(AiMesh节点)的组合。家中购置了绿联DX4600 NAS后，其搭载双2.5G网口，可以通过链路聚合组成5G速率。但AX86U仅有一个2.5G网口，无法充分发挥NAS的性能。并且当家中NAS高负载下载使用时，AiMesh连接到AC5300会偶发性的存在掉速甚至断联的情况。而且AC5300由于年代较为久远，内部硅胶垫存在老化的情况，虽然进行了更换，但发热仍然较为严重，我甚至加装了风扇来缓解发热的问题。 这些问题随着GT-AX11000Pro的到来迎刃而解。虽然都是八爪鱼，但这款相较于我之前的老款AC5300八爪鱼提升非常大，尤其是稳定性以及端口丰富性。搭载的万兆网口给内网环境增添了更多可玩性，同时搭配梅林固件应用中心的插件，搭建个人网站、私有云更加方便，给家庭娱乐系统提供了稳定的硬件支持。而无线覆盖面积对于我个人而言较为次要，GT-AX11000Pro(主)+ AX86U (AiMesh节点)的组合已经可以满足绝大部分家庭需求。对于极致玩家，搭配万兆交换机构建万兆内网环境也是一种很好的选择。","link":"/posts/727a344e/"},{"title":"ubuntu开机弹出系统程序出现问题解决方法","text":"开机提示:检测到系统程序出现问题修改方法： 打开终端，输入 1sudo gedit /etc/default/apport 把enabled=1改成enabled=0原理： 关闭系统自动检测 问题解决。","link":"/posts/9a7bc0ac/"},{"title":"三防铠甲，坚若磐石-华硕TUF Gaming铠甲固态硬盘盒体验评测","text":"今年十月初，华硕旗下的TUF 推出了自家的T1A铠甲三防移动硬盘盒，补齐了TUF硬盘盒分支的产品线。与之前ROG推出的硬盘盒相比，TUF此款硬盘盒在保证优秀性能的同时，主打三防功能，同市面上的各类硬盘盒产品做出了差异化，形成了互补。前两天拿到这款产品，通过拆解评测一下这款产品的做工及性能。 1. 参数介绍此款TUF硬盘盒支持USB3.2 Gen2接口的带宽规格，最大顺序读写速度均为10Gbps，也即1000MB/S上下。同时支持Nvme与SATA两种协议的M.2固态硬盘。这里需要提醒一下，使用SATA协议的M.2固态的话，由于SATA协议先天的性能限制，最高顺序读写速度只能达到6Gbps。使用Q-LATCH 免工具卡扣便于拆卸，并且通过MIL-STD-810H军工测试，具备IP68防尘防水属性，最大限度保证数据安全。 2. 开箱篇硬盘盒包装采用书本式翻盖设计，打开包装即可看到快速安装手册、说明书、保卡。 包装内部除硬盘盒本体及USB-A转USB-C数据线外，另附送一根六角扳手用于拆卸硬盘盒外壳。 硬盘盒外观非常硬朗，纯金属外壳棱角分明，扎实的铝坨坨本体重达142g，握在手里十分压手，分量十足。表面为磨砂材质，自带钥匙扣设计。与ROG不同，TUF这款硬盘盒没有采用RGB灯效，只在顶部有一枚显示工作状态的柔光LED指示灯。 硬盘盒背面印有TUF GAMING的产品logo，底壳同样为纯金属材质，由4颗黑色内六角螺丝进行固定。此种方式相比卡扣及常见的推拉式结构更加可靠，搭配胶圈同时也保证了防水性能。 3. 拆解篇拧下四颗螺丝便可以看到硬盘盒PCB本体。内部采用台阶式设计，搭配黑色防尘防水胶圈，以呈现出色的防水性能。硬盘盒外壳出厂已贴好导热硅胶垫，配合厚实的壳体对硬盘进行散热。 继续拆解。拧下4颗固定PCB板的十字螺丝，取下PCB。可以看到硬盘盒采用瑞昱RTL9210B，NVME、SATA双协议主控芯片。此前该芯片固件曾存在bug，即使安全弹出也会导致硬盘不安全关机次数增加。现在厂商已经更新固件，之前的问题已经得到解决，大家可以放心使用。 大家或许已经注意到，不知何种原因小螃蟹主控出厂并未覆盖硅胶导热贴。此款主控虽然温度控制比较优秀，但放着这么厚实的散热外壳不用似乎有些可惜。我自行添加了一块厚度为1mm的散热硅胶贴，供动手能力强的小伙伴参考。 防水USB-C接口特写，接口端子相较普通USB-C母口较短，在外层添加了防水橡胶圈，可以更好的应对极端环境。 Q-LATCH 免工具卡扣特写，相较往常的螺丝固定及橡胶塞固定，这种最新研发的卡扣结构更加便于对硬盘进行更换拆卸，只需旋转即可，十分方便，给大大的好评。硬盘盒支持2242、2260、2280不同长度。 4. 测试篇上机，使用CrystalDiskMark进行理论测试，这款软件默认显示读写测试结果的峰值，可以看到顺序读写速度基本达到了10G带宽理论上限。 NVME硬盘采用三星980Pro 1TB测试，持续读取速度为：1057.71MB/s 持续写入速度为：1046.88MB/s。 SATA硬盘采用三星PM871a 512GB测试，持续读取速度为：540.85MB/s 持续写入速度为：520.66MB/s，达到SATA标称的6Gbps速度。 从性能测试来看TUF 硬盘盒已经达到接口标称性能，也非常稳定，没有出现断联、无速度等情况。 5. 总结篇华硕TUF Gaming铠甲是一款优秀的移动硬盘盒，虽然价格略贵，但对IP68+MIL-STD-810H认证的三防能力有要求的用户而言物超所值，即使在恶劣工况下也能坚固耐用、持久稳定，在保证了数据传输性能的同时不用担心数据安全问题。","link":"/posts/5dcb1f53/"},{"title":"根据LLM参数量估算显存&#x2F;内存占用","text":"✨ Tips：文中“显存”指GPU可使用的内存空间，如有SoC使用Unified Memory(如Apple M1~M3系列、Nvidia AGX Orin等)则可简单理解为系统内存。 推理显存对于一个70亿参数（7B）的模型，以 qwen2-7B 为例，预计需要的显存需求如下： FP32浮点精度：28GB BF16精度：14GB int8精度：7GB 虽然其他因素也在占用显存，但推理期间使用显存的主要是参数量。 比如，qwen2-7B-BF16 模型需要的显存等于参数数量乘以类型大小：70亿参数 x 2字节 = 140亿字节。因此，140亿字节 = 14 x 1,000 x 1,000 x 1,000 / 1024 / 1024 / 1024 ≈ 13 GB（考虑1000/1024）³ ≈ 0.93。 注1：(1000/1024)³ ≈ 0.93，为了估算目的，简单地将此比率视为1。 注2：对于7B-BF16模型，显存需求大约是7 x 2 = 14 GB。上述估算略高于精确计算，但更实用，因为推理需要超出参数之外的额外内存。 假设要估算llama2-13B模型的显存需求，对应各种类型的分别是：float：13 x 4 = 52 GB，half/BF16：13 x 2 = 26 GB，int8：13 GB，int4：13 x 0.5 = 6.5 GB 常用模型参数量-显存占用估计统计如下表： 精度&显存占用量(估计值) 例子(实际值) 32bit(FP32) 16bit(FP16/BF16) 8bit(int8) 4bit(int4) 参数量 1 4byte 2byte 1byte 0.5byte 1B 4GB 2GB 1GB 0.5GB 2B 8GB 4GB 2GB 1GB Gemma_2B_4bit_1.4GB 7B 28GB 14GB 7GB 3.5GB Llama2_7B_4bit_3.8GB Mistral_7B_4bit_4.1GB 13B 52GB 26GB 13GB 6.5GB Llama2_13B_4bit_7.3GB 32B 128GB 64GB 32GB 16GB Qwen1.5_32B 32bit@120GB 16bit@60GB 4bit@15GB 70B 280GB 140GB 70GB 35GB Llama2_70B_4bit_39GB 130B 720GB 360GB 180GB 90GB Falcon_180B_16bit_360GB+ 训练显存由于反向传播、Adam优化和Transformer架构等因素，保守估计，训练所需的显存是具有相同参数数量和类型的推理显存的四倍（1x 为模型，1x 为梯度，1~2x 为优化器¹）。 注1：使用AdamW优化器，显存需求为2x；使用SGD优化器，显存需求为1x 为了确保训练期间模型收敛，参数类型一般不能是int8或int4。通常使用FP32或量化到BF16。例如，使用浮点精度FP32训练一个7B模型大约需要112GB（28GB x 4）。 假设要训练Qwen2-7B模型，估算所需的显存： 对于float类型：7（10亿参数）x 4（float的字节数）x 4 = 112 GB Adam优化实际占用为109.8GB 对于half/BF16类型参数：7（10亿参数）x 2（每个BF16参数字节数）x 4 = 56 GB Adam优化实际占用为54.88GB 可以看到，估算的显存与实际显存占用相近，实际情况中一般需要预留5%以上的显存空间供其他模块使用，所以估算值略大是合理的。 使用LoRA/QloRA技术的显存使用情况，以LoRA为例： LoRA涉及在原始模型上运行推理并训练一个较小的模型，以实现与训练原始参数几乎相同的效果。 例如，如果需要微调大小为1024x512的参数，使用LoRA并选择Rank为8，只需要微调以下数量的参数：1024x8 + 512x8。 这个过程需要使用原始参数量运行一次推理（不需要梯度和优化器状态），但在计算过程中仍需要一些显存来存储数据。总显存使用量是这些需求的总和。","link":"/posts/c87c0f5d/"},{"title":"解决hexo博客不能显示图床图片问题","text":"刚搭建好了hexo博客，写了一篇带图的文章，结果发现图挂了…之前看博客扫到hexo博客显示本地图片可能会有问题，于是选了图床图片的方式插图，结果还是没能幸免，好在搜索了半天，解决了这个问题，这里做个记录，帮助后面遇到问题的同学。 解决方案：问题情境：在自己电脑的Chrome浏览器查看博客，正常显示图片，切换到Safari、火狐浏览器图片挂了。 手机端各浏览器均显示不了图片。 解决步骤： 分析 检查图床图片的链接： 点进去发现图片正常显示，排除图床服务器问题。 用Chrome打开博文，右键检查或者查看网页源码： 找到图床图片链接，点击发生403(Forbidden)错误，找到问题根源。 解决 403 forbidden，说明了这个网络资源这样获取是被拒绝的，那么通过简单的谷歌，找到了相关的解决方法，并去实际尝试： 解决方法 ：只需要在markdown文章开头添加一个&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt; 然后就是hexo clean &amp;&amp; hexo g &amp;&amp; hexo d上传博客了，这一次分别在电脑和手机端打开文章，图片显示正常，问题解决。 原理解析：为了不做一个只会搬运的码农，这里简单讲解一下原理： HTML的 标签提供了 HTML 文档的元数据。元数据不会显示在客户端，但是会被浏览器解析。这也是为什么加在mardown文章里不会看到这段代码的原因。 HTML 的 name 属性规定了元数据的名称，这里我们用到的是referer属性，这个属性的作用是让服务器判断来源页面，即用户是从哪来的，很多时候referer被当做防盗链来使用，服务器根据你的访问来源判断是否应该让你下载这个资源，如果你的来源不和规范，比如是个恶意爬虫，那么就会产生403错误。 到这里，content=&quot;no-referrer&quot;的意义就呼之欲出了，既然我们想拿到这个资源但被服务器认出来之后又被拒绝了，那么伪装一下，不告诉服务器不就行了？所以，这里content的no-referer就是表示不发送引用数据，隐藏自己的来源信息。这样，图片就能正常显示了。 参考 https://newsn.net/say/referer-policy.html Hexo使用细节及各种问题 - Selier - 博客园","link":"/posts/9d5b9135/"},{"title":"手感、颜值、性能兼具？ROG月刃AimPoint月耀白拆解评测","text":"近年来随着传感器技术的飞速发展，鼠标传感器的扫描精度DPI从800,3200一路飙升。这次华硕ROG发布的月刃无线鼠标搭载了自研的AimPoint旗舰传感器，DPI达到了恐怖的36000，加速度可达50G、IPS 更是高达650。可能有很多人不理解，这么高的DPI有什么作用？没有人真的会用这么高的DPI工作或者打游戏吧？其实DPI代表的是鼠标每移动1英寸时鼠标指针在显示器上移动的像素点。AimPoint传感器的36000DPI，意味着其可以在一英寸的距离内检测到36000个点的数据。随着传感器接收到数据样本容量的提升，其读取精度和识别分辨率要比那些低DPI上限的鼠标更高。 就本体参数而言，其采用不会打油的PBT材质按键、热插拔微动、75g的轻量化设计、第一梯队的传感器，毫无疑问这是一款诚意满满的产品。 可以看到，ROG为月刃AimPoint提供了丰富的配件。包括2.4G接收器&amp;伞绳充电延长线、3Pin 欧姆龙灰点微动2（日产欧姆龙，1000万次点击寿命）、PTFE特氟龙脚贴4、橡胶防滑贴、ROG贴纸。 四款鼠标对比，从左到右分别是罗技G903、GPW、ROG 月刃有线版和月刃无线AimPoint月耀白。其中，ROG两款鼠标模具基本相同，手感保持在相同水平。这里特别表扬一下ROG的细节处理，PBT按键和附送的按键防滑贴很得我心意。在游戏操作中，GPW鼠标按键的ABS材质的会打油，使我迫不得已贴上了按键防滑贴（蜥蜴皮）。这次ROG居然直接送，点个赞 说一下手感体验。之前我是GPW用户，由GPW换为月刃无线AimPoint之后竟然没有感到不适。毕竟GPW是左右手通用鼠标，月刃无线AimPoint为右手专用，模具的不同并没有为我带来游戏操作上漫长的适应期。GPW一代重量为80克，GPW二代为63克，这款月刃无线AimPoint鼠标重量在二者之间，为75克（实测去除接收器73克）。下面是两鼠标使用手型对比。 下面要特别提一个小细节，对于游戏玩家来说，我们希望无线鼠标延迟要足够低，并且要防止不必要的干扰。所以大家可能会把接收器用延长线的形式放置于桌面。但是这样存在一个问题，延长线无法在桌面上固定，接收器随意摆放非常不美观。ROG的设计师同样考虑到这一问题，在接收器延长模块背面安装了一个金属夹，可以轻松的夹到鼠标垫上，防止接收器在桌面移动。 接收器固定到鼠标垫，简洁美观。 展示部分就到这里，下面来到今天的重头戏—拆解。 将鼠标底部两个硅胶塞取下，卸下两颗十字螺丝即可打开外壳。可以看到，ROG的设计师在轻量化上下了很大的功夫。鼠标上壳在保证强度的同时采用蜂窝结构，降低重量。而滚轮支撑部分也同样采用Z字型结构，尽可能少的使用不必要的塑料材质。而由于考虑到玩家们会时常拆解鼠标更换微动等配件，ROG采用预埋铜柱的方式防止螺丝滑丝，属于细节拉满。 其采用了一块容量为370mah的聚合物锂电池，供应商来自杭州金色能源。官方最大续航时间为蓝牙149小时，2.4G 119小时。 ROG自研微动特写，采用红色透明外壳设计，印有ROG logo。寿命为70M（7000万次点击）。手感清脆，个人使用体验感觉类似欧姆龙蓝点（仅供参考）。微动支持插拔更换。 请注意，普通玩家拆解到上面就已经可以满足更换微动的需求，非专业人员不建议继续拆解，可能会造成未知损害。 卸下主板，主板采用沉金工艺以实现更好的电气连接性能，不易氧化，可以提升PCB稳定性，中间的长方形芯片即为AimPoint 36K传感器。从传感器纸面数据可以看到，华硕这枚自研的AimPoint 36K传感器无论是DPI追踪精准度还是DPI的偏差值都非常的优秀，甚至在36000DPI下偏差值只有0.3%，是当之无愧的旗舰传感器。 靠近侧键微动的正方形芯片为来自nordic semi的SoC，型号为nRF52840。nRF52840基于带有浮点单元的32位ARM® Cortex™-M4 CPU，片内搭载1 MB 闪存 + 256 KB RAM，主频为64 MHz。支持2.4G、Bluetooth 5及蓝牙低功耗(BLE)，并通过精密的片上自适应电源管理系统，实现了极低的片上功耗，可以有效提升鼠标续航。特别的，芯片内部搭载了华硕这次全新升级的SpeedNova无线通信协议，针对低延迟优化。 PCB背面，可以看到AimPoint 36K传感器背面、模式切换开关及DPI和蓝牙配对开关。 底部的微动PCB小板采用12pin排座的形式与主板连接，搭载微动插拔座及type-c接口。不难看到，鼠标底壳也采用了较多加强筋的形式，在降低外壳厚度的同时提升强度。 拆解完成，对鼠标内部相关元件进行称重。鼠标底壳16g；鼠标上盖27g；滚轮2g；黑色电池架2g；电池7g；主板+背面按键16g；微动0.5g（两枚共1g）；螺丝&amp;硅胶塞2g。共计73克。对于极致减重玩家，不更改上盖与底壳的前提下，去掉电池架及螺丝硅胶塞，这款鼠标最轻可以降到69g。 ROG虽然在硬件圈子里是败家之眼，但是在外设圈子里，ROG真的是名副其实的卷王。不仅推新速度极快，性价比也非常的高，针对玩家赠送的配件同样十分齐全，让你不再需要购买鼠标后还需要在脚垫、贴纸上花费额外的心思（毕竟单买一套高端特氟龙脚贴也要二三十，蜥蜴皮防滑贴也需二三十）。 总的来看，ROG月刃无线AimPoint鼠标在沿用了ROG鼠标外观设计的基础上，加入了AimPoint 36K光学传感器，让这款鼠标拥有更高的配置；借助奥创软件，用户还能对鼠标进行自定义设置；轻量化以及符合人体工学的设计，则让其操作起来更为舒适，以往的GPW玩家也可以轻松上手。对电竞玩家而言，手感、颜值、性能兼具，这的确是一款值得入手的游戏鼠标。","link":"/posts/21f2167c/"},{"title":"高速下载 HuggingFace大模型（支持断点续传、多线程）","text":"特性 ⏯️ 从断点恢复：可随时重新运行或按 Ctrl+C ，再次执行脚本时下载恢复到断点状态。 🚀 多线程下载：利用多线程加快下载进程。 📦 轻量化：仅依赖git , aria2c/wget 。 基本命令：1./hf-downloader.sh *HF_Repo_ID* --tool aria2c -x 16 如果没有安装或条件不允许安装 Aria2 ，则可以切换到用 wget（不支持多线程）： 1./hf-downloader.sh *HF_Repo_ID* --tool wget 使用方法：完整拷贝 文末代码 到hf-downloader.sh,赋权： 1chmod a+x hf-downloader.sh 设置镜像端点的环境变量，或直接将其加入bash文件中： 1export HF_ENDPOINT=&quot;https://hf-mirror.com&quot; 正常执行脚本即可。例： 1./hf-downloader.sh Qwen/Qwen2-7B-Instruct --tool aria2c -x 16 备注： 参数-x是 aria2 的线程数量，默认为4，最大为16。 如果模型下载需要登录HF账号，需先获取 huggingface token ,然后下方填写用户名和token，如： 1./hf-downloader.sh Qwen/Qwen2-7B-Instruct --hf_username YOUR_HF_USERNAME(NOT_EMAIL) --hf_token YOUR_HF_TOKEN 下载模型时排除某些文件（如.safetensors）： 1./hf-downloader.sh Qwen/Qwen2-7B-Instruct --exclude *.safetensors huggingface-downloader 脚本代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193#!/usr/bin/env bash# Color definitionsRED='\\033[0;31m'GREEN='\\033[0;32m'YELLOW='\\033[1;33m'NC='\\033[0m' # No Colortrap 'printf &quot;${YELLOW}\\nDownload interrupted. If you re-run the command, you can resume the download from the breakpoint.\\n${NC}&quot;; exit 1' INTdisplay_help() { cat &lt;&lt; EOFUsage: hfd &lt;repo_id&gt; [--include include_pattern1 include_pattern2 ...] [--exclude exclude_pattern1 exclude_pattern2 ...] [--hf_username username] [--hf_token token] [--tool aria2c|wget] [-x threads] [--dataset] [--local-dir path] Description: Downloads a model or dataset from Hugging Face using the provided repo ID.Parameters: repo_id The Hugging Face repo ID in the format 'org/repo_name'. --include (Optional) Flag to specify string patterns to include files for downloading. Supports multiple patterns. --exclude (Optional) Flag to specify string patterns to exclude files from downloading. Supports multiple patterns. include/exclude_pattern The patterns to match against filenames, supports wildcard characters. e.g., '--exclude *.safetensor *.txt', '--include vae/*'. --hf_username (Optional) Hugging Face username for authentication. **NOT EMAIL**. --hf_token (Optional) Hugging Face token for authentication. --tool (Optional) Download tool to use. Can be aria2c (default) or wget. -x (Optional) Number of download threads for aria2c. Defaults to 4. --dataset (Optional) Flag to indicate downloading a dataset. --local-dir (Optional) Local directory path where the model or dataset will be stored.Example: hfd bigscience/bloom-560m --exclude *.safetensors hfd meta-llama/Llama-2-7b --hf_username myuser --hf_token mytoken -x 4 hfd lavita/medical-qa-shared-task-v1-toy --datasetEOF exit 1}MODEL_ID=$1shift# Default valuesTOOL=&quot;aria2c&quot;THREADS=4HF_ENDPOINT=${HF_ENDPOINT:-&quot;https://huggingface.co&quot;}INCLUDE_PATTERNS=()EXCLUDE_PATTERNS=()while [[ $# -gt 0 ]]; do case $1 in --include) shift while [[ $# -gt 0 &amp;&amp; ! $1 =~ ^-- ]]; do INCLUDE_PATTERNS+=(&quot;$1&quot;) shift done ;; --exclude) shift while [[ $# -gt 0 &amp;&amp; ! $1 =~ ^-- ]]; do EXCLUDE_PATTERNS+=(&quot;$1&quot;) shift done ;; --hf_username) HF_USERNAME=&quot;$2&quot;; shift 2 ;; --hf_token) HF_TOKEN=&quot;$2&quot;; shift 2 ;; --tool) TOOL=&quot;$2&quot;; shift 2 ;; -x) THREADS=&quot;$2&quot;; shift 2 ;; --dataset) DATASET=1; shift ;; --local-dir) LOCAL_DIR=&quot;$2&quot;; shift 2 ;; *) shift ;; esacdone# Check if aria2, wget, curl, git, and git-lfs are installedcheck_command() { if ! command -v $1 &amp;&gt;/dev/null; then echo -e &quot;${RED}$1 is not installed. Please install it first.${NC}&quot; exit 1 fi}# Mark current repo safe when using shared file system like samba or nfsensure_ownership() { if git status 2&gt;&amp;1 | grep &quot;fatal: detected dubious ownership in repository at&quot; &gt; /dev/null; then git config --global --add safe.directory &quot;${PWD}&quot; printf &quot;${YELLOW}Detected dubious ownership in repository, mark ${PWD} safe using git, edit ~/.gitconfig if you want to reverse this.\\n${NC}&quot; fi}[[ &quot;$TOOL&quot; == &quot;aria2c&quot; ]] &amp;&amp; check_command aria2c[[ &quot;$TOOL&quot; == &quot;wget&quot; ]] &amp;&amp; check_command wgetcheck_command curl; check_command git; check_command git-lfs[[ -z &quot;$MODEL_ID&quot; || &quot;$MODEL_ID&quot; =~ ^-h ]] &amp;&amp; display_helpif [[ -z &quot;$LOCAL_DIR&quot; ]]; then LOCAL_DIR=&quot;${MODEL_ID#*/}&quot;fiif [[ &quot;$DATASET&quot; == 1 ]]; then MODEL_ID=&quot;datasets/$MODEL_ID&quot;fiecho &quot;Downloading to $LOCAL_DIR&quot;if [ -d &quot;$LOCAL_DIR/.git&quot; ]; then printf &quot;${YELLOW}%s exists, Skip Clone.\\n${NC}&quot; &quot;$LOCAL_DIR&quot; cd &quot;$LOCAL_DIR&quot; &amp;&amp; ensure_ownership &amp;&amp; GIT_LFS_SKIP_SMUDGE=1 git pull || { printf &quot;${RED}Git pull failed.${NC}\\n&quot;; exit 1; }else REPO_URL=&quot;$HF_ENDPOINT/$MODEL_ID&quot; GIT_REFS_URL=&quot;${REPO_URL}/info/refs?service=git-upload-pack&quot; echo &quot;Testing GIT_REFS_URL: $GIT_REFS_URL&quot; response=$(curl -s -o /dev/null -w &quot;%{http_code}&quot; &quot;$GIT_REFS_URL&quot;) if [ &quot;$response&quot; == &quot;401&quot; ] || [ &quot;$response&quot; == &quot;403&quot; ]; then if [[ -z &quot;$HF_USERNAME&quot; || -z &quot;$HF_TOKEN&quot; ]]; then printf &quot;${RED}HTTP Status Code: $response.\\nThe repository requires authentication, but --hf_username and --hf_token is not passed. Please get token from https://huggingface.co/settings/tokens.\\nExiting.\\n${NC}&quot; exit 1 fi REPO_URL=&quot;https://$HF_USERNAME:$HF_TOKEN@${HF_ENDPOINT#https://}/$MODEL_ID&quot; elif [ &quot;$response&quot; != &quot;200&quot; ]; then printf &quot;${RED}Unexpected HTTP Status Code: $response\\n${NC}&quot; printf &quot;${YELLOW}Executing debug command: curl -v %s\\nOutput:${NC}\\n&quot; &quot;$GIT_REFS_URL&quot; curl -v &quot;$GIT_REFS_URL&quot;; printf &quot;\\n${RED}Git clone failed.\\n${NC}&quot;; exit 1 fi echo &quot;GIT_LFS_SKIP_SMUDGE=1 git clone $REPO_URL $LOCAL_DIR&quot; GIT_LFS_SKIP_SMUDGE=1 git clone $REPO_URL $LOCAL_DIR &amp;&amp; cd &quot;$LOCAL_DIR&quot; || { printf &quot;${RED}Git clone failed.\\n${NC}&quot;; exit 1; } ensure_ownership while IFS= read -r file; do truncate -s 0 &quot;$file&quot; done &lt;&lt;&lt; $(git lfs ls-files | cut -d ' ' -f 3-)fiprintf &quot;\\nStart Downloading lfs files, bash script:\\ncd $LOCAL_DIR\\n&quot;files=$(git lfs ls-files | cut -d ' ' -f 3-)declare -a urlsfile_matches_include_patterns() { local file=&quot;$1&quot; for pattern in &quot;${INCLUDE_PATTERNS[@]}&quot;; do if [[ &quot;$file&quot; == $pattern ]]; then return 0 fi done return 1}file_matches_exclude_patterns() { local file=&quot;$1&quot; for pattern in &quot;${EXCLUDE_PATTERNS[@]}&quot;; do if [[ &quot;$file&quot; == $pattern ]]; then return 0 fi done return 1}while IFS= read -r file; do url=&quot;$HF_ENDPOINT/$MODEL_ID/resolve/main/$file&quot; file_dir=$(dirname &quot;$file&quot;) mkdir -p &quot;$file_dir&quot; if [[ &quot;$TOOL&quot; == &quot;wget&quot; ]]; then download_cmd=&quot;wget -c \\&quot;$url\\&quot; -O \\&quot;$file\\&quot;&quot; [[ -n &quot;$HF_TOKEN&quot; ]] &amp;&amp; download_cmd=&quot;wget --header=\\&quot;Authorization: Bearer ${HF_TOKEN}\\&quot; -c \\&quot;$url\\&quot; -O \\&quot;$file\\&quot;&quot; else download_cmd=&quot;aria2c --console-log-level=error --file-allocation=none -x $THREADS -s $THREADS -k 1M -c \\&quot;$url\\&quot; -d \\&quot;$file_dir\\&quot; -o \\&quot;$(basename &quot;$file&quot;)\\&quot;&quot; [[ -n &quot;$HF_TOKEN&quot; ]] &amp;&amp; download_cmd=&quot;aria2c --header=\\&quot;Authorization: Bearer ${HF_TOKEN}\\&quot; --console-log-level=error --file-allocation=none -x $THREADS -s $THREADS -k 1M -c \\&quot;$url\\&quot; -d \\&quot;$file_dir\\&quot; -o \\&quot;$(basename &quot;$file&quot;)\\&quot;&quot; fi if [[ ${#INCLUDE_PATTERNS[@]} -gt 0 ]]; then file_matches_include_patterns &quot;$file&quot; || { printf &quot;# %s\\n&quot; &quot;$download_cmd&quot;; continue; } fi if [[ ${#EXCLUDE_PATTERNS[@]} -gt 0 ]]; then file_matches_exclude_patterns &quot;$file&quot; &amp;&amp; { printf &quot;# %s\\n&quot; &quot;$download_cmd&quot;; continue; } fi printf &quot;%s\\n&quot; &quot;$download_cmd&quot; urls+=(&quot;$url|$file&quot;)done &lt;&lt;&lt; &quot;$files&quot;for url_file in &quot;${urls[@]}&quot;; do IFS='|' read -r url file &lt;&lt;&lt; &quot;$url_file&quot; printf &quot;${YELLOW}Start downloading ${file}.\\n${NC}&quot; file_dir=$(dirname &quot;$file&quot;) if [[ &quot;$TOOL&quot; == &quot;wget&quot; ]]; then [[ -n &quot;$HF_TOKEN&quot; ]] &amp;&amp; wget --header=&quot;Authorization: Bearer ${HF_TOKEN}&quot; -c &quot;$url&quot; -O &quot;$file&quot; || wget -c &quot;$url&quot; -O &quot;$file&quot; else [[ -n &quot;$HF_TOKEN&quot; ]] &amp;&amp; aria2c --header=&quot;Authorization: Bearer ${HF_TOKEN}&quot; --console-log-level=error --file-allocation=none -x $THREADS -s $THREADS -k 1M -c &quot;$url&quot; -d &quot;$file_dir&quot; -o &quot;$(basename &quot;$file&quot;)&quot; || aria2c --console-log-level=error --file-allocation=none -x $THREADS -s $THREADS -k 1M -c &quot;$url&quot; -d &quot;$file_dir&quot; -o &quot;$(basename &quot;$file&quot;)&quot; fi [[ $? -eq 0 ]] &amp;&amp; printf &quot;Downloaded %s successfully.\\n&quot; &quot;$url&quot; || { printf &quot;${RED}Failed to download %s.\\n${NC}&quot; &quot;$url&quot;; exit 1; }doneprintf &quot;${GREEN}Download completed successfully.\\n${NC}&quot; Ref：https://gist.github.com/padeoe/697678ab8e528b85a2a7bddafea1fa4f#file-hfd-sh-L1","link":"/posts/20d2b052/"},{"title":"ONNX算子简介","text":"详细英文介绍见ONNX算子 （算子较多，善用Ctrl+F查找） 序号 算子 含义 参数 1 Abs 求绝对值 【输入】input：输入Tensor，float32【约束】无限制【输出】**output：输出Tensor 2 Acos 反余弦 【输入】input：输入Tensor，数值范围[-1, 1]，类型：float32【约束】无限制【输出】**output：输出Tensor，数值范围[0, pi]，类型与x输入相同 3 Add 二元点加 【输入】- A：输入Tensor，类型：float32，第1个操作数- B：输入Tensor，类型：float32，第2个操作数【约束】支持两组输入的维度不一致，进行广播操作（广播即维度补齐），目前支持以下几种广播场景：- NCHW+NCHW(备注, 两个维度相同tensor)- NCHW+scalar- NCHW+W, CHW+W, HW+W(备注, W维度做broadcast)- NCHW + NCH1, CHW + CH1, HW + H1- CHW + C1W(备注，H维度做broadcast)对于两个输入维度个数不相同的场景，需要将维度补齐到四维。例如，x.shape=(1, 5, 6, 7) 和 y.shape=(6, 7)需要将y的维度补齐到4维，即y.shape=(1, 1, 6, 7)。说明：两个Tensor的输入顺序可以互换。【输出】C：输出Tensor，类型同B 4 And 取与运算 【输入】- A：输入Tensor，类型：bool- B：输入Tensor，类型：bool【约束】input输入不支持NCHW格式数据【输出】output：输出Tensor，类型：bool 5 ArgMax 在指定轴上找到最大值索引 【输入】data：输入Tensor，类型：float32【参数】- axis：int，default值为0，取值范围[-r, r-1]，r = rank(data)- keepdims：int，default值为1【输出】**output：输出Tensor，类型：int64 6 Asin 反正弦 【输入】input：输入Tensor，数值范围[-1, 1]，类型：float32【约束】无限制【输出】output：输出Tensor，数值范围[-pi/2, pi/2]，类型与input输入相同 7 Atan 反正切 【输入】input：输入Tensor，类型：float32【约束】无限制【输出】output：输出Tensor，类型与input输入相同 8 AveragePool 平均池化 【输入】X：输入Tensor，类型：float32【参数】- auto_pad：optional, string，pad的计算模式，默认是NOTSET- ceil_mode：optional, int，使用ceil（向上取整）还是floor（向下取整）计算输出维度，默认是0（ceil）- count_include_pad：optional，int，计算边缘时是否包含pad，默认是0，不包含pad- kernel_shape：list of ints，每个值对应相应维度的窗口大小- pads：list of ints，每个值对应相应维度的pad值，默认值为0- strides：list of ints，其中每个值对应相应维度的滑动步长，默认值为1【约束】- auto_pad参数不支持SAME_UPPER，SAME_LOWER- count_include_pad参数只支持默认值【输出】Y：输出Tensor，类型与X输入相同 9 BatchNormalization 对输入做标准化 【输入】- X：输入Tensor，类型：float32- scale：输入Tensor，类型：float32，用于缩放- B：输入Tensor，类型：float32，偏差- mean：输入Tensor，类型：float32，用于推理总体均值- var：输入Tensor，类型：float32，用于推理总体方差- training_mode：输入Tensor，optional，训练模式【参数】- epsilon：float32，在X的方差中添加的一个小的浮点数，默认值是1e-05- momentum：float32，计算mean和var的因子，默认值为0.9- spatial：int，计算mean和var的方式，默认值1【约束】- 不支持训练场景- 不支持training_mode输入- 不支持output_mean、output_var、saved_mean、saved_var输出- opset7中不支持spatial设置【输出】- Y：输出Tensor，和X输入有相同的维度- output_mean：训练模式下是滑动均值，非训练模式下是估计均值- output_var：训练模式下是滑动方差，非训练模式下是估计方差- saved_mean：已保存的均值- saved_var：已保存的均值 10 Cast 数据类型转换 【输入】input：输入Tensor，类型：float32，bool，int32，uint8【参数】to：数据类型int- FLOAT = 1- UINT8 = 2- INT8 = 3- UINT16 = 4- INT16 = 5- INT32 = 6- INT64 = 7- STRING = 8- BOOL = 9- FLOAT16 = 10- DOUBLE = 11- UINT32 = 12【约束】支持下面类型转换：- fp16 -&gt; fp32- fp32 -&gt; fp16- u8 -&gt; fp16- fp16 -&gt; u8- int32 -&gt; fp32- fp32-&gt;int32- fp16 -&gt; int8- int8 -&gt; fp16- in32 -&gt; fp16- fp16 -&gt; int32- bool -&gt; fp16- fp16 -&gt; bool【输出】output：输出Tensor 11 Ceil 向上取值 【输入】X：输入Tensor，类型：float32【约束】无【输出】output：输出Tensor，类型与input输入相同 12 Clip 将输入限制在一个区间中 【输入】- input：输入Tensor，类型：float32- min：Scalar Tensor，optional，类型：float32，区间最小值- max：Scalar Tensor，optional，类型：float32，区间最大值【参数】在opset 7~10中min和max是参数【约束】- min输入必须是常量- max输入必须是常量【输出】output：输出Tensor，类型与input输入相同 13 Concat 数据按维度拼接 【输入】- inputs：List of tensors，类型：float32，int32【参数】- axis：int，轴参数，控制需要拼接的数据轴，负值表示从维度最后一位往前数【约束】无【输出】concat_result：拼接之后的Tensor，类型：float32，int32 14 Constant 输出1个常量Tensor 【输入】无【参数】- sparse_value：稀疏类型的输出值- value：Tensor，输出Tensor的值- value_float：float32类型的标量输出Tensor的值- value_floats：list of floats，float32类型的1D输出Tensor的值- value_int：int，int32类型的标量输出Tensor的值- value_ints：list of ints，int32类型的1D输出Tensor的值- value_string：string，string类型的标量UTF-8输出Tensor的值- value_strings：list of strings，string类型的1D UTF-8输出Tensor的值【约束】- 不支持sparse_value参数- 不支持value_string参数- 不支持value_strings参数【输出】output：输出Tensor，和提供的Tensor具有相同的值 15 ConstantOfShape 根据给定的值和维度，生成1个Tensor 【输入】input：1-D Tensor，类型：int32，uint8【参数】value：optional，0-D Tensor，需要填充的值，默认为0，默认类型float32【约束】无【输出】output：输出Tensor，类型同value 16 Conv 卷积 【输入】- X：输入Tensor，类型：float32- W：输入Tensor，具有维度(M C/group kH kW)，其中C是channels的数量，kH和kW是卷积核的高和宽，M是feature maps的数量- B：optional，1D 常量Tensor，卷积计算时添加的偏置【参数】- auto_pad：optional, string，pad的计算模式，默认是NOTSET- dilations：optional，list of ints，每个值对应卷积核对应空间轴上的扩张值，默认值1- group：optional，int，组的数量- kernel_shape：list of ints，卷积核的维度- pads：list of ints，每个值对应相应维度的pad值- list of ints，每个值对应相应维度的滑动步长，默认值为1【约束】auto_pad参数不支持SAME_UPPER, SAME_LOWER*【输出】Y：输出Tensor，类型同X 17 ConvTranspose 反卷积 【输入】- X：输入Tensor，类型：float32- W：输入Tensor，具有维度(M C/group kH kW)，其中C是channels的数量，kH和kW是卷积核的高和宽，M是feature maps的数量- B：optional，1D 常量Tensor，卷积计算时添加的偏置【参数】- auto_pad：optional, string，pad的计算模式，默认是NOTSET- dilations：optional，list of ints，每个值对应卷积核对应空间轴上的扩张值，默认值1- group：optional，int，组的数量- kernel_shape：list of ints，卷积核的维度- output_padding：为输出坐标指数较高的边添加的额外值- output_shape：输出的shape- pads：list of ints，每个值对应相应维度的pad值- list of ints，每个值对应相应维度的滑动步长，默认值为1【约束】- auto_pad参数不支持SAME_UPPER, SAME_LOWER- output_padding参数不支持- W输入必须为常量*【输出】Y：输出Tensor，类型同X输入 18 Cos 计算余弦 【输入】input：输入Tensor，类型：float32【约束】无限制【输出】output：输出Tensor，类型与x输入相同 19 DepthToSpace 重组数据，根据blocksize 【输入】input：输入Tensor，类型：float32【参数】- blocksize：数据类型：int- mode: 数据类型 string【约束】mode仅支持DCR CRD两种模式【输出】output：输出Tensor，类型与x输入相同 20 Div 做除法运算 【输入】- A：输入Tensor，类型：float32，int32- B：输入Tensor，类型：float32，int32【约束】对于两个输入维度个数不相同的场景，需要将维度补齐到四维。例如，x.shape=(1, 5, 6, 7) 和 y.shape=(6, 7)需要将y的维度补齐到4维，即y.shape=(1, 1, 6, 7)。【输出】C：输出Tensor，类型与x输入相同 21 Elu 根据f(x) = alpha * (exp(x) - 1.) 该公式做计算 【输入】X：输入Tensor，类型：float32【参数】alpha：float32，缺省值为1.0【约束】无【输出】Y：输出Tensor，类型与x输入相同 22 Equal 判断输入是否相等 【输入】- A：输入Tensor，类型：uint8,float32,bool,int32（int32只支持标量）- B：输入Tensor，类型：uint8,float32,bool,int32（int32只支持标量）【约束】暂不支持广播场景【输出】C：输出Tensor，类型 bool 23 Erf 对输入数据逐个元素做error function计算 【输入】x：输入Tensor，类型：float32【约束】无限制【输出】y：输出Tensor，类型与x输入相同 24 Exp 指数函数，output = e^input 【输入】input：输入Tensor，类型：float32，double【约束】无限制【输出】output：输出Tensor，类型与x输入相同 25 Expand 根据指定的shape做广播 【输入】- input：输入Tensor，类型：float32，int8, uint8, bool- shape：输入Tensor，类型：int32，1D的tensor，指定输出的shape【约束】- 支持任意满足broadcast条件的Broadcast场景- 对于需要插broadcastTo算子的Add、Sub、Mul、Div、Max，不支持量化功能- 支持在Kirin 9000及以后的芯片上运行【输出】output：输出Tensor，类型与x输入相同 26 Flatten 数据按维度展开 【输入】input：输入 Tensor，类型float32【参数】axis：int，标识数据在哪个维度上展开，值的范围[-r, r]，r是输入Tensor的维度个数，负值表示从最后1个维度往回计算【约束】axis参数必须为1【输出】output：2-D Tensor，类型float32 27 Floor 对输入进行向下取整 【输入】X：输入Tensor，类型：float32【约束】无【输出】Y：输出Tensor，类型同X输入 28 Gather 根据输入的indices，从data中获取entry组成输出tensor 【输入】- data：输入Tensor，类型：float32, int32- indices：输入Tensor，数据类型int32【参数】axis：int, [-r, r-1] ,r = rank(data)【约束】无【输出】output：输出Tensor，类型同data输入 29 Gemm 通用矩阵乘法，Y = alpha A’ B’ + beta * C 【输入】- A：输入Tensor，类型：float32- B：输入Tensor，类型：float32- C：输入Tensor，类型：float32【参数】- alpha：float32，A B的标量乘数，默认值1.0- beta：float32，C的标量乘数，默认值1.0- transA：int，A输入是否需要转置，默认值0- transB：int，B输入是否需要转置，默认值0【约束】- transA参数不支持true- 输入B和C只支持常量- 如果A是MK，B是KN，C可以是N或1N或不指定【输出】Y：输出Tensor，维度是（M, N） 30 GlobalAveragePool 对输入进行全局平均池化 【输入】X：输入Tensor，类型：float32，维度是（N C H W）【约束】无*【输出】Y：输出Tensor，类型同X输入 31 GlobalMaxPool 对输入进行全局最大池化 【输入】X：输入Tensor，类型float32，维度是（N C H W）【约束】无*【输出】Y：输出Tensor，类型同X输入 32 Greater 逐个元素比较哪个大 【输入】- A：输入Tensor，类型float32，- B：输入Tensor，类型float32，【约束】无【输出】C：输出Tensor，类型 bool 33 InstanceNormalization 按照下面公式做归一化运算y = scale * (x - mean) / sqrt(variance + epsilon) + B 【输入】- input：输入4D Tensor，类型float32，- scale：输入Tensor，类型float32，- B：输入Tensor，类型float32，【参数】alpha：float32，避免除零错误，默认值1e-05【约束】无【输出】output：输出Tensor，类型同input输入 34 LeakyRelu 对输入进行LeakyRelu激活函数计算f(x) = alpha * x for x &lt; 0, f(x) = x for x &gt;= 0 【输入】X：输入Tensor，类型：float32【参数】alpha：float32，泄漏系数，默认值0.01【约束】无【输出】Y：输出Tensor，类型同X输入 35 Less 对输入A和B进行逐元素Less逻辑运算 【输入】- A：输入Tensor，类型：float32- B：输入Tensor，类型：float32【约束】无限制【输出】C：输出Tensor，类型：bool 36 Log 取自然对数运算 【输入】input：输入Tensor，类型： float32【约束】无【输出】output：输出Tensor，类型同input输入 37 LogSoftmax 对输入进行logsoftmax（log of softmax）计算 【输入】input：输入Tensor，类型：float32【参数】axis：int，输入变为2D维度时的轴，默认值1【约束】axis参数仅支持最后一维【输出】output：输出Tensor，维度和输入相同 38 MatMul 矩阵乘 【输入】- A：输入Tensor，类型：float32- B：输入Tensor，类型：float32【约束】- A: 输入tensor，2&lt;=rank&lt;=4- B: 输入tensor，类型与rank同A【输出】Y：输出Tensor，类型：float32 39 Max 逐个元素取最大值 【输入】- X1：输入Tensor，类型：float32- X2：输入Tensor，类型：float32【约束】- 对于两个输入维度个数不相同的场景，需要将维度补齐到四维。例如，x.shape=(1, 5, 6, 7) 和 y.shape=(6, 7)需要将y的维度补齐到4维，即y.shape=(1, 1, 6, 7)；Kirin 9000平台下，已经支持broadcast；1&lt;=N &lt;= 65535- 只支持2个输入【输出】y：输出Tensor，类型：float32 40 MaxPool 最大池化 【输入】X：输入Tensor，类型：float32【参数】- auto_pad：optional, string，pad的计算模式，默认是NOTSET- ceil_mode：optional, int，使用ceil（向上取整）还是floor（向下取整）计算输出维度，默认值0（ceil）- dilations：optional，list of ints，每个值对应池化核对应空间轴上的扩张值，默认值1- kernel_shape：list of ints，每个值对应相应维度的窗口大小- pads：list of ints，每个值对应相应维度的pad值，默认值为0- storage_order：int，Tensor的存储顺序，默认值0，按行存储- strides：list of ints，其中每个值对应相应维度的滑动步长，默认值为1【约束】- auto_pad参数只支持默认值- storage_order参数只支持默认值- dilations参数只支持默认值- Indices可选输出不支持【输出】- Y：输出Tensor，类型与X输入相同- Indices：optional，输出Tensor 41 Min 逐个元素取最小 【输入】- X1：输入Tensor，类型：float32, int32- X2：输入Tensor，类型：float32,int32【约束】- 5D输入不支持常量广播- 只支持2个输入【输出】y：输出Tensor，类型与Xn输入相同 42 Mul 二元点乘 【输入】- A：输入Tensor，类型：float32，第1个操作数- B：输入Tensor，类型：float32，第2个操作数【约束】支持两组输入的维度不一致，进行广播操作（广播即维度补齐），目前支持以下几种广播场景：- NCHW+NCHW(备注, 两个维度相同tensor)- NCHW+scalar- NCHW+W, CHW+W, HW+W(备注, W维度做broadcast)- NCHW + NCH1, CHW + CH1, HW + H1- CHW + C1W(备注，H维度做broadcast)对于两个输入维度个数不相同的场景，需要将维度补齐到四维。例如，x.shape=(1, 5, 6, 7) 和 y.shape=(6, 7)需要将y的维度补齐到4维，即y.shape=(1, 1, 6, 7)。说明：两个Tensor的输入顺序可以互换。【输出】C：输出Tensor，类型同B 43 Neg 对Tensor的每个元素取反，y=-x 【输入】X：输入Tensor，类型：float32【约束】无【输出】Y：输出Tensor，类型：float32 44 NonMaxSuppression 进行非最大值压缩在指定框中 【输入】- boxes：输入Tensor，类型：float32- scores：输入Tensor，类型：float32- max_output_boxes_per_class（可选）：输入Tensor，类型：int32- iou_threshold（可选）：输入Tensor，类型：float32- score_threshold（可选）：输入Tensor，类型：float32【约束】- max_output_boxes_per_class、iou_threshold、score_threshold仅支持权值输入- max_output_boxes_per_class不支持取0- iou_threshold不支持取0和1【输出】selected_indices：输出Tensor，类型：float32 45 Or 对输入Tensor的每个元素取逻辑或 【输入】- A：输入Tensor，类型：bool- B：输入Tensor，类型：bool【约束】input输入不支持NCHW格式数据【输出】C：输出Tensor，类型：bool 46 PRelu 根据下面公式做运算f(x) = slope * x for x &lt; 0, f(x) = x for x &gt;= 0 【输入】- X：输入Tensor，类型：float32- slope：输入Tensor，类型：float32【约束】- slope输入必须是常量- slope必须是标量或者1C11或C11的形式，其中C是X输入的channel- X输入必须是4D【输出】Y：输出Tensor，类型同X输入 47 Pad 对输入Tensor做补pad处理 【输入】- data：输入Tensor，类型：float32- pads：输入Tensor，类型：int64- constant_value：optional，输入Tensor，标量，类型同data输入，默认值0【参数】- mode：string，支持的模式- 在opset 7~10中pads输入是参数- 在opset 7~10中存在value参数，表示要被填充的值【约束】- mode仅支持constant模式- pads输入必须是常量【输出】output：输出Tensor，类型：float32 48 Pow 逐个元素做指数运算 【输入】- X：输入Tensor，类型：float32, int32- Y：输入Tensor，类型：float32, int32【约束】无限制【输出】Z：输出Tensor，类型：float32, int32 49 Range 创建一个Tensor，Tensor的数据以start开始，以delta作为步长扩展直到limit 【输入】- start：输入Tensor，标量，类型：float32，int32，输出数据的起始值- limit：输入Tensor，标量，类型：float32，int32，输出数据的上限值- delta：输入Tensor，标量，类型：float32，int32，步长【约束】- 输入start必须是常量- 输入limit必须是常量- 输入delta必须是常量【输出】output：输出Tensor，标量，类型float32，int32 50 ReduceLogSumExp 计算输入Tensor沿着指定轴上的对数和的指数 【输入】data：输入Tensor，类型：float32【参数】- axes：list of ints，指定的轴- keepdims：ints，是否保留指定轴上的维度，默认值是1【约束】无【输出】reduced：输出Tensor 51 ReduceMax 计算输入Tensor沿着指定轴上的最大值 【输入】data：输入Tensor，类型：float32【参数】- axes：list of ints，指定的轴- keepdims：ints，是否保留指定轴上的维度，如果是1，保留，如果是0，则不保留，默认值是1【约束】axes参数为必选参数【输出】reduced：输出Tensor 52 ReduceMean 计算输入Tensor沿着指定轴上的平均值 【输入】data：输入Tensor，类型：float32【参数】- axes：list of ints，指定的轴- keepdims：ints，是否保留指定轴上的维度，如果是1，保留，如果是0，则不保留，默认值是1【约束】axes参数为必选参数【输出】reduced：输出Tensor 53 ReduceMin 计算输入Tensor沿着指定轴上的最小值 【输入】data：输入Tensor，类型：float32【参数】- axes：list of ints，指定的轴- keepdims：int，是否保留维度，默认值1【约束】- axes参数为必选参数- keepdims参数仅支持设置为1【输出】reduced：输出Tensor 54 ReduceSum 计算输入Tensor沿着指定轴上的和 【输入】data：输入Tensor，类型：float32【参数】- axes：list of ints，指定的轴- keepdims：int，是否保留维度，默认值1【约束】axes参数为必选参数【输出】reduced：输出Tensor 55 Relu 整流线性单位函数 【输入】X：输入Tensor，类型：float32【约束】无【输出】Y：输出Tensor，类型同X输入 56 Reshape 改变输入Tensor的维度 【输入】- data：输入Tensor，类型：float32，int32，int64，bool- shape：输入Tensor，类型：int32，int64【约束】shape输入必须是常量【输出】reshaped：输出Tensor，类型同data输入 57 Resize 调整输入tensor的维度 【输入】- X：输入Tensor，类型：float32- roi：输入Tensor，类型：float32【参数】- align_corners：bool，缺省值为false- half_pixel_centers：bool，缺省值为false【约束】- scales和sizes两个输入仅支持权值输入，不支持非权值输入- coordinate_transformation_mode支持half_pixel，pytorch_half_pixel。其中pytorch_half_pixel仅支持resized_length&gt;1场景，resized_length &lt;=1场景报错- cubic_coeff_a仅支持默认值-0.75- exclude_outside仅支持默认值0- extrapolation_value仅支持默认值：0.0- mode 支持nearest, linear- nearest_mode仅支持默认值round_prefer_floor- 不支持crop功能- roi是无效输入时，仅支持权值输入- 其他场景报错处理【输出】Y：输出Tensor，类型同data输入 58 RoiAlign 对关注的区域做对齐操作 【输入】- X：输入Tensor，类型：float32- roi：输入Tensor，类型：int32- batch_indices：输入Tensor，类型：int32【参数】- mode：string，缺省值为avg- output_height：int32，缺省值为1- output_width：int32，缺省值为1- sampling_ratio：int32，缺省值为1- spatial_scale：float32，缺省值为1.0【约束】mode仅支持avg模式【输出】Y：输出Tensor，类型同X输入 59 Round 逐个元素取整 【输入】X：输入Tensor，类型：float32【约束】无限制【输出】Y：输出Tensor，类型同X输入 60 ScatterElements 绘制散点图 【输入】- data：输入Tensor，类型：float32, int8, uint8, bool- indices：输入Tensor，类型：int32, int64- updates：输入Tensor，类型：float32, int8, uint8, bool【参数】axis：int，缺省值为0【约束】无【输出】output：输出Tensor，类型同data输入 61 Selu 对输入做下面公式计算y = gamma (alpha e^x - alpha) for x &lt;= 0, y = gamma * x for x &gt; 0 【输入】x：输入Tensor，类型：float32【参数】- alpha：float32，缺省值为1.67326- gamma：float32，缺省值为1.0507【约束】仅支持alpha和gamma参数是默认值【输出】y：输出Tensor，类型同x输入 62 Shape 获取输入Tensor的维度，并输出 【输入】data：输入Tensor，类型：float32，int32，bool，uint8【约束】不支持指定为输出节点【输出】shape：输出Tensor，data输入的维度 63 Sigmoid sigmoid函数，y = 1 / (1 + exp(-x)) 【输入】X：输入Tensor，类型：float32【约束】无【输出】Y：输出Tensor，类型同X输入 64 Sign sign函数（符号函数），当x&gt;0，sign(x)=1当x=0，sign(x)=0当x&lt;0，sign(x)=-1 【输入】input：输入Tensor，类型：float32【约束】无【输出】output：输出Tensor，类型和维度同input输入 65 Sin 计算正弦 【输入】input：输入Tensor，类型：float32【约束】无限制【输出】output：输出Tensor，类型与x输入相同 66 Slice 对输入Tensor沿着指定轴切分 【输入】- data：输入Tensor，类型：float32，int32，uint8，bool- starts：1-D输入Tensor，类型：int64，int32，表示在指定轴上切分的起始位置- ends：1-D输入Tensor，类型：int64，int32，表示在指定轴上切分的结束位置- axes：optional，1-D输入Tensor，类型：int64，int32，指定需要切分的轴，缺省表示沿所有的维度切分，负值表示从后往前统计维度值- steps：optional，1-D输入Tensor，类型：int64，int32，切分的步长【参数】opset9及之前版本，axes，ends，starts是参数【约束】- 输入starts，ends，axes，steps必须为常量- 不支持切分后，存在维度为0的场景【输出】output：输出Tensor，切分后的Tensor 67 Softmax 归一化逻辑函数 【输入】input：输入Tensor，类型：float32【参数】axis：int，输入变为2D维度时的轴，默认值1【约束】axis参数仅支持最后一维【输出】output：输出Tensor，类型和维度同input输入 68 Softplus softplus激活函数，y = ln(exp(x) + 1) 【输入】X：1-D输入Tensor，类型：float32【约束】无【输出】Y：1-D输出Tensor，类型同X输入 69 Split 在指定轴上做拆分,输出多个tensor 【输入】input：输入Tensor，类型： float32【参数】- axis：int, 缺省值为0- split: list of ints 值必须大于等于0【约束】无【输出】outputs：D输出Tensor，类型同输入 70 Sqrt 求平方根 【输入】X：输入Tensor，类型：float32【约束】无【输出】Y：输出Tensor，类型同X输入 71 Squeeze 在指定轴上降维 【输入】data：输入Tensor，类型：float32【参数】axes：list of ints，轴，缺省值为所有维度，负值表示从后往前遍历【约束】无【输出】squeezed：输出Tensor，类型：float32 72 Sub 逐个元素的减法运算 【输入】- A：输入Tensor，类型：float32 ，第1个操作数- B：输入Tensor，类型：float32 ，第2个操作数【约束】无【输出】C：输出Tensor，类型：float32 73 Tan 正切函数 【输入】input：输入Tensor，类型：float32【约束】无【输出】output：输出Tensor，类型：float32 74 Tanh 双曲函数 【输入】input：输入Tensor，类型：float32【约束】无【输出】output：输出Tensor，类型：float32 75 Tile 对输入Tensor做平铺操作 【输入】- input：输入Tensor，类型：float32，int8，uint8，bool- repeats：1-D输入Tensor，类型：int32, int64【约束】repeats输入必须是常量【输出】output：输出Tensor，类型同input输入 76 TopK 实现最大或者最小的K个元素在指定的轴上。 【输入】- X：输入Tensor，类型：float32- K：输入Tensor，类型：int32, int64【参数】- axis：int，缺省值为-1- largest：int，缺省值为1- sorted：int，缺省值为1【约束】K输入必须是常量【输出】- values：输出Tensor，类型：float32- indices: 输出Tensor，类型：int32 77 Transpose 根据属性perm中各个轴的排列顺序，对输入Tensor和shape做相应转换 【输入】data：输入Tensor，类型：float32【参数】perm：list of ints，轴调整排列的顺序表【约束】无【输出】transposed：输出Tensor，类型：float32 78 Unsqueeze 在指定轴上扩维 【输入】data：输入Tensor，类型：float32，int32，uint8，bool【参数】axes：list of ints，指定需要扩维的轴【约束】仅支持axes个数为1【输出】expanded：输出Tensor，类型：float32，int32，uint8，bool 79 Upsample 上采样 【输入】- X：输入Tensor，类型：float32- scales：输入Tensor，类型：float32【参数】- mode：string，模式，有2个插值模式，nearest模式和linear模式（包含bilinear, trilinear等），默认是nearest模式- 在opset7中scales输入是参数【约束】- 仅支持nearest、bilinear两种插值模式- X仅支持4D输入Tensor- N、C方向的scale仅支持等于1.0【输出】Y：输出Tensor，类型：float32 80 ReduceL2（V510新增） 计算输入Tensor沿着指定轴上的欧几里得范数 【输入】data：输入Tensor，类型：float32【参数】- axes：list of ints，指定的轴- keepdims：int，是否保留维度，默认值1【约束】- 只支持keepdims=1的情形，所以输入和输出的realDim相等- 输入N &lt;= 65535- axes范围：支持realDim为3和realDim为4时对最后一维做reduceL2【输出】reduced：输出Tensor","link":"/posts/5ae3bedd/"},{"title":"Autoware 软件开发指南","text":"目录 一、Autoware 概述及安装指南 二、Autoware 感知模块解析 2.1 基于Darknet的Yolov3图像识别 2.2 voxel_grid_filter点云降采样程序注解 2.3 ring_ground_filter地面点云去除程序注解 三、Autoware 定位模块解析 3.0 基础知识 3.1 ndt_mapping节点解析 3.2 ndt_matching节点解析 四、Autoware 决策规划模块解析 4.1 节点waypoint_loader 4.2 节点waypoint_replanner 4.3 节点lane_navi 4.4 节点lane_rule 4.5 节点lane_select 4.6 节点 astar_avoid 4.7 节点velocity_set 五、Autoware 控制模块解析 5.1 节点pure_pursuit 5.2 节点twist_filter 5.3 节点listener_car_drive 一、Autoware 概述及安装指南1.1 Autoware简介​ Autoware 最早是由名古屋大学研究小组在加藤伸平教授(Prof. Shinpei Kato)的领导下于2015年8月正式发布。2015年12月下旬，加藤伸平教授创立了Tier IV，以维护Autoware并将其应用于真正的自动驾驶汽车。随着时间的流逝，Autoware已成为公认的开源项目。Autoware 也是世界上第一个用于自动驾驶技术的“多合一”开源软件。Autoware.ai版本基于ROS 1，并在Apache 2.0许可下可用。Autoware的功能主要适合与城市，但也可以覆盖高速公路。支持以下功能：路径规划、路径跟随、加速/制动/转向控制、数据记录、汽车/行人/物体检测、3D本地化、3D映射、交通信号检测、交通灯识别、车道检测、对象跟踪、传感器校准、传感器融合、面向云的地图连接自动化、智能手机导航、软件仿真、虚拟现实等。 ​ Autoware 作为第一款开源的自动驾驶框架，当前各大自动驾驶公司的框架几乎都借鉴过，Autoware框架是理解自动驾驶系统知识最好的学习模板之一。其包含了自动驾驶所有关键技术模块：建图、定位、感知、规划和运动控制。 1.2 Autoware主体框架​ autoware主要包括sensing、computing（perception、decision、planning）、actuation等几个部分，如下图所示。 ​ sensing模块对应的是各类传感器对真实世界中各类数据的采样，例如camera采样图像、LiDAR采样激光点云等，采样数据属于未处理的原始数据，需要输入到computing模块进行计算处理。 ​ computing模块主要是为了对传感器采样的原始数据进行加工处理，最后以为实现安全高效的导航为目的，将规划结果输出给actuation模块。其中computing模块主要分为三个小模块。① perception（感知模块），这部分要处理localization（通过车辆当前采集传感器数据和已有地图进行自身定位，若无地图需要通过SLAM构建地图），然后detection模块负责检测周围与车辆有场景交互的非自身个体（车辆、行人等），prediction模块会对检测初得物体进行未来预测估计，以便提前规划防止碰撞。② decision（决策模块），根据之前感知的结果，Autoware决策一个由有限状态机表示的驾驶行为，以便可以选择适当的计划功能。当前的决策方法是基于规则的系统。③ planning（规划模块），主要是根据决策和起始点和目标点，采用mission和motion模块可以计算出一条kinodynamic的路径。④ actuation模块，表示驱动器模块，如YMC驱动器等，接收planning模块出来的规划结果，通过驱动器实现驱动控制。 ​ 其各个模块都有对应不同的ros节点，如下图所示： 1.3 Autoware安装指南1.3.1 系统版本及驱动确认​ 请确认系统版本为Ubuntu18.04，并正确安装英伟达显卡驱动460版本、CUDA版本10.0、cuDNN版本10.0。系统及驱动安装教程不再赘述。 1.3.2 安装caffe① caffe相关依赖包123$ sudo apt install -y libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler$ sudo apt install -y --no-install-recommends libboost-all-dev$ sudo apt install -y libgflags-dev libgoogle-glog-dev liblmdb-dev ② 安装caffe1sudo apt install caffe-cuda 1.3.3 安装eigen3.3.712345$ cd &amp;&amp; wget http://bitbucket.org/eigen/eigen/get/3.3.7.tar.gz$ mkdir eigen &amp;&amp; tar --strip-components=1 -xzvf 3.3.7.tar.gz -C eigen$ cd eigen &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make$ sudo make install$ cd &amp;&amp; rm -rf 3.3.7.tar.gz &amp;&amp; rm -rf eigen 1.3.4 安装Autoware 1.14① 安装Ubuntu 18.04 依赖1234$ sudo apt update$ sudo apt install -y python-catkin-pkg python-rosdep ros-$ROS_DISTRO-catkin$ sudo apt install -y python3-pip python3-colcon-common-extensions python3-setuptools python3-vcstool$ pip3 install -U setuptools ② 建立workspace12$ mkdir -p autoware.ai/src$ cd autoware.ai ③ 下载Autoware 1.1412$ wget -O autoware.ai.repos &quot;https://gitlab.com/autowarefoundation/autoware.ai/autoware/raw/1.14.0/autoware.ai.repos?inline=false&quot;$ vcs import src &lt; autoware.ai.repos ④ 安装ROS依赖12$ rosdep update$ rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO ⑤ 编译环境1$ AUTOWARE_COMPILE_WITH_CUDA=1 colcon build --cmake-args -DCMAKE_BUILD_TYPE=Release 1.4 参考文献[1] Autoware Foundation. Autoware-Documentation[DB/OL]. [2023-02-13]. https://autowarefoundation.github.io/autoware-documentation/main/. [2] Github-Computing Platforms Federated Laboratory. Autoware Manuals[DB/OL]. [2020-05-02]. https://github.com/CPFL/Autoware-Manuals. 二、Autoware 感知模块解析​ Autoware是一个完整、系统化的自动驾驶平台，其中，core_perception模块包含了视觉和点云感知处理算法的实现过程。本节以视觉感知算法YoloV3、voxel grid filter及ring ground filter点云处理算法为例简要介绍Autoware感知相关算法原理及代码实现过程，梳理相关框架及逻辑。 2.1 基于Darknet的Yolov3图像识别​ Yolo的全称是You Only Look Once，指只需要浏览一次就可以识别出图中的物体的类别和位置。Yolo算法是一种one-stage的目标检测算法，与two-stage目标检测算法（如R-CNN系列）的主要区别在于two-stage算法需要先生成proposal(一个有可能包含待检物体的预选框)，然后进行细粒度的物体检测。而one-stage算法会直接在网络中提取特征来预测物体分类和位置。two-stage算法速度相对较慢但是准确率高，one-stage算法准确率没有two-stage算法高但是速度较快。 ​ Yolo系列算法将图片划分成若干个网格，再基于anchor机制生成先验框，只用一步就生成检测框，这种方法大大提升了算法的预测速度，YOLOv3的论文于2018年发表在CVPR上。整个框架可划分为3个部分：分别为Darknet-53结构(下图Backbone部分)、特征层融合结构(下图黄色梯形concat部分)、以及分类检测结构(下图未画出)。 ​ 从网络结构的输入说起，给一张图像，输入到Darkenet-53网络结构，进行一系列的卷积以及残差网络，分别得到原图像1/8、1/16、1/32的特征图（即feature map），这个过程就是所谓的特征提取过程。在上图也可以看到经过Darkenet-53网络之后有3个分支，分别对应的就是3个不同尺寸的feature map。划分不同尺寸的feature map特征图，是为了让YOLO算法能适应不同大小目标的检测；比如：19×19×255的特征图，其一个特征点就对应原图大小为32×32（608/19=32）的块的检测，适合于大目标的检测；而76×76×255的特征图，其一个特征点对应原图大小为8×8（608/76）的块的检测。适合与小目标的检测，同理38×38×255适合于中目标的检测。但由于提取的这些特征有时不能充分的反应原图中的目标信息。所以接下来需要将3个特征图进行特征融合，以获得更强的特征表现力，从而达到更好的效果；其中由于尺寸不一样，中间需要进行上采样以及下采样（其实就是卷积），使特征图变成相同大小，然后进行堆叠、融合及相应的卷积等操作后，得到最终的3个特征层，即上图中的19×19×255（Y1）、38×38×255（Y2）、76×76×255（Y3），这3个特征图恰好分别为原图像x的1/32、1/16、1/8。 2.1.1 依赖项 NVIDIA GPU 驱动、 CUDA 基于COCO数据集预训练的YOLOv3权重文件详情见 : YOLO website. weights文件需放置在 vision_darknet_detect/darknet/data/ 目录下 2.1.2 程序路径12345678//源代码路径~/autoware.ai/src/autoware/core_perception/vision_darknet_detect/src/vision_darknet_detect.cpp//launch文件路径~/autoware.ai/src/autoware/core_perception/vision_darknet_detect/launch/vision_yolo3_detect.launch//训练names文件~/autoware.ai/src/autoware/core_perception/vision_darknet_detect/darknet/cfg/coco.names 2.1.3 启动方法 终端启动: roslaunch vision_darknet_detect vision_yolo3_detect.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方Computing 选项卡 -&gt; Detection/ vision_detector -&gt; vision_darknet_detect，单击 [app] 按钮可更改设置和文件路径等参数。 2.1.4 参数详情 参数名 类型 说明 score_threshold Double Detections with a confidence value larger than this value will be displayed. Default 0.5. nms_threshold Double Non-Maximum suppresion area threshold ratio to merge proposals. Default 0.45. network_definition_file String Network architecture definition configuration file. Default yolov3.cfg. pretrained_model_file String Path to pretrained model. Default yolov3.weights. camera_id String Camera workspace. Default /. image_src String Image source topic. Default /image_raw. names_file String Path to pretrained model. Default coco.names. 2.1.5 订阅话题名 Topic 消息类型 说明 /image_raw sensor_msgs/Image 要检测的原始图像流 /config/Yolo3 autoware_config_msgs/ConfigSSD 阈值的配置调整参数 2.1.6 发布话题名 Topic 消息类型 说明 /detection/vision_objects autoware_msgs::DetectedObjectArray 检测到对象的边界框坐标 2.1.7 代码注解① Yolo3DetectorNode类​ 声明了ROS相关节点及参数类型，定义目标检测所需关键方法。最后在公有域中执行Run。 123456789101112131415161718192021222324252627282930class Yolo3DetectorNode { //定义ROS中相应节点 ros::Subscriber subscriber_image_raw_; ros::Subscriber subscriber_yolo_config_; ros::Publisher publisher_objects_; ros::NodeHandle node_handle_; //定义类方法Yolo3Detector darknet::Yolo3Detector yolo_detector_; image darknet_image_ = {}; //定义参数类型 float score_threshold_; float nms_threshold_; double image_ratio_; uint32_t image_top_bottom_border_; uint32_t image_left_right_border_; std::vector&lt;cv::Scalar&gt; colors_; std::vector&lt;std::string&gt; custom_names_; bool use_coco_names_; //定义目标检测中所使用的方法 void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, autoware_msgs::DetectedObjectArray&amp; out_message); void rgbgr_image(image&amp; im); image convert_ipl_to_image(const sensor_msgs::ImageConstPtr&amp; msg); void image_callback(const sensor_msgs::ImageConstPtr&amp; in_image_message); void config_cb(const autoware_config_msgs::ConfigSSD::ConstPtr&amp; param); std::vector&lt;std::string&gt; read_custom_names_file(const std::string&amp; in_path);//公有化参数域public: void Run();}; ② convert_rect_to_image_obj函数​ 对矩形框预测结果进行处理，包括坐标值转换、目标类别标签获取等，然后发布检测结果。 1234567891011121314151617181920212223242526272829303132333435363738394041void Yolo3DetectorNode::convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, autoware_msgs::DetectedObjectArray&amp; out_message){ for (unsigned int i = 0; i &lt; in_objects.size(); ++i) { { autoware_msgs::DetectedObject obj; //yolov3检测算法中对目标矩形框四个坐标值的处理 obj.x = (in_objects[i].x /image_ratio_) - image_left_right_border_/image_ratio_; obj.y = (in_objects[i].y /image_ratio_) - image_top_bottom_border_/image_ratio_; obj.width = in_objects[i].w /image_ratio_; obj.height = in_objects[i].h /image_ratio_; if (in_objects[i].x &lt; 0) obj.x = 0; if (in_objects[i].y &lt; 0) obj.y = 0; if (in_objects[i].w &lt; 0) obj.width = 0; if (in_objects[i].h &lt; 0) obj.height = 0; //目标类型分数 obj.score = in_objects[i].score; //使用Coco数据集时，将检测结果与相应的类别标签对应 //GetClassString()方法用于映射目标类别标签方法 if (use_coco_names_) { obj.label = in_objects[i].GetClassString(); } else { if (in_objects[i].class_type &lt; custom_names_.size()) obj.label = custom_names_[in_objects[i].class_type]; else obj.label = &quot;unknown&quot;; } obj.valid = true; //发送检测结果 out_message.objects.push_back(obj); } }} ③ rgbgr_image函数​ rgbgr_image主要用于对输入图片进行通道变换处理，以适应网络的输入类型。 12345678910void Yolo3DetectorNode::rgbgr_image(image&amp; im){ int i; for(i = 0; i &lt; im.w*im.h; ++i) { float swap = im.data[i]; im.data[i] = im.data[i+im.w*im.h*2]; im.data[i+im.w*im.h*2] = swap; }} ④ convert_ipl_to_image函数​ convert_ipl_to_image函数主要对输入图片的尺寸进行处理以适应网络输入大小。当图片尺寸与输入大小不符，计算比值并将其作为缩放因子对图片进行裁剪填充处理，最后进行归一化以提高网络训练的数值稳定性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354image Yolo3DetectorNode::convert_ipl_to_image(const sensor_msgs::ImageConstPtr&amp; msg){ //cv_bridge定义opencv类型的cv_image cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(msg, &quot;bgr8&quot;); cv::Mat mat_image = cv_image-&gt;image; int network_input_width = yolo_detector_.get_network_width(); int network_input_height = yolo_detector_.get_network_height(); int image_height = msg-&gt;height, image_width = msg-&gt;width; IplImage ipl_image; cv::Mat final_mat; if (network_input_width!=image_width || network_input_height != image_height) { //网络输入和图像不符时，计算两者比值 image_ratio_ = (double ) network_input_width / (double)mat_image.cols; //对图像进行resize，缩放因子为网络输入与图像的比值 cv::resize(mat_image, final_mat, cv::Size(), image_ratio_, image_ratio_); //填充 image_top_bottom_border_ = abs(final_mat.rows-network_input_height)/2; image_left_right_border_ = abs(final_mat.cols-network_input_width)/2; cv::copyMakeBorder(final_mat, final_mat, image_top_bottom_border_, image_top_bottom_border_, image_left_right_border_, image_left_right_border_, cv::BORDER_CONSTANT, cv::Scalar(0,0,0)); } else final_mat = mat_image; ipl_image = final_mat; unsigned char *data = (unsigned char *)ipl_image.imageData; int h = ipl_image.height; int w = ipl_image.width; int c = ipl_image.nChannels; int step = ipl_image.widthStep; int i, j, k; image darknet_image = make_image(w, h, c); //填充后的图像进行归一化 for(i = 0; i &lt; h; ++i){ for(k= 0; k &lt; c; ++k){ for(j = 0; j &lt; w; ++j){ darknet_image.data[k*w*h + i*w + j] = data[i*step + j*c + k]/255.; } } } rgbgr_image(darknet_image); return darknet_image;} ⑤ image_callback函数​ image_callback函数通过convert_ipl_to_image对图片预处理，然后利用convert_rect_to_image_obj将检测结果进一步转换为具体的目标信息并发布。 123456789101112131415void Yolo3DetectorNode::image_callback(const sensor_msgs::ImageConstPtr&amp; in_image_message){ std::vector&lt; RectClassScore&lt;float&gt; &gt; detections; //调用convert_ipl_to_image对图片resize darknet_image_ = convert_ipl_to_image(in_image_message); //以resize后的图像作为yolov3检测器的输入 detections = yolo_detector_.detect(darknet_image_); autoware_msgs::DetectedObjectArray output_message; output_message.header = in_image_message-&gt;header; //调用convert_rect_to_image_obj()将检测结果转换为相应的目标信息 convert_rect_to_image_obj(detections, output_message); //发布检测结果 publisher_objects_.publish(output_message); free(darknet_image_.data);} ⑥ read_custom_names_file函数​ read_custom_names_file函数主要用于获取文件路径、文件名等信息 1234567891011121314std::vector&lt;std::string&gt; Yolo3DetectorNode::read_custom_names_file(const std::string&amp; in_names_path){ //文件路径 std::ifstream file(in_names_path); std::string str; //文件名 std::vector&lt;std::string&gt; names; while (std::getline(file, str)) { names.push_back(str); std::cout &lt;&lt; str &lt;&lt; std::endl; } return names;} ⑦ Run函数​ 首先声明了ROS函数命名空间，并通过节点名判断来接受相应的参数信息，然后调用yolo_detector检测器通过配置文件、预训练模型文件、像素均值等参数来初始化yolov3模型进行目标检测。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283void Yolo3DetectorNode::Run(){ //ROS构造函数指定命名空间 ros::NodeHandle private_node_handle(&quot;~&quot;); //声明标准字符变量接受图片 std::string image_raw_topic_str; if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str)) { ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str.c_str()); } else { ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;); image_raw_topic_str = &quot;/image_raw&quot;; } //声明标准字符变量，接收网络配置文件 std::string network_definition_file; //声明标准字符变量，接收预训练模型文件 std::string pretrained_model_file, names_file; //判断是否有网络配置文件节点名 if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file)) { ROS_INFO(&quot;Network Definition File (Config): %s&quot;, network_definition_file.c_str()); } else { ROS_INFO(&quot;No Network Definition File was received. Finishing execution.&quot;); return; } //判断是否有预训练模型节点名 if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file)) { ROS_INFO(&quot;Pretrained Model File (Weights): %s&quot;, pretrained_model_file.c_str()); } else { ROS_INFO(&quot;No Pretrained Model File was received. Finishing execution.&quot;); return; } if (private_node_handle.getParam(&quot;names_file&quot;, names_file)) { ROS_INFO(&quot;Names File: %s&quot;, names_file.c_str()); use_coco_names_ = false; custom_names_ = read_custom_names_file(names_file); } else { ROS_INFO(&quot;No Names file was received. Using default COCO names.&quot;); use_coco_names_ = true; } //定义私有节点参数score_threshold，阈值为0.5 private_node_handle.param&lt;float&gt;(&quot;score_threshold&quot;, score_threshold_, 0.5); ROS_INFO(&quot;[%s] score_threshold: %f&quot;,__APP_NAME__, score_threshold_); //定义私有节点参数nms_threshold，阈值为0.45 private_node_handle.param&lt;float&gt;(&quot;nms_threshold&quot;, nms_threshold_, 0.45); ROS_INFO(&quot;[%s] nms_threshold: %f&quot;,__APP_NAME__, nms_threshold_); //调用yolo_detector_函数，初始化模型 ROS_INFO(&quot;Initializing Yolo on Darknet...&quot;); yolo_detector_.load(network_definition_file, pretrained_model_file, score_threshold_, nms_threshold_); ROS_INFO(&quot;Initialization complete.&quot;); #if (CV_MAJOR_VERSION &lt;= 2) cv::generateColors(colors_, 80); #else generateColors(colors_, 80); #endif publisher_objects_ = node_handle_.advertise&lt;autoware_msgs::DetectedObjectArray&gt;(&quot;/detection/image_detector/objects&quot;, 1); ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str()); subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;Yolo3DetectorNode::image_callback, this); std::string config_topic(&quot;/config&quot;); config_topic += &quot;/Yolo3&quot;; subscriber_yolo_config_ = node_handle_.subscribe(config_topic, 1, &amp;Yolo3DetectorNode::config_cb, this); ROS_INFO_STREAM( __APP_NAME__ &lt;&lt; &quot;&quot; ); ros::spin(); ROS_INFO(&quot;END Yolo&quot;);} 2.2 voxel_grid_filter点云降采样程序注解2.2.1 启动方法 终端启动: roslaunch points_downsampler points_downsample.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方Sensing 选项卡 -&gt; Points Downsampler -&gt; voxel_grid_filter，单击 [app] 按钮可更改设置等参数。 2.2.2 点云消息数据结构激光雷达雷达坐标系名称：velodyne 点云话题名：/points_raw 消息类型为sensor_msgs/PointCloud2，下面为消息类型的详细介绍。 123456789101112header: // 点云头 seq: // 序列号 stamp: // 话题时间戳 frame_id: // 点云坐标系名称height: // 点云的二维结构。如果云是无序的，则高度为1，宽度为点云的长度。width: // 点云的长度fields: // 描述二进制数据blob中的通道及其布局。is_bigendian: // 数据存储方式，包括大端与小端point_step: // 一个点占的字节数 row_step: // 一行的长度占用的字节数data:[] // 点云数据is_dense: // 有没有非法数据点 2.2.3 程序路径12345// 源代码路径~/autoware.ai/src/autoware/core_perception/points_downsampler/nodes/voxel_grid_filter/voxel_grid_filter.cpp// launch启动文件路径~/autoware.ai/src/autoware/core_perception/points_downsampler/launch/points_downsample.launch 2.2.4 参数详情 参数名 类型 说明 voxel_leaf_size int 滤波器处理时采用的体素大小 measurement_range double 测量距离 output_log bool 是否输出log points_topic string 点云接收话题名 2.2.5 订阅话题名 话题名 消息类型 /config/voxel_grid_filter autoware_config_msgs/ConfigVoxelGridFilter /points_raw sensor_msgs/PointCloud2 2.2.6 发布话题名 话题名 消息类型 /filtered_points sensor_msgs::PointCloud2 /points_downsampler_info points_downsampler::PointsDownsamplerInfo 2.2.7 代码注解① main函数​ main函数主要初始化ROS，订阅点云及参数信息，初始化发布者。使用体素化网格方法实现降采样，即减少点的数量，减少点云数据，并同时保持点云的形状特征，在提高配准、曲面重建、形状识别等算法速度中非常实用。PCL实现的VoxelGrid类通过输入的点云数据创建一个三维体素栅格（可把体素栅格想象为微小的空间三维立方体的集合），然后在每个体素（即 三维立方体）内，用体素中所有点的重心来近似显示体素中其他点，这样该体素就内所有点就用一个重心点最终表示，对于所有体素处理后得到过滤后的点云。这种方法比用体素中心来逼近的方法更慢，但它对于采样点对应曲面的表示更为准确。 1234567891011121314151617181920212223242526272829303132int main(int argc, char** argv){ ros::init(argc, argv, &quot;voxel_grid_filter&quot;); ros::NodeHandle nh; ros::NodeHandle private_nh(&quot;~&quot;); //参数服务器获取激光点云topic以及是否输出log private_nh.getParam(&quot;points_topic&quot;, POINTS_TOPIC); private_nh.getParam(&quot;output_log&quot;, _output_log); //输出log if(_output_log == true){ char buffer[80]; std::time_t now = std::time(NULL); std::tm *pnow = std::localtime(&amp;now); std::strftime(buffer,80,&quot;%Y%m%d_%H%M%S&quot;,pnow); filename = &quot;voxel_grid_filter_&quot; + std::string(buffer) + &quot;.csv&quot;; ofs.open(filename.c_str(), std::ios::app); } //参数服务器获取激光测量距离参数 private_nh.param&lt;double&gt;(&quot;measurement_range&quot;, measurement_range, MAX_MEASUREMENT_RANGE); // 发布降采样点云、info filtered_points_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/filtered_points&quot;, 10); points_downsampler_info_pub = nh.advertise&lt;points_downsampler::PointsDownsamplerInfo&gt;(&quot;/points_downsampler_info&quot;, 1000); // 订阅config、点云话题 ros::Subscriber config_sub = nh.subscribe(&quot;config/voxel_grid_filter&quot;, 10, config_callback); ros::Subscriber scan_sub = nh.subscribe(POINTS_TOPIC, 10, scan_callback); ros::spin(); return 0;} ② config_callback函数​ config_callback 回调函数的参数为降采样参数消息(autoware_config_msgs::ConfigVoxelGridFilter.msg）。此处接收降采样参数及测量距离范围信息。 12345static void config_callback(const autoware_config_msgs::ConfigVoxelGridFilter::ConstPtr&amp; input){ voxel_leaf_size = input-&gt;voxel_leaf_size; measurement_range = input-&gt;measurement_range;} ③ scan_callback函数​ scan_callback函数接收激光雷达sensor_msgs::PointCloud2类型消息，并对点云进行降采样处理。 ​ PCL点云降采样库详情请见：pcl::VoxelGrid官方文档web 1234567891011121314151617181920212223242526272829303132333435363738394041424344static void scan_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input){ // 声明pcl::PointCloud&lt;pcl::PointXYZI&gt;类型的点云数据用来储存接收到的点云 pcl::PointCloud&lt;pcl::PointXYZI&gt; scan; // 点云类型转换sensor_msgs::PointCloud2 -&gt; pcl::PointCloud&lt;pcl::PointXYZI&gt; pcl::fromROSMsg(*input, scan); // 判断要使用的激光点距离是否超限，并移除超限的激光点 if(measurement_range != MAX_MEASUREMENT_RANGE){ scan = removePointsByRange(scan, 0, measurement_range); } pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(scan)); pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;()); sensor_msgs::PointCloud2 filtered_msg; filter_start = std::chrono::system_clock::now(); // 若voxel_leaf_size &lt; 0.1，voxel_grid_filter无法完成降采样(PCL规范) if (voxel_leaf_size &gt;= 0.1) { // 使用VoxelGrid滤波器对点云进行降采样 pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter; voxel_grid_filter.setLeafSize(voxel_leaf_size, voxel_leaf_size, voxel_leaf_size); voxel_grid_filter.setInputCloud(scan_ptr); voxel_grid_filter.filter(*filtered_scan_ptr); pcl::toROSMsg(*filtered_scan_ptr, filtered_msg); } else // 若设置的voxel_leaf_size&lt;0.1，无法降采样，直接输出原始点云 { pcl::toROSMsg(*scan_ptr, filtered_msg); } // 记录降采样结束时间 filter_end = std::chrono::system_clock::now(); // 发布filtered_msg降采样后点云消息 filtered_msg.header = input-&gt;header; filtered_points_pub.publish(filtered_msg); // 发布points_downsampler_info_msg降采样info消息 points_downsampler_info_msg.header = input-&gt;header; //...（下略）} 2.3 ring_ground_filter地面点云去除程序注解2.3.1 启动方法 终端启动: roslaunch points_preprocessor ring_ground_filter.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方Sensing 选项卡 -&gt; Points Preprocessor -&gt; ring_ground_filter，单击 [app] 按钮可更改设置等参数。 2.3.2 程序路径12345// 源代码路径~/autoware.ai/src/autoware/core_perception/points_preprocessor/nodes/ring_ground_filter/ring_ground_filter.cpp// launch启动文件路径~/autoware.ai/src/autoware/core_perception/points_preprocessor/launch/ring_ground_filter.launch 2.3.3 参数详情 参数名 类型 说明 point_topic string 点云接收话题名 remove_floor bool 是否移除地面 sensor_model int 激光雷达发射线束数量(16,32,64) sensor_height double 激光雷达安装高度 max_slope double 环境地面最大坡度 vertical_thres double 障碍物和地面的差异度，大于这个值则被认为是障碍 2.3.4 订阅话题名 话题名 消息类型 /points_raw sensor_msgs::PointCloud2 2.3.5 发布话题名 话题名 消息类型 说明 /points_no_ground sensor_msgs::PointCloud2 去除地面点云 /points_ground sensor_msgs::PointCloud2 地面点云 2.3.6 代码注解① VelodyneCallback函数​ VelodyneCallback函数主要接收来自激光雷达的点云信息，将原始点云数据传给FilterGround函数处理，并发布处理好的地面点云、去除地面点云数据。 12345678910111213141516171819202122void GroundFilter::VelodyneCallback(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg){ // 声明pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;类型的点云数据 pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; vertical_points; pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; ground_points; vertical_points.header = in_cloud_msg-&gt;header; ground_points.header = in_cloud_msg-&gt;header; //初始化清空 vertical_points.clear(); ground_points.clear(); // 调用FilterGround函数进行地面过滤 FilterGround(in_cloud_msg, vertical_points, ground_points); if (!floor_removal_) { vertical_points = *in_cloud_msg; } //发布处理完毕的点云 groundless_points_pub_.publish(vertical_points); ground_points_pub_.publish(ground_points);} ② FilterGround函数​ FilterGround函数用于将VelodyneCallback传入的点云进行地面去除，并输出处理好的地面点云、去除地面点云数据。首先，将所有与点集具有相同水平角的点分组，然后逐点集进行计算。在每个点集中，此算法应用两步滤波器，该滤波器使用两个连续点的角度和距离来区分地面点云和垂直地面(障碍物)点云。 (1) 基于角度的滤波器 ​ 两步滤波器的第一步是基于角度的滤波器，若两个连续点的角度小于角度阈值，则将其添加进“候选组”，计算一直持续到角度大于阈值为止，然后检查“候选组”的大小。如果点数足够大，这一点集中的所有点都会被标记为地面点云。 (2) 基于距离的滤波器 ​ 通过比较连续点与动态阈值之间的距离来过滤上一步的其余点。如果这些点彼此足够接近，则将其标记为垂直地面的点云(障碍物点云)，其余的点被标记为地面点云。 算法具体流程图及伪代码请见：round_filter介绍pdf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106void GroundFilter::FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg, pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_groundless_points, pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_ground_points){ velodyne_pointcloud::PointXYZIR point; InitDepthMap(horizontal_res_); // 计算点云集中每个点的角度，并使每个激光点对应到列表中的行和列 for (size_t i = 0; i &lt; in_cloud_msg-&gt;points.size(); i++) { double u = atan2(in_cloud_msg-&gt;points[i].y,in_cloud_msg-&gt;points[i].x) * 180/M_PI; if (u &lt; 0) { u = 360 + u; } int column = horizontal_res_ - (int)((double)horizontal_res_ * u / 360.0) - 1; int row = vertical_res_ - 1 - in_cloud_msg-&gt;points[i].ring; index_map_.at&lt;int&gt;(row, column) = i; } // 按每条激光线束上点的数量遍历(以16线雷达为例，每条环形线有1000个激光点) for (int i = 0; i &lt; horizontal_res_; i++) { Label point_class[vertical_res_]; int point_index[vertical_res_]; int point_index_size = 0; double z_max = 0; double z_min = 0; double r_ref = 0; std::copy(class_label_, class_label_ + vertical_res_, point_class); // 按激光线束ID遍历每线激光 for (int j = 0; j &lt; vertical_res_; j++) { // 如果存在列表中(j,i)这个点，且此点没有被分类到任何一个点云集 if (index_map_.at&lt;int&gt;(j,i) &gt; -1 &amp;&amp; point_class[j] == UNKNOWN) { // 读取每点xyz坐标 double x0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].x; double y0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].y; double z0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].z; // 计算该点距离 double r0 = sqrt(x0*x0 + y0*y0); double r_diff = fabs(r0 - r_ref); if (r_diff &lt; radius_table_[j] || r_ref == 0) { r_ref = r0; if (z0 &gt; z_max || r_ref == 0) z_max = z0; if (z0 &lt; z_min || r_ref == 0) z_min = z0; point_index[point_index_size] = j; point_index_size++; } else { // 判断点云集类型 if (point_index_size &gt; 1 &amp;&amp; (z_max - z_min) &gt; vertical_thres_) { // 点云类型为非地面点云(障碍物) for (int m = 0; m &lt; point_index_size; m++) { //...(下略) point_class[point_index[m]] = VERTICAL; } // 重置point_index_size point_index_size = 0; } else // 点云类型为地面点云 { for (int m = 0; m &lt; point_index_size; m++) { //...(下略) point_class[point_index[m]] = GROUND; } // 重置point_index_size point_index_size = 0; } r_ref = r0; z_max = z0; z_min = z0; point_index[point_index_size] = j; point_index_size++; } } // 判断剩余的点云 if (j == vertical_res_ - 1 &amp;&amp; point_index_size != 0) { // 点云类型为非地面点云(障碍物) if (point_index_size &gt; 1 &amp;&amp; (z_max - z_min) &gt; vertical_thres_) { for (int m = 0; m &lt; point_index_size; m++) { //...(下略) point_class[point_index[m]] = VERTICAL; } point_index_size = 0; } // 点云类型为地面点云 else { for (int m = 0; m &lt; point_index_size; m++) { //...(下略) point_class[point_index[m]] = GROUND; } point_index_size = 0; } } } }} 2.4 参考文献[1] YOLO: Real-Time Object Detection[OB/OL].[2018-3-25]. https://pjreddie.com/darknet/yolo/. [2] Redmon J, Farhadi A. YOLOv3: An Incremental Improvement[J]. arXiv: Computer Vision and Pattern Recognition,2018. [3] Redmon J, Farhadi A. YOLO9000: Better, faster and stronger[C]. Computer Vision and Patter Recognition, 2017: 6517-6525. [4] Redmon J, Farhadi A. YOLOv3: An incremental improvement[J]. arXiv: Computer Vision and Pattern Recognition, 2018. [5] Simon M, Milz S, Amende K, et al. Complex-YOLO: Real-time 3D object detection on point clouds[J]. arXiv: Computer Vision and Pattern Recognition, 2018. [6] PCL VoxelGrid Class Template Reference[OB/OL]. [2015-8-26]. https://docs.ros.org/en/hydro/api/pcl/html/classpcl_1_1VoxelGrid.html. [7] Nagoya University. Ground Filter Method[OB/OL]. [2017-8-4]. https://github.com/CPFL/Autoware-Manuals/blob/master/en/pdfs/ground_filter.pdf. 三、Autoware 定位模块解析​ 自动驾驶车辆在行驶过程中需要为决策模块提供自身在车道上的精确位姿，精度一般需要达到厘米级别。目前主流的自动驾驶定位技术大致有三种，分别是基于GNSS定位、基于航迹推算的定位，以及基于环境特征匹配的定位方法。其中基于环境特征匹配的方法采用激光雷达获取点云数据，然后与地图中的点云数据进行特征匹配，实现精确定位。 3.0 基础知识3.0.1 三维空间描述与坐标变换​ 无人驾驶汽车在三维空间中运动与工作，为准确描述其在运动过程中车辆本身与相关传感器的相对位姿关系，需要建立包括车体自身在内的各个元器件所对应三维坐标系间的关系。 1、位置描述​ 车辆在三维空间中运动时，我们首先对整个空间建立一个三维坐标系，即World坐标系。建立好之后我们可以用一个向量来表示车辆在World坐标系中的位置。车辆本身也同样建立一个固定在车体上的坐标系base_link，一般满足右手坐标系规则。 2、姿态描述​ 车辆在World坐标系中的位置确定之后，车辆与World之间的坐标原点的距离也随之确定。欲求得车辆的姿态，我们需要一个固定坐标系World，求出base_link相对于World坐标系的关系，使用旋转矩阵来表示。 ​ 假设World坐标系的单位正交基底为 _e1,e2,e3_ ，base_link坐标系的单位正交基底为 _γ1,γ2,γ3_ ，两坐标系间存在旋转关系。那么对于同一个向量 _α_ 在两坐标系下的坐标分别为 _(α1,α2,α3)_ 和 _(β1,β2,β3)_ ，此时有 ​ 等式两端同乘 _[e1,e2,e3]_ 的转置矩阵得到 ​ 通过上述变换，得到旋转矩阵 _R_ ，其描述了向量从base_link坐标系到World坐标系的旋转变换关系。 3、运动描述​ 我们一般用位姿来描述刚体的运动，此时我们通过变换矩阵 _T_ 来表示位姿在坐标系之间的变换关系。 _R_ 表示旋转矩阵，_t_ 表示平移向量。所以向量 _α_ 从base_link到World的转换关系可以由下式表示。 \\begin{array}{c} \\boldsymbol{T}=\\left[\\begin{array}{ll} \\boldsymbol{R} & \\boldsymbol{t} \\\\ 0 & 1 \\end{array}\\right] \\\\ {\\left[\\begin{array}{l} \\alpha_{1} \\\\ \\alpha_{2} \\\\ \\alpha_{3} \\end{array}\\right]=\\boldsymbol{T}\\left[\\begin{array}{l} \\beta_{1} \\\\ \\beta_{2} \\\\ \\beta_{3} \\end{array}\\right]} \\end{array}3.0.2 正态分布变换算法NDT​ NDT，Normal Distributions Transform正态分布变换算法是一种统计学模型。如果一组随机向量满足正态分布，那么它的概率密度函数为： ​ 其中D表示维度，表示均值向量，表示随机向量的协方差矩阵。由于扫描得到的激光点云数据点是三维空间点坐标，所以需要采用三维正态分布。NDT能够通过概率的形式描述点云的分部情况，这有利于减少配准所需要的时间。 ​ 下面简要介绍一下NDT算法的主要流程。 1、NDT算法的主要流程① 栅格化目标点云​ 首先要将激光雷达收到的点云进行栅格化，点云配准一般是对两个点云数据进行两两配准，需要先固定一个点云数据，另外一个点云数据再通过旋转平移来和固定点云进行匹配拼接。这里的固定点云就是目标点云，平移旋转的点云就是源点云。栅格化目标点云主要是利用立方体将激光点云所在空间进行均匀划分，使得激光点处于相应的立方体中，这一步作为NDT算法的第一步非常重要。 ② 注册激光点云数据​ 在第一步栅格化完成后，将点云加载到网格内，计算均值向量，其中表示网格中所有扫描点的坐标。 ​ 然后计算协方差矩阵并求出每个网格内的正态分布概率密度函数。需要注意，由于需要用到协方差矩阵的逆矩阵，所以每个网格中包含的激光点不可少于三个，一般至少要保证有五个点。 ③ 求出源点云相对于目标点云的初始坐标变换参数​ 坐标变换通常涉及到平移与旋转，平移通过平移向量表示，旋转则可以通过旋转矩阵表示，旋转是关于自身zyx三个固定轴的旋转，转角分别用α、β、γ表示，分别与yaw，pitch，roll对应。通过计算旋转平移矩阵，可以得到同一个激光点云在这两个点云坐标系下的位置坐标变换关系。 ​ 这一步是为了寻找一个合适的初始坐标变换使得源点云大致处于目标点云的坐标平面当中。这一步提供的变换参数的初值，为下一步变换参数的迭代提供距离最优点较近的初值。在自动驾驶里初始值的提供可以依靠GNSS、Odom或者IMU惯性导航，利用这些传感器获取车辆的当前位姿，通过坐标变换得到相对于目标点云的坐标变换参数，也就是旋转矩阵 _R_ 和平移向量 _t_ 。 ④ 源点云进行初始坐标变换，并计算在目标点云网格中的概率​ 源点云根据初始变换参数将坐标转换到目标点云中。此时源点云分布在目标点云网格中，转换后源点云的坐标X’由对应所在的网格的正态分布概率密度函数，求出激光点坐标为X‘的概率。将每个点的概率乘积起来作为目标似然函数。通过似然函数找到概率乘积最大时候的坐标转换关系。 ​ 简单来说就是由最大的概率找到最优的坐标变换。 ⑤ 高斯牛顿法进行优化，找出最佳变换参数p完成点云配准2、点云配准原理​ 在激光点云地图建图过程中，由于激光雷达扫描距离存在限制，一次扫描难以获取完整的目标环境，并且距离激光雷达越远，点云就会变得越稀疏，所以需要经过连续多次扫描，然后将每次扫描的点云数据进行配准拼接，最终才能形成连续完整的激光点云地图。 ​ 从不同角度扫描同一场景所得到的的点云数据统一转换到同一坐标系的过程叫做点云配准。简单地说就是将离散的点云数据在统一的坐标系下拼接成一整个完整的点云数据。通常点云配准算法能够利用两个点集之间的最小距离或者利用统计学方法，得到两个点集之间的变换关系，使得点云达到变换配准的效果。问题关键在于如何得到激光点云之间的RT矩阵。通常可以直接利用PCL开源点云库来对相关点云数据进行处理，PCL点云库中包含了基于NDT正态分布变换等多种点云配准算法。C++ PCL库架构图如下图所示，PCL更多资料见：PCL学习指南 点云配准具体的步骤如下： ① 输入实时点云并下采样​ 激光雷达扫描得到的激光点云数据需要去除距离车体较近与较远的激光点集，然后利用体素滤波过滤剩下的激光点云数据，在保持点云统计特征的情况下，降低激光点云数据集的尺寸大小，最好将降采样后的过滤点云作为NDT配准算法的输入源点云以降低运算时间，节省资源。 ② 输入源点云(全局地图)​ 加载全局地图作为NDT配准的输入目标点云。特别的，建图时第一帧激光点云作为初始全局地图。 ③ 输入初始位姿​ 为了快速得到准确的配准结果，需要给NDT算法提供良好的初始值，该节点通过IMU、Odom以及两者联合来求得初始位姿估计。 ④ 点云配准​ 将前三者得到的结果作为参数传入到NDT配准算法中进行激光点云配准。 3、伪代码​ 具体详见4中两篇参考论文，此处以二维举例。 4、参考论文 [1] Biber P, Straßer W. The normal distributions transform: A new approach to laser scan matching[C] IROS 2003 . IEEE, 2003, 3: 2743-2748. [2] Merten H. The three-dimensional normal-distributions transform[J]. threshold, 2008, 10: 3. 3.1 ndt_mapping节点解析​ ndt_mapping主要利用的是scan_to_map的方式实现激光点云建图，该方法经常使用在SLAM同时定位与建图中，当激光雷达进行扫描建图的时候，由于受到扫描距离等因素的限制，使得激光雷达不能一次扫描得到完整的环境地图，因此需要进行连续多次的扫描。最终扫描得到的整个环境地图就是全局地图map，而其中scan表示当前扫描得到的激光点云数据，可以通过固定目标点云地图submap，然后利用NDT配准算法，将每一帧扫描得到的激光点云数据scan变换到目标点云submap中，并使得两者拼接在一起，最终得到拼接完整的全局地图map。ndt_mapping简要流程如下图所示。 3.1.1 启动方法 终端启动: roslaunch lidar_localizer ndt_mapping.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方Computing 选项卡 -&gt; Localization/ lidar_localizer -&gt; ndt_mapping，单击 [app] 按钮可更改设置等参数。 3.1.2 程序路径12345//源代码路径~/autoware.ai/src/autoware/core_perception/lidar_localizer/nodes/ndt_mapping/ndt_mapping.cpp//launch文件路径~/autoware.ai/src/autoware/core_perception/lidar_localizer/launch/ndt_mapping.launch 3.1.3 参数详情 参数名 类型 说明 method_type int ndt使用算法类型 use_odom bool 是否使用里程计减少误差 use_imu bool 是否使用IMU减少误差 imu_upside_down bool IMU坐标系是否翻转 imu_topic String IMU话题名 incremental_voxel_update bool 是否更新增量体素 3.1.4 订阅话题名 话题名 消息类型 /config/ndt_mapping autoware_config_msgs/ConfigNDTMapping /config/ndt_mapping_output autoware_config_msgs/ConfigNDTMappingOutput /points_raw sensor_msgs/PointCloud2 /vehicle/odom nav_msgs/Odometry /imu_raw sensor_msgs/Imu /vehicle/twist geometry_msgs/TwistStamped 3.1.5 发布话题名 话题名 消息类型 /ndt_map sensor_msgs/PointCloud2 /current_pose geometry_msgs/PoseStamped 3.1.6 代码注解① 主函数​ 主函数初始化位姿、ROS节点及参数，并写入日志文件。从参数服务器中获取参数值，计算变换矩阵tf_btol，最后发布与订阅相关消息。 1234567//私有句柄调用getparam函数从参数服务器上得到参数值，若无参数则置为默认值 private_nh.getParam(&quot;method_type&quot;, method_type_tmp);_method_type = static_cast&lt;MethodType&gt;(method_type_tmp);private_nh.getParam(&quot;use_gnss&quot;, _use_gnss);private_nh.getParam(&quot;queue_size&quot;, _queue_size);private_nh.getParam(&quot;offset&quot;, _offset);//...(下略) ​ 计算map与base_link的坐标转换关系 12345678910// 初始平移向量tl_btol，激光雷达相对于车身底盘坐标系的位姿Eigen::Translation3f tl_btol(tf_x, tf_y, tf_z);// tl: translation// 初始化旋转向量，分别绕着x、y、z轴旋转tf::Matrix3x3(tf_baselink2primarylidar.getRotation()).getRPY( tf_roll, tf_pitch,tf_yaw);Eigen::AngleAxisf rot_x_btol(tf_roll, Eigen::Vector3f::UnitX()); // rot: rotationEigen::AngleAxisf rot_y_btol(tf_pitch, Eigen::Vector3f::UnitY());Eigen::AngleAxisf rot_z_btol(tf_yaw, Eigen::Vector3f::UnitZ());tf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();tf_ltob = tf_btol.inverse();//...(下略) ② param_callback函数​ param_callback函数通过autoware_config_msgs::ConfigNDTMapping文件进行参数配置，主要设置ndt算法配准时的参数。其中定义了配准时的消息、网格大小、高斯牛顿法步长等参数。 1234567891011121314static void param_callback(const autoware_config_msgs::ConfigNDTMapping::ConstPtr&amp; input){ //设置ndt参数：分辨率、步长，最大迭代次数、体素叶大小、激光扫描范围等 ndt_res = input-&gt;resolution; //resolution表示点云网格化时网格的边长，过大会影响精度，过小则影响内存使用 step_size = input-&gt;step_size; //step_size设置利用牛顿法优化的最大步长 trans_eps = input-&gt;trans_epsilon; //trans_epsilon设置两连续变换的最大差值用于判断是否收敛至阈值 max_iter = input-&gt;max_iterations; //max_iterations设置优化迭代的最大次数 voxel_leaf_size = input-&gt;leaf_size; //leaf_size设置体素滤波叶的大小用于原始点云过滤 //激光点云有效扫描距离 min_scan_range = input-&gt;min_scan_range; max_scan_range = input-&gt;max_scan_range; min_add_scan_shift = input-&gt;min_add_scan_shift; //...(下略)} ③ output_callback函数​ output_callback主要使用体素滤波将原始点云数据进行过滤，在保持点云特性的情况下降低点云数量，然后将滤波后的点云通过ROS发布，并写入PCD文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static void output_callback(const autoware_config_msgs::ConfigNDTMappingOutput::ConstPtr&amp; input){ double filter_res = input-&gt;filter_res; std::string filename = input-&gt;filename; //...(下略) pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(map)); pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_filtered(new pcl::PointCloud&lt;pcl::PointXYZI&gt;()); map_ptr-&gt;header.frame_id = &quot;map&quot;; map_filtered-&gt;header.frame_id = &quot;map&quot;; sensor_msgs::PointCloud2::Ptr map_msg_ptr(new sensor_msgs::PointCloud2); // 运用体素滤波，如果不滤波则输出原始点云，并将pcl::PointCloud&lt;pcl::PointXYZI&gt;转化为sensor_msgs::PointCloud2类型 if (filter_res == 0.0) { std::cout &lt;&lt; &quot;Original: &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl; pcl::toROSMsg(*map_ptr, *map_msg_ptr); } else { // 声明体素滤波对象voxel_grid_filter pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter; // 设置体素滤波网格大小，网格是边长为filter_res的立方体 voxel_grid_filter.setLeafSize(filter_res, filter_res, filter_res); // 将map作为输入地图 voxel_grid_filter.setInputCloud(map_ptr); // 点云下采样并保存结果至map_filtered voxel_grid_filter.filter(*map_filtered); std::cout &lt;&lt; &quot;Original: &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Filtered: &quot; &lt;&lt; map_filtered-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl; // 将点云类型转换为ROS可用的sensor_msgs::PointCloud2格式 pcl::toROSMsg(*map_filtered, *map_msg_ptr); } // 发布过滤点云消息 ndt_map_pub.publish(*map_msg_ptr); // 点云数据写入PCD文件 if (filter_res == 0.0) { pcl::io::savePCDFileASCII(filename, *map_ptr); std::cout &lt;&lt; &quot;Saved &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; data points to &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl; } else { pcl::io::savePCDFileASCII(filename, *map_filtered); std::cout &lt;&lt; &quot;Saved &quot; &lt;&lt; map_filtered-&gt;points.size() &lt;&lt; &quot; data points to &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl; }} ④ points_callback函数​ points_callback函数由ros::Subscriber points_sub = nh.subscribe(“points_raw”, 100000, points_callback)调用，参数为激光雷达所取到的 sensormsgs::PointCloud2 类型的激光点云数据，r表示激光点云中每一个点与激光雷达的距离，这用来后续滤除距离车体较近与较远的激光点集。p表示原始激光点云中的点对象，类型为pcl::PointXYZI。函数声明了两个类型为pcl::PointxYZI的点云对象 tmp, scan。 tmp表示临时的原始点云数据，scan 表示的是 tmp 滤除距离激光雷达过近和过远的激光点的点云数据。t_localizer 与 t_base_ link 分别表示为激光雷达与车体相对于 map 坐标系的变换矩阵，并且均初始化为4阶单位阵。需要注意的是，NDT配准算法是将激光雷达获取到的激光点云与地图目标点云进行配准，激光点云是相对于激光雷达坐标系，所以进行 NDT 配准的时候求出的是激光雷达相对于全局地图坐标系 map 的变换关系 t_localizer。要想求得车身底盘相对于全局地图map 坐标系的变换关系，需要在t_localizer 的基础上补偿一个激光雷达与车身底盘之间的变换矩阵tf_ltob。 ​ 函数获取当前时间戳作为当前的点云扫描时间，然后利用 pcl:fromROSMsg 函数将输入的 sensor msgs:PointCloud2 类型的点云数据转化为 PCL 使用的数据类型。 123456789101112131415161718192021static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input){ // r表示点云到激光雷达的距离 double r; pcl::PointXYZI p; // 声明点云对象tmp, scan pcl::PointCloud&lt;pcl::PointXYZI&gt; tmp, scan; pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;()); pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr transformed_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;()); tf::Quaternion q; Eigen::Matrix4f t_localizer(Eigen::Matrix4f::Identity()); Eigen::Matrix4f t_base_link(Eigen::Matrix4f::Identity()); // 声明tf发布者br static tf::TransformBroadcaster br; // 声明变换对象transform tf::Transform transform; // 获取当前帧点云扫描时间戳 current_scan_time = input-&gt;header.stamp; // 点云类型转换 pcl::fromROSMsg(*input, tmp); ​ 这一部分代码块主要实现上一步提到的滤除距离车体过近与过远的激光点集。tmp 是原始的激光点云数据，在for循环中逐一获取tmp中的点云数据，然后利用r=√x^2+y^2求出激光点与激光雷达之间的距离，其中，x,y分别表示激光点的横纵坐标。当r在最小扫描距离以及最大扫描距离之间时，则将激光点添加至 scan 点云容器中。 123456789101112131415// 处理tmp点云容器中的点for (pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator item = tmp.begin(); item != tmp.end(); item++){ p.x = (double)item-&gt;x; p.y = (double)item-&gt;y; p.z = (double)item-&gt;z; p.intensity = (double)item-&gt;intensity; // 计算点与激光雷达的欧氏距离r，逐一判断每个点，将满足扫描距离的点插入scan r = sqrt(pow(p.x, 2.0) + pow(p.y, 2.0)); if (min_scan_range &lt; r &amp;&amp; r &lt; max_scan_range) { scan.push_back(p); }}pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(scan)); ​ 激光点云地图需要初始化载入，实际上是将第一帧激光点云加入到map中。initial_scan_loaded 用来表示初始化载入是否成功，当地图没有初始化载入时，则将第一帧点云数据通过 pcl::transformPointcloud 函数进行转换后加入到map，pcl::transformPointCloud 函数的第一个参数为输入点云，第二个参数为输出点云，第三个参数为变换矩阵tf_btol. 123456789// 将初始化点云加入地图，若点云地图未初始化if (initial_scan_loaded == 0){ // 通过tf_btol变换矩阵作为输入将原始点云进行转化 pcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, tf_btol); // 将转换后的点云加入map进行拼接，实际上是作为第一帧点云图像 map += *transformed_scan_ptr; initial_scan_loaded = 1;} ​ 即使筛选掉距离激光雷达过近与过远的激光点，scan_ptr 中含有的激光点的数量仍然较大，所以函数通过体素滤波来降低点云数据的规模。PCL提供的VoxelGrid 类将输入点云集合空间进行三维网格化，然后以每一个网格(每一个立方体)内所有点的重心来代表体素内的所有点，体素内所有点由一个点来表示，这减少了数据规模，而且还保持了输入点云的形状特征。体素滤波主要设置网格大小voxel_leaf_ size， 然后将scan_ptr过滤，得到输出点云*filtered_scan_ptr。 123456// 对scan_ptr输入点云进行体素过滤pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter;voxel_grid_filter.setLeafSize(voxel_leaf_size, voxel_leaf_size, voxel_leaf_size);voxel_grid_filter.setInputCloud(scan_ptr);voxel_grid_filter.filter(*filtered_scan_ptr);pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(map)); ​ 根据 method_type 参数进行相应的NDT参数设置，在ndt配准算法中Epsilon参数主要表示平移向量和旋转角度的临界递增量，当增量小于该参数时，配准算法结束，完成配准，该参数是 NDT 配准算法的收敛条件。步长参数step_size表示的是牛顿迭代法允许的最大步长，ndt_res 表示的是 NDT 配淮算法的网格划分分辨率的大小，分辨率大则网格所含点的数量整体较多，一般不少于5个。max_iter 表示的是牛顿迭代法的最大迭代次数，filtered_scan_ptr 作为 NDT 算法的输入源点云。 12345678910// 设置转换参数Epsilon、最大步长、网格大小最大迭代次数，设置输入点云为已过滤点云 if (_method_type == MethodType::PCL_GENERIC) { ndt.setTransformationEpsilon(trans_eps); ndt.setStepSize(step_size); ndt.setResolution(ndt_res); ndt.setMaximumIterations(max_iter); ndt.setInputSource(filtered_scan_ptr); } //...(下略) ​ 全局地图map 初始化之后，ndt.setlnputTarget 函数将第一帧点云作为 NDT 配准算法的输入目标点云。结合上一段代码可以得到 NDT 目标点云为map全局地图，NDT 源点云为每一次接收到的降采样过滤点云 filtered_scan_ptr。 123456789// 将第一张地图map_ptr设置输入NDT点云 static bool is_first_map = true; if (is_first_map == true) { if (_method_type == MethodType::PCL_GENERIC) ndt.setInputTarget(map_ptr); //...(下略) is_first_map = false; } ​ NDT 配准算法需要提供一个位姿初值，该位姿初值用来计算配准算法的初始变换矩阵，然后再利用牛顿迭代法进行不断选代优化直至达到收敛或者最大迭代次数。Autoware利用IMU、里程计数据融合提供一个更加准确的位姿初值。车辆位姿是随着时间变化的，上一时刻的位姿加上位姿的变化量得到当前时刻的位姿，NDT配准算法所需要的初始位置可以利用前一帧位姿加上前后两帧位姿变化来得到。根据传感器的使用情况，来选择初始位姿计算方法。其中，imu_odom_calc, imu_calc, odom_calc 分别表示选择 imu 与里程计联合，单独使用imu或里程计时的初值计算函数。当不使用 IMU 与里程计计算初值的肘候，使用 guess_pose 作为 NDT 配准算法的初始位姿 guess_pose_for_ndt。代码中使用 guess_pose_for_ndt 初始位姿来构造初始变换矩阵。 12345678910111213141516171819202122232425262728293031guess_pose.x = previous_pose.x + diff_x;guess_pose.y = previous_pose.y + diff_y;guess_pose.z = previous_pose.z + diff_z;guess_pose.roll = previous_pose.roll;guess_pose.pitch = previous_pose.pitch;guess_pose.yaw = previous_pose.yaw + diff_yaw;// 选择使用初值的计算方法，第一种使用imu与里程计融合if (_use_imu == true &amp;&amp; _use_odom == true) imu_odom_calc(current_scan_time);if (_use_imu == true &amp;&amp; _use_odom == false) imu_calc(current_scan_time);if (_use_imu == false &amp;&amp; _use_odom == true) odom_calc(current_scan_time);// 声明NDT初值pose guess_pose_for_ndt;if (_use_imu == true &amp;&amp; _use_odom == true) guess_pose_for_ndt = guess_pose_imu_odom;else if (_use_imu == true &amp;&amp; _use_odom == false) guess_pose_for_ndt = guess_pose_imu;else if (_use_imu == false &amp;&amp; _use_odom == true) guess_pose_for_ndt = guess_pose_odom;else // 若未使用imu或里程计，用guess_pose guess_pose_for_ndt = guess_pose;// 利用guess_pose_for_ndt位置的位姿旋转量来初始化xyz轴的旋转向量Eigen::AngleAxisf init_rotation_x(guess_pose_for_ndt.roll, Eigen::Vector3f::UnitX());Eigen::AngleAxisf init_rotation_y(guess_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());Eigen::AngleAxisf init_rotation_z(guess_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());// 使用guess_pose_for_ndt的三维坐标初始化平移向量Eigen::Translation3f init_translation(guess_pose_for_ndt.x, guess_pose_for_ndt.y, guess_pose_for_ndt.z);Eigen::Matrix4f init_guess = (init_translation * init_rotation_z * init_rotation_y * init_rotation_x).matrix() * tf_btol; ​ 这段代码主要进行了 NDT 的配准操作。代码首先获取当前时间戳作为配准计时的起始时间t4，然后根据方法类型进行 NDT 配准。ndt.align 函数开始进行 NDT 配准，该函数第一个参数是输出点云，第二个参数是初始化变换矩阵，其中，初始化变换矩阵是上一步得到的 init_guess，ndt.align 实际上调用了 ndt.computeTransformation 函数得到最终的配准点云。代码使用 ndt.getFitnessScore()计算匹配得分，一般来说匹配得分小于 1。t_localizer 表示的是 NDT 配准算法得到的激光雷达相对于map 坐标系的最终变换矩阵。 1234567891011121314151617181920t3_end = ros::Time::now();d3 = t3_end - t3_start;t4_start = ros::Time::now();pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZI&gt;);// 根据_method_type类型进行配准if (_method_type == MethodType::PCL_GENERIC){ // 开始配准，ndt.align以init_guess为初值进行迭代优化 ndt.align(*output_cloud, init_guess); // 利用ndt.getFitnessScore()计算目标点云与源点云最近点间的欧式距离平方和作为匹配得分 fitness_score = ndt.getFitnessScore(); // 通过NDT配准得到最终雷达相对于map坐标系的变换矩阵t_localizer t_localizer = ndt.getFinalTransformation(); // 判断是否收敛 has_converged = ndt.hasConverged(); // 得到最后的迭代次数 final_num_iteration = ndt.getFinalNumIteration(); transformation_probability = ndt.getTransformationProbability();}//...(下略) ​ 这段代码首先求出车体相对于原点的变换矩阵 t_base link，然后pcl::transformPointcloud 函数主要将降采样后的原始点云 scan 变换为点云*transformed_scan_ptr，变换时采用的变换矩阵为基于 NDT 配准方法得到的变换矩阵。mat_l，mat_b 分别表示激光雷达与车体相对于全局地图map的旋转矩阵，分别由 t_localizer与t_base_ link 矩阵的前三列与前三行进行对应赋值。ndt_pose 表示 NDT 配准后的车辆在全局地图中的位姿，其坐标位置由t_base_link 变换矩阵的平移向量进行赋值。​ 此时的 ndt_pose 作为当前时刻的位姿估计 current_pose。最后利用当前扫描时间current_scan_time 减去上一帧扫描时间 previous_scan_time 得到激光雷达的扫描间隔时间scan_duration。 123456789101112131415161718192021222324252627282930313233343536373839404142434445t_base_link = t_localizer * tf_ltob;// 将原始图像经过NDT变换后输出点云transformed_scan_ptrpcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, t_localizer);tf::Matrix3x3 mat_l, mat_b;// t_localize为4*4的变换矩阵，其中前三行前三列为旋转矩阵，第四列第三行为平移向量mat_l.setValue(static_cast&lt;double&gt;(t_localizer(0, 0)), static_cast&lt;double&gt;(t_localizer(0, 1)), static_cast&lt;double&gt;(t_localizer(0, 2)), static_cast&lt;double&gt;(t_localizer(1, 0)), static_cast&lt;double&gt;(t_localizer(1, 1)), static_cast&lt;double&gt;(t_localizer(1, 2)), static_cast&lt;double&gt;(t_localizer(2, 0)), static_cast&lt;double&gt;(t_localizer(2, 1)), static_cast&lt;double&gt;(t_localizer(2, 2)));mat_b.setValue(static_cast&lt;double&gt;(t_base_link(0, 0)), static_cast&lt;double&gt;(t_base_link(0, 1)), static_cast&lt;double&gt;(t_base_link(0, 2)), static_cast&lt;double&gt;(t_base_link(1, 0)), static_cast&lt;double&gt;(t_base_link(1, 1)), static_cast&lt;double&gt;(t_base_link(1, 2)), static_cast&lt;double&gt;(t_base_link(2, 0)), static_cast&lt;double&gt;(t_base_link(2, 1)), static_cast&lt;double&gt;(t_base_link(2, 2)));// 更新localizer_poselocalizer_pose.x = t_localizer(0, 3);localizer_pose.y = t_localizer(1, 3);localizer_pose.z = t_localizer(2, 3);//通过mat_l.getRPY设置localizer_pose的旋转rpy角度mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);// 更新ndt_posendt_pose.x = t_base_link(0, 3);ndt_pose.y = t_base_link(1, 3);ndt_pose.z = t_base_link(2, 3);mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);// 将NDT配准后的位置作为当前位置current_pose.x = ndt_pose.x;current_pose.y = ndt_pose.y;current_pose.z = ndt_pose.z;current_pose.roll = ndt_pose.roll;current_pose.pitch = ndt_pose.pitch;current_pose.yaw = ndt_pose.yaw;// 以当前位置为坐标原点transform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));// 当前位置旋转角度RPY，设置四元数Qq.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);transform.setRotation(q);// 发布坐标变换信息br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;map&quot;, &quot;base_link&quot;));// 计算扫描间隔时间scan_duration = current_scan_time - previous_scan_time;double secs = scan_duration.toSec(); ​ 这一部分代码计算了相邻两帧之间的位移 diff 和偏航角变化 diff_yaw。 NDT建图过程要求车辆尽量保持匀速行驶，由于相邻两帧时问差较小，所以车辆短时间内近似为匀速模型，利用x，y，z方向的位移变化与激光雷达扫描间隔的比值作为当前的速度 current_velocity。最后代码将当前位姿 current_pose 赋值于前一帧位姿previous_pose， 为下一次 NDT 配准提供计算初值。 123456789101112131415161718// 计算相邻位姿偏差 (curren_pos - previous_pos)diff_x = current_pose.x - previous_pose.x;diff_y = current_pose.y - previous_pose.y;diff_z = current_pose.z - previous_pose.z;diff_yaw = calcDiffForRadian(current_pose.yaw, previous_pose.yaw);diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);// 利用前后两帧扫描位置偏差与扫描间隔计算此时的瞬时速度current_velocity_x = diff_x / secs;current_velocity_y = diff_y / secs;current_velocity_z = diff_z / secs;// 当前位姿current_pose赋予imu当前位姿并更新校正current_pose_imu.x = current_pose.x;current_pose_imu.y = current_pose.y;current_pose_imu.z = current_pose.z;current_pose_imu.roll = current_pose.roll;current_pose_imu.pitch = current_pose.pitch;current_pose_imu.yaw = current_pose.yaw;//...(下略) ​ 这一部分代码主要负责地图的更新，每隔一定的距离会更新一次地图，这里的距离由 shift 表示。added_pose 是上一帧车辆的位姿，用于判断是否需要更新地图。当前后两帧距离差 shift 大于min_add scan_ shift 最小更新距离时，将转换后的点云数据*transformed scan ptr 加入到 map 全局地图，然后将当前位姿 current_pose 赋値于added_pose 进行位姿更新。最后把当前配准拼接后的点云数据 map_ptr 设置为下一次配准的输入目标点云。 12345678910111213141516171819202122232425 // 计算added_pose与current_pose间距离 double shift = sqrt(pow(current_pose.x - added_pose.x, 2.0) + pow(current_pose.y - added_pose.y, 2.0)); if (shift &gt;= min_add_scan_shift) { // 将经过坐标转换后的transformed_scan_ptr加到map中完成拼接 map += *transformed_scan_ptr; added_pose.x = current_pose.x; added_pose.y = current_pose.y; added_pose.z = current_pose.z; added_pose.roll = current_pose.roll; added_pose.pitch = current_pose.pitch; added_pose.yaw = current_pose.yaw; if (_method_type == MethodType::PCL_GENERIC) ndt.setInputTarget(map_ptr); //...(下略) } // 声明sensor_msgs::PointCloud2点云对象 sensor_msgs::PointCloud2::Ptr map_msg_ptr(new sensor_msgs::PointCloud2); // 数据类型转换 pcl::toROSMsg(*map_ptr, *map_msg_ptr); // 发布点云 ndt_map_pub.publish(*map_msg_ptr); //...(下略)} ⑤ odom_callback函数​ odom_callback 函数由ros::Subscriber odom_sub = nh.subscribe(“vehicle/odom”, 100000, odom_callback)所调用。odom_callback 函数以里程计接收到的数据作为函数参数，主要调用 odom_calc 初值计算函数，该函数以接收到的里程计数据时间戳作为输入参数，求得 NDT 的初始位姿估计。 12345static void odom_callback(const nav_msgs::Odometry::ConstPtr&amp; input){ odom = *input; odom_calc(input-&gt;header.stamp);} ​ odom_calc里程计初始位姿计算函数如下 12345678910111213141516171819202122232425262728293031static void odom_calc(ros::Time current_time){ static ros::Time previous_time = current_time; // 获取两帧时间差 double diff_time = (current_time - previous_time).toSec(); // 计算两帧时间间隔内的里程计旋转角度 double diff_odom_roll = odom.twist.twist.angular.x * diff_time; double diff_odom_pitch = odom.twist.twist.angular.y * diff_time; double diff_odom_yaw = odom.twist.twist.angular.z * diff_time; // 更新当前里程计位置的角度 current_pose_odom.roll += diff_odom_roll; current_pose_odom.pitch += diff_odom_pitch; current_pose_odom.yaw += diff_odom_yaw; // diff_distance为x方向的变化距离，offset为车身不稳定造成的计算偏差 double diff_distance = odom.twist.twist.linear.x * diff_time; offset_odom_x += diff_distance * cos(-current_pose_odom.pitch) * cos(current_pose_odom.yaw); offset_odom_y += diff_distance * cos(-current_pose_odom.pitch) * sin(current_pose_odom.yaw); offset_odom_z += diff_distance * sin(-current_pose_odom.pitch); offset_odom_roll += diff_odom_roll; offset_odom_pitch += diff_odom_pitch; offset_odom_yaw += diff_odom_yaw; // 对初始位置修正 guess_pose_odom.x = previous_pose.x + offset_odom_x; guess_pose_odom.y = previous_pose.y + offset_odom_y; guess_pose_odom.z = previous_pose.z + offset_odom_z; guess_pose_odom.roll = previous_pose.roll + offset_odom_roll; guess_pose_odom.pitch = previous_pose.pitch + offset_odom_pitch; guess_pose_odom.yaw = previous_pose.yaw + offset_odom_yaw; previous_time = current_time;} ⑥ imu_callback函数​ imu_callback函数由ros::Subscriber imu_sub = nh.subscribe(_imu_topic, 100000, imu_callback)调用。该函数主要是利用 imu_calc (input-&gt;header.stamp) 函数计算位置初值，为 NDT 配准提供初始位置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455static void imu_callback(const sensor_msgs::Imu::Ptr&amp; input){ if (_imu_upside_down) imuUpsideDown(input); // 接收到imu消息的时候获取当前时间戳 const ros::Time current_time = input-&gt;header.stamp; static ros::Time previous_time = current_time; // 计算前后两次接收消息的微小时间差 const double diff_time = (current_time - previous_time).toSec(); double imu_roll, imu_pitch, imu_yaw; // 声明用于转换的四元数 tf::Quaternion imu_orientation; // 将IMU采集到的四元数消息转化为TF类型 tf::quaternionMsgToTF(input-&gt;orientation, imu_orientation); // 初始化3*3旋转矩阵，使用getRPY获取当前rpy旋转角 tf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw); // 转化为弧度 imu_roll = wrapToPmPi(imu_roll); imu_pitch = wrapToPmPi(imu_pitch); imu_yaw = wrapToPmPi(imu_yaw); static double previous_imu_roll = imu_roll, previous_imu_pitch = imu_pitch, previous_imu_yaw = imu_yaw; const double diff_imu_roll = calcDiffForRadian(imu_roll, previous_imu_roll); const double diff_imu_pitch = calcDiffForRadian(imu_pitch, previous_imu_pitch); const double diff_imu_yaw = calcDiffForRadian(imu_yaw, previous_imu_yaw); imu.header = input-&gt;header; // 获取imu在x方向的线性加速度 imu.linear_acceleration.x = input-&gt;linear_acceleration.x; imu.linear_acceleration.y = 0; imu.linear_acceleration.z = 0; if (diff_time != 0) { // 若时间差不等于0，imu在工作，计算imu瞬时角速度 imu.angular_velocity.x = diff_imu_roll / diff_time; imu.angular_velocity.y = diff_imu_pitch / diff_time; imu.angular_velocity.z = diff_imu_yaw / diff_time; } else { // 否则角速度置0 imu.angular_velocity.x = 0; imu.angular_velocity.y = 0; imu.angular_velocity.z = 0; } // 计算位置初值，提供初始位置 imu_calc(input-&gt;header.stamp); previous_time = current_time; previous_imu_roll = imu_roll; previous_imu_pitch = imu_pitch; previous_imu_yaw = imu_yaw;} 3.2 ndt_matching节点解析​ ndt_matching节点首先读取points_map_loader发布的点云地图，将此地图设置为target。同时，使用上述2.2小节中voxel_grid_filter将激光雷达发布的/points_raw话题发布的/sensor_msgs/PointCloud2点云消息降采样，将降采样后的点云设置为source。此后利用ndt进行配准，得出齐次变换矩阵，可以得到车的几个坐标系的位置信息，从而进行定位。 3.2.1 启动方法 终端启动: roslaunch lidar_localizer ndt_matching.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方Computing 选项卡 -&gt; Localization/ lidar_localizer -&gt; ndt_matching，单击 [app] 按钮可更改设置等参数。 3.2.2 程序路径12345//源代码路径~/autoware.ai/src/autoware/core_perception/lidar_localizer/nodes/ndt_matching/ndt_matching.cpp//launch启动文件路径~/autoware.ai/src/autoware/core_perception/lidar_localizer/launch/ndt_matching.launch 3.2.3 参数详情 参数名 类型 说明 method_type int ndt使用算法类型 use_gnss bool 是否使用gnss use_odom bool 是否使用里程计减少误差 use_imu bool 是否使用IMU减少误差 imu_upside_down bool IMU坐标系是否翻转 imu_topic String IMU话题名 queue_size int 消息缓冲区大小 offset String 位姿偏移校正 get_height bool z轴高度较正 use_local_transform bool 使用本地tf sync bool 是否将话题名/points_raw映射为/sync_drivers/points_raw output_log_data bool 是否输出log output_tf_frame_id String tf frameID 默认为base_link gnss_reinit_fitness double 比较fitness_core的参考，默认值为500.0 3.2.4 订阅话题名 话题名 消息类型 /config/ndt autoware_config_msgs/ConfigNDT /gnss_pose geometry_msgs/PoseStamped /initialpose geometry_msgs/PoseWithCovarianceStamped /filtered_points sensor_msgs/PointCloud2 /vehicle/odom nav_msgs/Odometry /imu_raw sensor_msgs/Imu /vehicle/twist geometry_msgs/TwistStamped 3.2.5 发布话题名 话题名 消息类型 /predict_pose geometry_msgs::PoseStamped /predict_pose_imu geometry_msgs::PoseStamped /predict_pose_odom geometry_msgs::PoseStamped /predict_pose_imu_odom geometry_msgs::PoseStamped /ndt_pose geometry_msgs::PoseStamped /localizer_pose geometry_msgs::PoseStamped /estimate_twist geometry_msgs::TwistStamped /estimated_vel_mps std_msgs::Float32 /estimated_vel_kmph std_msgs::Float32 /estimated_vel geometry_msgs::Vector3Stamped /time_ndt_matching std_msgs::Float32 /ndt_stat autoware_msgs::NDTStat /ndt_reliability std_msgs::Float32 3.2.6 代码注解① 流程简介​ ndt_matching节点与ndt_mapping节点结构相似，不同之处在于ndt_matching利用scan_to_matching方法实现定位。该方法将已知的高精度地图map作为全局地图global map，利用激光雷达获取当前帧的激光点云数据scan，与固定不动的全局地图global_map进行ndt配准，求出最终车体相对于全局地图的位姿，从而实现精准定位。具体步骤如下: ​ ①由激光雷达获取的激光点云数据降采样作为 NDT 算法的输入源点云，这部分与 ndt mapping 一致​ ②将全局地图 global map 作为 NDT 算法的输入目标点云；​ ③此处 GNSS 的主要目标是实现重定位，当 imu 与odom 产生累计误差影响到NDT 配准算法的效果，或者是使用 gnss 时并未将 gnss 位姿初始化的时候，此时将当前gnss 位姿作为准确的车辆位姿信息，它能够及时纠正 imu 与odom 的累计误差；​ ④利用 imu, odom 等传感器获取 NDT 所需的初始位姿估计；​ ⑤进行 NDT 配准;​ ⑥求得车辆相对于 全局地图的位姿 current pose。 ​ ndt matching 节点的main 函数(源码略)与 ndt mapping 节点很相似，主要进行话题消息的发布，发布的话题有/predict pose (预测的位姿），/predict pose imu(利用imu 预测的位姿），/predict_pose_odom （利用里程计预测得到的位姿），/predict_pose_imu_odom (利用里程计与 imu 联合得到的位姿)等参数。订阅的话题有config/ndt (ndt 配置参数），gnss_pose(使用gnss 得到的位姿)，initial_pos(初始位姿)，filtered_points（过滤处理后的激光点集），/vehicle/odom（里程汁消息）。 ② param_callback函数​ param_callback 回调函数的参数为 NDT 配置参数消息(autoware_config_msgs::ConfigNDT.msg）。函数判断 _use_gnss 与 NDT 配置参数 init_pos_gnss 是否相等，use_gnss 表示使用 gnss 进行位姿估计，init_pos_gnss 用来表示 gnss 的初始位置。如果 use_gnss与 init_pos_gnss 不相等，则 init_pos_set=0, 表示未进行位姿初始化。当 use_gnss==0, 即不使用 gnss, 以及 NDT 参数配置中的车辆初始位姿与 initial_pose 不相等的时候，令 init_pos_set=0。该代码主要判断 gnss 使用参数与 gnss 初始位姿是否初始化。 123456789101112131415static void param_callback(const autoware_config_msgs::ConfigNDT::ConstPtr&amp; input){ if (_use_gnss != input-&gt;init_pos_gnss) { // 使用gnss时要对gnss位置初始化，如果两者不匹配，将初始位置init_pos_set置为0 init_pos_set = 0; } else if (_use_gnss == 0 &amp;&amp; (initial_pose.x != input-&gt;x || initial_pose.y != input-&gt;y || initial_pose.z != input-&gt;z || initial_pose.roll != input-&gt;roll || initial_pose.pitch != input-&gt;pitch || initial_pose.yaw != input-&gt;yaw)) { init_pos_set = 0; } _use_gnss = input-&gt;init_pos_gnss; ​ 该代码主要对 NDT 配准的参数进行设置，根据方法类型的不同，将 ConfigNDT消息中的参数作为输入加载到 NDT 配准算法中。其中加载的 NDT 参数有:收敛条件、最大步长、分辨率(网格划分大小)以及最大迭代次数。 1234567891011121314151617181920if (input-&gt;step_size != step_size){ step_size = input-&gt;step_size; // 按照方法类型不同使用ndt.setResolution(ndt_res)函数设置NDT网格大小 if (_method_type == MethodType::PCL_GENERIC) ndt.setStepSize(step_size); //...(下略)}// 设置ndt算法收敛条件if (input-&gt;trans_epsilon != trans_eps){ trans_eps = input-&gt;trans_epsilon; //...(下略)}// 设置最大迭代次数if (input-&gt;max_iterations != max_iter){ max_iter = input-&gt;max_iterations; //...(下略)} ​ 该代码块主要判断是否使用 GNSS 、是否已初始化车辆位姿，当未使用 GNSS 并且未初始化车辆位姿时，利用 NDT 配置消息进行位姿初始化。当使用局部变换的时候，需要补偿一个局部变换矩阵 local_transform.inverse()，从而求得车辆相对于全局地图 map 的初始位姿。局部变换矩阵 local_transform 表示的是world 坐标系与地面坐标系 map 之间的变换关系。 123456789101112131415161718192021222324252627 if (_use_gnss == 0 &amp;&amp; init_pos_set == 0) { // 如果未使用gnss且未初始化车辆位姿，则用ndt参数配置消息中的位姿进行初始化 initial_pose.x = input-&gt;x; //...(下略) if (_use_local_transform == true) { // 如果使用局部变换，在求初始位姿时要补偿一个局部变换矩阵local_transform.inverse() tf2::Vector3 v(input-&gt;x, input-&gt;y, input-&gt;z); tf2::Quaternion q; q.setRPY(input-&gt;roll, input-&gt;pitch, input-&gt;yaw); tf2::Transform transform(q, v); initial_pose.x = (local_transform.inverse() * transform).getOrigin().getX(); initial_pose.y = (local_transform.inverse() * transform).getOrigin().getY(); initial_pose.z = (local_transform.inverse() * transform).getOrigin().getZ(); tf2::Matrix3x3 m(q); m.getRPY(initial_pose.roll, initial_pose.pitch, initial_pose.yaw); std::cout &lt;&lt; &quot;initial_pose.x: &quot; &lt;&lt; initial_pose.x &lt;&lt; std::endl; //...(下略) } // 设置初始位姿 localizer_pose.x = initial_pose.x; localizer_pose.y = initial_pose.y; //...(下略) }} ③ gnss_callback函数​ gnss_callback主要实现GNSS重定位功能，用来纠正IMU与里程计的积分累计误差，当ndt配准结果较差，也需要GNSS重定位来提供配准初值。 123456789101112131415161718192021222324252627282930static void gnss_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; input){ // 将GNSS的旋转参数保存至tf类型的旋转四元数 tf2::Quaternion gnss_q(input-&gt;pose.orientation.x, input-&gt;pose.orientation.y, input-&gt;pose.orientation.z, input-&gt;pose.orientation.w); // 将位置四元数转换为旋转矩阵gnss_m tf2::Matrix3x3 gnss_m(gnss_q); // current_gnss_pose表示当前GNSS的位置 pose current_gnss_pose; current_gnss_pose.x = input-&gt;pose.position.x; current_gnss_pose.y = input-&gt;pose.position.y; current_gnss_pose.z = input-&gt;pose.position.z; // 利用gnss_m.getRPY得到旋转矩阵的RPY旋转角，分别以三个参数输出 gnss_m.getRPY(current_gnss_pose.roll, current_gnss_pose.pitch, current_gnss_pose.yaw); static pose previous_gnss_pose = current_gnss_pose; //记录当前接受到GNSS消息的时间 ros::Time current_gnss_time = input-&gt;header.stamp; static ros::Time previous_gnss_time = current_gnss_time; //如果使用GNSS且初始位置为0或fitness_score&gt;=500,则进行GNSS重定位，并计算当前位置与先前位置的偏差 //注意：ndt的fitness_score越低越好，一般小于1 if ((_use_gnss == 1 &amp;&amp; init_pos_set == 0) || fitness_score &gt;= _gnss_reinit_fitness) { previous_pose.x = previous_gnss_pose.x; previous_pose.y = previous_gnss_pose.y; //...(下略) } previous_gnss_pose.x = current_gnss_pose.x; //...(下略)} ④ map_callback函数​ map_callback函数主要用于载入激光雷达数据作为初始全局地图map，并将初始全局地图map作为ndt配准算法的目标点云。函数按收到的 sensor_msgs::PointCloud2 类型的点云数据为输入参数，首先判断地图尺寸 points_map_num 与输入点云的宽度是否相等。初始状态时 points_map_num 默认为 0。车辆处于初始状态时，激光点云地图未加载，此时更新 map 地图大小为输入激光点云的大小。利用 pcl::fromROSMsg 函数将输入点云进行转换，并保存至map。最后根据方法类型的不同，对 NDT 参数进行设置，主要设置网格大小、NDT 算法的目标点云、最大迭代次数、最大迭代步长以及收敛阈值Epsilon，添加最大迭代次数能够增加程序鲁棒性，避免程序在错误迭代方向运行时间过长。最后代码利用 4 阶单位矩阵作为初始变换矩阵，来对第一帧点云进行配准，输出结果保存至output_cloud，至此地图加载成功。下面为详细代码注解。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static void map_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input){ // 若points_map_num不等于输入点云宽度，更新点云参数 if (points_map_num != input-&gt;width) { std::cout &lt;&lt; &quot;Update points_map.&quot; &lt;&lt; std::endl; points_map_num = input-&gt;width; // 将输入激光点云类型从sensor_msgs::PointCloud2转换为pcl类型 pcl::fromROSMsg(*input, map); if (_use_local_transform == true) { // 如果局部变换存在，向外广播局部变换 // local_transform表示world坐标系与map坐标系之间的变换 tf2_ros::Buffer tf_buffer; tf2_ros::TransformListener tf_listener(tf_buffer); geometry_msgs::TransformStamped local_transform_msg; try { local_transform_msg = tf_buffer.lookupTransform(&quot;map&quot;, &quot;world&quot;, ros::Time::now(), ros::Duration(3.0)); } catch (tf2::TransformException&amp; ex) { ROS_ERROR(&quot;%s&quot;, ex.what()); } // 将map坐标系转换为world坐标系 tf2::fromMsg(local_transform_msg, local_transform); pcl::transformPointCloud(map, map, tf2::transformToEigen(local_transform_msg).matrix().inverse().cast&lt;float&gt;()); } pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(map)); // 根据方法类型不同设置要进行ndt配准的点云 if (_method_type == MethodType::PCL_GENERIC) { pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; new_ndt; pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;); // 设置网格大小 new_ndt.setResolution(ndt_res); // 将map_ptr作为ndt输入点云 new_ndt.setInputTarget(map_ptr); // 设置最大迭代次数 new_ndt.setMaximumIterations(max_iter); // 设置步长大小 new_ndt.setStepSize(step_size); new_ndt.setTransformationEpsilon(trans_eps); // 利用单位矩阵作为初始坐标变换矩阵来进行ndt配准 // 此时为第一帧点云配准 new_ndt.align(*output_cloud, Eigen::Matrix4f::Identity()); pthread_mutex_lock(&amp;mutex); ndt = new_ndt; pthread_mutex_unlock(&amp;mutex); } //...（下略） // 地图载入成功 map_loaded = 1; }} ⑤ points_callback 函数​ 该回调函数主要进行多传感器之间的融合定位。函数首先融合 IMU 和odom 数据得到较为准确的位置估计，然后利用 filtered_points 将点云数据加入到 NDT 的算法内，计算得到一个 NDT 的预测位姿。最后，该位姿与 IMU 和 odom 融合得到的位姿进行比较，得出更准确的位姿。 ​ Points_callback 回调函数以接收到的激光点云数据为输入参数，当全局点云地图载入成功并且车辆位姿初始化成功之后，ndt_matching 开始配准。代码利用std:chrono::system_clock::now 函数来获取当前系统的时间并将其作为定位匹配的起始时间 matching_start。然后获取当前接收到的激光点云时间戳作为当前扫描时间current_scan_time。利用 pcl::fromROSMsg 函数将输入点云转换为 pcl::PointCloud&lt; pcl:PointXYZ &gt;类型的点云数据并存储于 filtered_scan。最后将filtered_scan 作为 NDT 算法的输入源点云，与 NDT 算法目标点云全局地图 map 进行匹配。 12345678910111213141516171819202122232425262728293031323334353637static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input){ health_checker_ptr_-&gt;CHECK_RATE(&quot;topic_rate_filtered_points_slow&quot;, 8, 5, 1, &quot;topic filtered_points subscribe rate slow.&quot;); // 默认地图载入状态为0 if (map_loaded == 1 &amp;&amp; init_pos_set == 1) { // 获取配准开始时间 matching_start = std::chrono::system_clock::now(); static tf2_ros::TransformBroadcaster br; tf2::Transform transform; tf2::Quaternion predict_q, ndt_q, current_q, localizer_q; pcl::PointXYZ p; // 声明pcl::PointCloud&lt;pcl::PointXYZ&gt;类型的点云数据用来储存过滤后的点云 pcl::PointCloud&lt;pcl::PointXYZ&gt; filtered_scan; // 获取当前接收点云的扫描时间 ros::Time current_scan_time = input-&gt;header.stamp; static ros::Time previous_scan_time = current_scan_time; // 将当前sensor_msgs::PointCloud2转化为PCL类型 pcl::fromROSMsg(*input, filtered_scan); pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(filtered_scan)); // 获取点云数量 int scan_points_num = filtered_scan_ptr-&gt;size(); // 单位矩阵初始化车身底盘base_link和localizer关于原点的坐标变换矩阵 Eigen::Matrix4f t(Eigen::Matrix4f::Identity()); // base_link Eigen::Matrix4f t2(Eigen::Matrix4f::Identity()); // localizer // 声明配准起止时间与getFitnessScore起止时间 std::chrono::time_point&lt;std::chrono::system_clock&gt; align_start, align_end, getFitnessScore_start, getFitnessScore_end; static double align_time, getFitnessScore_time = 0.0; pthread_mutex_lock(&amp;mutex); // 按照不同方法类型将filtered_scan_ptr作为ndt输入点云 if (_method_type == MethodType::PCL_GENERIC) ndt.setInputSource(filtered_scan_ptr); //...(下略) ​ 该代码主要计算得出 NDT 配准算法所需要的初始位姿。offset 有三种情况，当 offset 为线性值的时候，利用匀速运动模型计算出 offset 的大小;当 offset 为二次模型，即加速度不为0的时候。offset 的x与y方向的分量利用vt+(1/2)at^2求出，y方向的分量与偏航角保持匀速运动模型；第三种情况是 offset 为 0。代码利用previous_pose (前一帧位姿)+offset(两帧时间内的偏差量)得到 predict_pose (当前预测的车辆位姿)。然后代码根据 imu、odom 的使用情况估计 NDT 所需当前初始位姿，这一步与ndt mapping 类似。最后如果使用传感器来获取位姿，则将相应传感器估计得到的当前位姿作为 predict_pose_for_ndt (ndt 配准所需的初值），否则将 predict_pose (当前预测的车辆位姿）作为 NDT 配准所需的初值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 计算前后两帧激光扫描时间差 double diff_time = (current_scan_time - previous_scan_time).toSec(); // _offset为线性时，位置偏差和航向角等于速度乘前后帧时间差 if (_offset == &quot;linear&quot;) { offset_x = current_velocity_x * diff_time; offset_y = current_velocity_y * diff_time; offset_z = current_velocity_z * diff_time; offset_yaw = angular_velocity * diff_time; } // _offset为二次类型，则利用vt+at^2表示x、y，z、yaw与线性一致 else if (_offset == &quot;quadratic&quot;) { offset_x = (current_velocity_x + current_accel_x * diff_time) * diff_time; offset_y = (current_velocity_y + current_accel_y * diff_time) * diff_time; offset_z = current_velocity_z * diff_time; offset_yaw = angular_velocity * diff_time; } else if (_offset == &quot;zero&quot;) { offset_x = 0.0; offset_y = 0.0; offset_z = 0.0; offset_yaw = 0.0; } // 估计位置的坐标xyz=前一帧+偏移量、rp角度与前一帧角度相等，yaw随车变化 predict_pose.x = previous_pose.x + offset_x; predict_pose.y = previous_pose.y + offset_y; predict_pose.z = previous_pose.z + offset_z; predict_pose.roll = previous_pose.roll; predict_pose.pitch = previous_pose.pitch; predict_pose.yaw = previous_pose.yaw + offset_yaw; // 根据imu和odom使用情况，采用不同方法对ndt配准的初始位置进行计算，与mapping保持一致 if (_use_imu == true &amp;&amp; _use_odom == true) imu_odom_calc(current_scan_time); if (_use_imu == true &amp;&amp; _use_odom == false) imu_calc(current_scan_time); if (_use_imu == false &amp;&amp; _use_odom == true) odom_calc(current_scan_time); // 根据使用方法不同，赋予ndt位置预测初值 pose predict_pose_for_ndt; if (_use_imu == true &amp;&amp; _use_odom == true) predict_pose_for_ndt = predict_pose_imu_odom; else if (_use_imu == true &amp;&amp; _use_odom == false) predict_pose_for_ndt = predict_pose_imu; else if (_use_imu == false &amp;&amp; _use_odom == true) predict_pose_for_ndt = predict_pose_odom; else predict_pose_for_ndt = predict_pose; ​ 该部分代码主要求出激光雷达坐标系相对于全局地图坐标系的初始变换矩阵init_guess, 该矩阵的计算需要补偿一个变换矩阵tf_btol,即车身底盘坐标系 base_link到激光雷达坐标系的变换矩阵，这一变换矩阵由 main 函数得出。代码获取当前系统时间戳作为 NDT 配准起始时间，然后利用 ndt.align(output_cloud, init_guess) 函数以初始变换矩阵 init_guess 为参数，得到输出点云 output_cloud，然后计算 NDT 配准的结果，最后计算配准时间。t tf_btol.inverse函数得到车身底盘相对于全局地图坐标系的最终变换矩阵t2。 1234567891011121314151617181920212223242526272829303132333435363738394041// 将predict_pose_for_ndt位置的xyz坐标作为init_translation初始平移的构造函数参数Eigen::Translation3f init_translation(predict_pose_for_ndt.x, predict_pose_for_ndt.y, predict_pose_for_ndt.z);Eigen::AngleAxisf init_rotation_x(predict_pose_for_ndt.roll, Eigen::Vector3f::UnitX());Eigen::AngleAxisf init_rotation_y(predict_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());Eigen::AngleAxisf init_rotation_z(predict_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());// init_guess表示激光雷达坐标系相对于全局地图坐标系的坐标变换矩阵Eigen::Matrix4f init_guess = (init_translation * init_rotation_z * init_rotation_y * init_rotation_x) * tf_btol;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);// 根据不同方法进行ndt配准if (_method_type == MethodType::PCL_GENERIC){ // 获取当前时间戳作为配准开始时间 align_start = std::chrono::system_clock::now(); // 利用初始变换矩阵init_guess进行ndt配准，将结果存到output_cloud ndt.align(*output_cloud, init_guess); // 获取配准结束时间 align_end = std::chrono::system_clock::now(); // 是否收敛 has_converged = ndt.hasConverged(); // 获取ndt配准最终变换矩阵 t = ndt.getFinalTransformation(); // 得到迭代次数 iteration = ndt.getFinalNumIteration(); getFitnessScore_start = std::chrono::system_clock::now(); fitness_score = ndt.getFitnessScore(); getFitnessScore_end = std::chrono::system_clock::now(); trans_probability = ndt.getTransformationProbability();}//...(下略)// 计算配准时间align_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(align_end - align_start).count() / 1000.0;// 计算此时车身底盘相对于全局地图坐标系的最终变换矩阵t2 = t * tf_btol.inverse();getFitnessScore_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(getFitnessScore_end - getFitnessScore_start).count() / 1000.0;pthread_mutex_unlock(&amp;mutex); ​ 该代码主要计算当前激光雷达与车身底盘相对于全局地图坐标系的位姿。激光雷达 localizer 相对于全局地图 map 的旋转矩阵mat_l和位置坐标 localizer_pose.x, localizer_pose.y, localizer_pose.z 由 NDT 配准得到的变换矩阵 _t_ 求得。代码利用mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1） 函数求出激光雷达的旋转欧拉角rpy。同理，利用 _t2_ (车身底盘相对于 map 的变换矩阵）求出ndt_pose(ndt 算法得到的车体相对于 map 的位姿)。然后代码将 NDT 配准算法得到的车辆定位 ndt_pose 与 ndt 算法提供的初值 predict_pose_for_ndt 进行比较，求出两者之间的误差 predict_pose_error。当误差小于阈值 PREDICT_POSE_THRESHOLD时，使用ndt_pose 作为当前位姿估计 current_pose，否则使用 predict_pose_for_ndt作为 current_pose。 123456789101112131415161718192021222324252627282930// localizer的旋转矩阵tf2::Matrix3x3 mat_l;// 将ndt最终变换的矩阵赋予mat_lmat_l.setValue(static_cast&lt;double&gt;(t(0, 0)), static_cast&lt;double&gt;(t(0, 1)), static_cast&lt;double&gt;(t(0, 2)), static_cast&lt;double&gt;(t(1, 0)), static_cast&lt;double&gt;(t(1, 1)), static_cast&lt;double&gt;(t(1, 2)), static_cast&lt;double&gt;(t(2, 0)), static_cast&lt;double&gt;(t(2, 1)), static_cast&lt;double&gt;(t(2, 2)));// 更新localizer_pose的位置向量localizer_pose.x = t(0, 3);localizer_pose.y = t(1, 3);localizer_pose.z = t(2, 3);// 最终变换的旋转rpy角度值赋予localizer_pose的rpy角度值mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);// 相对于base_link的旋转矩阵mat_b由t2变换矩阵赋值tf2::Matrix3x3 mat_b; // base_linkmat_b.setValue(static_cast&lt;double&gt;(t2(0, 0)), static_cast&lt;double&gt;(t2(0, 1)), static_cast&lt;double&gt;(t2(0, 2)), static_cast&lt;double&gt;(t2(1, 0)), static_cast&lt;double&gt;(t2(1, 1)), static_cast&lt;double&gt;(t2(1, 2)), static_cast&lt;double&gt;(t2(2, 0)), static_cast&lt;double&gt;(t2(2, 1)), static_cast&lt;double&gt;(t2(2, 2)));// ndt_pose的坐标由车身底盘相对于map的平移向量来赋值，计算车辆在全局地图坐标系下的位置ndt_pose.x = t2(0, 3);ndt_pose.y = t2(1, 3);ndt_pose.z = t2(2, 3);mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);// 计算ndt_pose和predict_pose间的误差predict_pose_error = sqrt((ndt_pose.x - predict_pose_for_ndt.x) * (ndt_pose.x - predict_pose_for_ndt.x) + (ndt_pose.y - predict_pose_for_ndt.y) * (ndt_pose.y - predict_pose_for_ndt.y) + (ndt_pose.z - predict_pose_for_ndt.z) * (ndt_pose.z - predict_pose_for_ndt.z));//...(下略) ​ 该部分代码主要发布 base link 坐标系到全局地图坐标系 map 之间的变换关系，主要通过 sendTransform 函数进行变换消息的广播，其中，第一个参数为 base link到 map 的坐标变换 transform，第二个参数为发布时间，第三个参数为父坐标系 map,最后一个参数为子坐标系 base_link。然后计算并发送ndt_matching 匹配定位的耗时time_ndt_matching.data，最后发布 NDT 的状态参数信息，current_scan_time, time_ndt_matching.data, iteration, fitness_score, current_velocity, current _accel. 123456789101112131415161718192021222324252627282930313233343536373839//...(上略)// 注：current_pose 经由 vel_pose_mux 发布// 发布车辆预测位姿predict_pose_pub.publish(predict_pose_msg);health_checker_ptr_-&gt;CHECK_RATE(&quot;topic_rate_ndt_pose_slow&quot;, 8, 5, 1, &quot;topic ndt_pose publish rate slow.&quot;);// 发布ndt位姿ndt_pose_pub.publish(ndt_pose_msg);// 发布激光雷达当前预测位姿localizer_pose_pub.publish(localizer_pose_msg);// 发布 TF &quot;base_link&quot; -&gt; &quot;map&quot;transform.setOrigin(tf2::Vector3(current_pose.x, current_pose.y, current_pose.z));transform.setRotation(current_q);if (_use_local_transform == true){ transform = local_transform * transform;}tf2::Stamped&lt;tf2::Transform&gt; tf(transform, current_scan_time, &quot;map&quot;);geometry_msgs::TransformStamped tf_msg = tf2::toMsg(tf);tf_msg.child_frame_id = _output_tf_frame_id;br.sendTransform(tf_msg);// 记录匹配结束时间matching_end = std::chrono::system_clock::now();// 记录匹配耗时，存入time_ndt_matching.data并发布exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(matching_end - matching_start).count() / 1000.0;time_ndt_matching.data = exe_time;health_checker_ptr_-&gt;CHECK_MAX_VALUE(&quot;time_ndt_matching&quot;, time_ndt_matching.data, 50, 70, 100, &quot;value time_ndt_matching is too high.&quot;);// 发布配准时间信息time_ndt_matching_pub.publish(time_ndt_matching);// 设置预计速度信息/estimate_twist并发布estimate_twist_msg.header.stamp = current_scan_time;//...(下略)estimated_vel_pub.publish(estimate_vel_msg);// 设置ndt状态信息/ndt_stat并发布ndt_stat_msg.header.stamp = current_scan_time;//...(下略)ndt_reliability_pub.publish(ndt_reliability); ​ 最后一部分代码更新当前位姿 current_pose 为上一帧的位姿 previous_pose，速度做同样处理，为下次的ndt_matching 匹配定位做铺垫。ndt_matching 节点的odom_callback 与 imu_callback 这两个回调函数与 ndt_mapping节点里的同名回调函数内容是相同的，这里不再赘述。 12345678910111213141516171819 // 相邻两帧的位姿偏差归零 offset_imu_x = 0.0; //...(下略) offset_odom_x = 0.0; //...(下略) offset_imu_odom_x = 0.0; //...(下略) // 更新当前位姿为上一帧位姿 previous_pose.x = current_pose.x; //...(下略) // 更新当前扫描时间为上一帧扫描时间 previous_scan_time = current_scan_time; // 更新速度 previous_previous_velocity = previous_velocity; //...(下略) }} ⑥ thread_func函数​ thread_func函数主要是额外开启一个线程检测并更新地图。 12345678910111213141516void* thread_func(void* args){ // 开启一个线程检测并更新地图 ros::NodeHandle nh_map; ros::CallbackQueue map_callback_queue; nh_map.setCallbackQueue(&amp;map_callback_queue); ros::Subscriber map_sub = nh_map.subscribe(&quot;points_map&quot;, 10, map_callback); ros::Rate ros_rate(10); while (nh_map.ok()) { map_callback_queue.callAvailable(ros::WallDuration()); ros_rate.sleep(); } return nullptr;} 3.3 参考文献 [1] Biber P, Straßer W. The normal distributions transform: A new approach to laser scan matching[C] IROS 2003 . IEEE, 2003, 3: 2743-2748. [2] Merten H. The three-dimensional normal-distributions transform[J]. threshold, 2008, 10: 3. [3] 双愚. PCL(Point Cloud Library)学习指南&amp;资料推荐（2023版）[OB/OL]. [2023-02-05].https://zhuanlan.zhihu.com/p/268524083. [4] Badue C, Guidolini R, Carneiro R V, et al. Self-driving cars: A survey [J]. arXiv: Robotics, 2019. [5] 高翔,张涛等. 视觉 SLAM 十四讲：从理论到实践[M]，北京：电子工业出版社，2017. [6] Adam Shan. 无人驾驶汽车系统入门(十三）一正态分布变换 (NDT) 配准与无人车定位[DB/OL]. [2020-04-11]. https://blog.csdn.net/AdamShan/article/details/79230612. [7] Martin M. The Three-dimensional normal-distributions transform - An efficient representation for registration, surface analysis, and loop detection[D]. Orebro: Orebro University, 2009. [8] 田大新,段续庭等. Autoware与自动驾驶技术，北京：科学出版社，2020. 四、Autoware 决策规划模块解析​ Autoware的决策规划模块主要时基于感知的输出结果，进行全局路径规划和局部路径规划。全局路径规划在车辆启动或重启的时候被确定，局部路径根据车辆的状态实时更新。例如，如果车辆在障碍物前或在停止线前，车辆状态变为“stop”，那么车辆的速度就被规划为0。如果车辆遇到一个障碍物且状态为“avoid”，那么局部跟踪路径就会被重新规划绕过障碍物，基础节点及他们之间的关系（话题之间的订阅/发布）如下图所示。 ​ 本节对Autoware决策规划模块内的基础ROS节点（waypoint_loader, waypoint_replanner, lane_rule, lane_select, astar_avoid,velocity_set, pure_pursuit等节点）做简略分析。 4.1 节点waypoint_loader​ 节点waypoint_loader的主要作用：从本地文件加载采集的轨迹点。 4.1.1 启动方法 终端启动: roslaunch waypoint_maker waypoint_loader.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方computing 选项卡 -&gt; Motion Planning -&gt;waypoint_maker-&gt;waypoint_loader，单击 [app] 按钮可更改设置等参数。 4.1.2 程序路径12//源代码路径src/autoware/core_planning/waypoint_maker/nodes/waypoint_loader 4.1.3 参数详情 参数名 类型 说明 multi_lane_csv string 路标点文件 4.1.4 主要结构体​ autoware_msg::Lane结构体 12345678910111213autoware_msgs::Lane{ Header header int32 increment int32 lane_id Waypoint[] waypoints uint32 lane_index float32 cost float32 closest_object_distance float32 closest_object_velocity bool is_blocked} 123456789std_msgs::Header{ //序列号 uint32 seq //时间戳 time stamp //表示数据来源于哪一个frame string frame_id} 123456789101112131415161718192021222324252627282930313233autoware_msgs::Waypoint{ //全局id int32 gid //局部id int32 lid //位姿信息 geometry_msgs/PoseStamped pose //速度，角速度等信息 geometry_msgs/TwistStamped twist //道路信息 DTLane dtlane int32 change_flag //路点信息 WaypointState wpstate uint32 lane_id uint32 left_lane_id uint32 right_lane_id uint32 stop_line_id float32 cost float32 time_cost # Lane Direction # FORWARD = 0 # FORWARD_LEFT = 1 # FORWARD_RIGHT = 2 # BACKWARD = 3 # BACKWARD_LEFT = 4 # BACKWARD_RIGHT = 5 # STANDSTILL = 6 uint32 direction} 1234567891011121314151617181920212223geometry_msgs/PoseStamped{ Header header Pose pose}geometry_msgs/Pose{ Point position Quaternion orientation}geometry_msgs/Point{ float64 x float64 y float64 z}geometry_msgs/Quaternion{ float64 x float64 y float64 z float64 w} 12345678910111213141516geometry_msgs/TwistStamped{ Header header Twist twist}geometry_msgs/Twist{ Vector3 linear Vector3 angular}geometry_msgs/Vector3{ float64 x float64 y float64 z} 4.1.5 代码注解① main函数​ main函数在waypoint_loader_node.cpp中，节点的功能主要通过WaypointLoaderNode对象的run函数实现。 1234567int main(int argc, char** argv){ ros::init(argc, argv, &quot;waypoint_loader&quot;); waypoint_maker::WaypointLoaderNode wln; wln.run(); return 0;} ② run函数​ 读取存储的轨迹点文件数据，并发布至话题“/based/lane_waypoints_raw” 12345678910void WaypointLoaderNode::run(){ multi_file_path_.clear(); parseColumns(multi_lane_csv_, &amp;multi_file_path_); autoware_msgs::LaneArray lane_array; createLaneArray(multi_file_path_, &amp;lane_array); lane_pub_.publish(lane_array); output_lane_array_ = lane_array; ros::spin();} ③ parseColumns函数​ parseColumns函数以”，“ 作为分隔符号将字符串line分成若干段，并将其中的空格全部去除，依次储存至字符串向量columns中 123456789101112131415161718192021222324void parseColumns(const std::string&amp; line, std::vector&lt;std::string&gt;* columns){ std::istringstream ss(line); std::string column; //以”，“为分隔符截取字符串中的每一段 while (std::getline(ss, column, ',')) { //将每段字符串中的空格删除 while (1) { //返回区间[begin()，end()）中第一个值等于&quot; &quot;的元素位置；若未找到，返回end。返回的是迭代器或指针，即位置信息 auto res = std::find(column.begin(), column.end(), ' '); if (res == column.end()) { break; } column.erase(res); } if (!column.empty()) { columns-&gt;emplace_back(column); } }} ④ createLaneArray函数​ 将paths中各个本地路径对应文件中包含的信息分别填入lane 中，再将lane依次填入lane_array 123456789101112131415161718192021222324252627282930void WaypointLoaderNode::createLaneWaypoint(const std::string&amp; file_path, autoware_msgs::Lane* lane){ //检查文件file_path中数据是否合规 if (!verifyFileConsistency(file_path.c_str())) { ROS_ERROR(&quot;lane data is something wrong...&quot;); return; } ROS_INFO(&quot;lane data is valid. publishing...&quot;); //判断文件数据存储格式 FileFormat format = checkFileFormat(file_path.c_str()); std::vector&lt;autoware_msgs::Waypoint&gt; wps; if (format == FileFormat::ver1) { loadWaypointsForVer1(file_path.c_str(), &amp;wps); } else if (format == FileFormat::ver2) { loadWaypointsForVer2(file_path.c_str(), &amp;wps); } else { //读取文件内容存入waypoints中 loadWaypointsForVer3(file_path.c_str(), &amp;wps); } lane-&gt;header.frame_id = &quot;/map&quot;; lane-&gt;header.stamp = ros::Time(0); lane-&gt;waypoints = wps;} ⑤ verifyFileConsistency函数​ verifyFileConsistency函数的作用时“验证文件一致性”。首先ifstream以输入的方式打开filename，如果打开失败则直接返回失败；如果成功则执行checkFileFormat函数，文件格式以下图为例 1234567891011121314151617181920212223242526272829303132333435363738bool WaypointLoaderNode::verifyFileConsistency(const char* filename){ ROS_INFO(&quot;verify...&quot;); std::ifstream ifs(filename); if (!ifs) { return false; } // 检查该文件内数据的存储格式 FileFormat format = checkFileFormat(filename); ROS_INFO(&quot;format: %d&quot;, static_cast&lt;int&gt;(format)); if (format == FileFormat::unknown) { ROS_ERROR(&quot;unknown file format&quot;); return false; } std::string line; //删掉第一行 std::getline(ifs, line); size_t ncol = format == FileFormat::ver1 ? 4 // x,y,z,velocity : format == FileFormat::ver2 ? 5 // x,y,z,yaw,velocity : countColumns(line); //从第二行开始，检验每一行列数是否跟第一行列数一致 while (std::getline(ifs, line)) { if (countColumns(line) != ncol) { return false; } } return true;} ⑥ checkFileFormat函数​ 主要作用为判断文件格式 12345678910111213141516171819202122232425262728293031323334FileFormat WaypointLoaderNode::checkFileFormat(const char* filename){ std::ifstream ifs(filename); if (!ifs) { return FileFormat::unknown; } // 读取第一行 std::string line; std::getline(ifs, line); // 分析第一行 std::vector&lt;std::string&gt; parsed_columns; parseColumns(line, &amp;parsed_columns); // 检查第一个元素是否由数字组成 // Note: 浮点型数字因为包含小数点，所以会返回False if (!std::any_of(parsed_columns.at(0).cbegin(), parsed_columns.at(0).cend(), isdigit)) { return FileFormat::ver3; } // 如果元素只由数字组成，则以“，”作为分隔符，计算此行有几个元素组成 int num_of_columns = countColumns(line); ROS_INFO(&quot;columns size: %d&quot;, num_of_columns); return (num_of_columns == 3 ? FileFormat::ver1 // &quot;x y z (velocity)&quot; : num_of_columns == 4 ? FileFormat::ver2 // &quot;x y z yaw (velocity) : FileFormat::unknown);} ⑦loadWaypointsForVer3函数​ 加载文件内容并解析 1234567891011121314151617181920212223void WaypointLoaderNode::loadWaypointsForVer3(const char* filename, std::vector&lt;autoware_msgs::Waypoint&gt;* wps){ std::ifstream ifs(filename); if (!ifs) { return; } std::string line; std::getline(ifs, line); // 读取第一行 std::vector&lt;std::string&gt; contents; parseColumns(line, &amp;contents); // 从第二行开始解析 while (std::getline(ifs, line)) { autoware_msgs::Waypoint wp; // 解析该行，构造waypoint结构体 parseWaypointForVer3(line, contents, &amp;wp); wps-&gt;emplace_back(wp); }} ⑧parseWaypointForVer3函数​ 解析输入字符串，构造waypoint结构体 12345678910111213141516171819202122void WaypointLoaderNode::parseWaypointForVer3(const std::string&amp; line, const std::vector&lt;std::string&gt;&amp; contents, autoware_msgs::Waypoint* wp){ std::vector&lt;std::string&gt; columns; parseColumns(line, &amp;columns); std::unordered_map&lt;std::string, std::string&gt; map; for (size_t i = 0; i &lt; contents.size(); i++) { map[contents.at(i)] = columns.at(i); } wp-&gt;pose.pose.position.x = std::stod(map[&quot;x&quot;]); wp-&gt;pose.pose.position.y = std::stod(map[&quot;y&quot;]); wp-&gt;pose.pose.position.z = std::stod(map[&quot;z&quot;]); wp-&gt;pose.pose.orientation = tf::createQuaternionMsgFromYaw(std::stod(map[&quot;yaw&quot;])); wp-&gt;twist.twist.linear.x = kmph2mps(std::stod(map[&quot;velocity&quot;])); wp-&gt;change_flag = std::stoi(map[&quot;change_flag&quot;]); wp-&gt;wpstate.steering_state = (map.find(&quot;steering_flag&quot;) != map.end()) ? std::stoi(map[&quot;steering_flag&quot;]) : 0; wp-&gt;wpstate.accel_state = (map.find(&quot;accel_flag&quot;) != map.end()) ? std::stoi(map[&quot;accel_flag&quot;]) : 0; wp-&gt;wpstate.stop_state = (map.find(&quot;stop_flag&quot;) != map.end()) ? std::stoi(map[&quot;stop_flag&quot;]) : 0; wp-&gt;wpstate.event_state = (map.find(&quot;event_flag&quot;) != map.end()) ? std::stoi(map[&quot;event_flag&quot;]) : 0;} 4.2 节点waypoint_replanner​ 节点waypoint_replanner的主要作用：在加载的轨迹点基础上重新对他们的速度进行设置。 4.2.1 启动方法 终端启动: roslaunch waypoint_maker waypoint_loader.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方computing 选项卡 -&gt; Motion Planning -&gt;waypoint_maker-&gt;waypoint_loader，单击 [app] 按钮可更改设置等参数。 4.2.2 程序路径1src/autoware/core_planning/waypoint_maker/nodes/waypoint_replanner 4.2.3 参数详情 参数名 类型 说明 replanning_mode bool 重规划模式 velocity_max double 最大速度（km/h) velocity_min double 最小速度（km/h) accel_limit double 加速限制 decel_limit double 减速限制 resample_mode bool 重采样模式 resample_interval bool 重采样间隔 replan_curve_mode bool 重规划曲线模式 replan_endpoint_mode bool 重规划结束点模式 4.2.4 代码注解① main函数​ main函数在waypoint_replanner_node.cpp中。 12345678int main(int argc, char** argv){ ros::init(argc, argv, &quot;waypoint_replanner&quot;); waypoint_maker::WaypointReplannerNode wr; ros::spin(); return 0;} ​ 在main函数中只做了一件事，新建WaypointReplannerNode对象wr， 因此转到WaypointReplannerNode类的构造函数， 构造函数内实现了话题的订阅和发布。其中订阅的“/based/waypoints_raw”就是前面waypoint_loader节点所发布的话题。 1234567891011121314151617WaypointReplannerNode::WaypointReplannerNode() : pnh_(&quot;~&quot;), is_first_publish_(true){ WaypointReplannerConfig temp_config; //...(下略) if (use_decision_maker_) { lane_pub_ = nh_.advertise&lt;autoware_msgs::LaneArray&gt;(&quot;/based/lane_waypoints_array&quot;, 10, true); } else { lane_pub_ = nh_.advertise&lt;autoware_msgs::LaneArray&gt;(&quot;/lane_waypoints_array&quot;, 10, true); } lane_sub_ = nh_.subscribe(&quot;/based/lane_waypoints_raw&quot;, 1, &amp;WaypointReplannerNode::laneCallback, this); config_sub_ = nh_.subscribe(&quot;/config/waypoint_replanner&quot;, 1, &amp;WaypointReplannerNode::configCallback, this);} ② configCallback函数​ configCallback函数为话题“/config/waypoint_replanner”的回调函数，主要进行一些成员变量的初始化。 12345678910111213void WaypointReplannerNode::configCallback(const autoware_config_msgs::ConfigWaypointReplanner::ConstPtr&amp; conf){ //重规划模式 replanning_mode_ = conf-&gt;replanning_mode; //实时调整模式 realtime_tuning_mode_ = conf-&gt;realtime_tuning_mode; use_decision_maker_ = conf-&gt;use_decision_maker; replanner_.initParameter(conf); if (!lane_array_.lanes.empty() &amp;&amp; (is_first_publish_ || realtime_tuning_mode_)) { publishLaneArray(); }} ③ laneCallback函数​ laneCallback函数为话题“/based/lane_waypoints_raw”的回调函数，在加载的轨迹点基础上重新规划并发布话题“lane_waypoints_array”。 12345void WaypointReplannerNode::laneCallback(const autoware_msgs::LaneArray::ConstPtr&amp; lane_array){ lane_array_ = *lane_array; publishLaneArray();} ④ publishLaneArray函数​ 如果replanning_mode 为true，则调用replan函数重新规划。 12345678910111213void WaypointReplannerNode::publishLaneArray(){ autoware_msgs::LaneArray array(lane_array_); if (replanning_mode_) { //重规划路径 replan(array); } //发布重新规划过的路径集合 lane_pub_.publish(array); is_first_publish_ = false;} ⑤ replan函数​ replan函数内遍历lane_array.lanes。对每一条Lane，replanner_都调replanLaneWaypointVel函数。 12345678void WaypointReplannerNode::replan(autoware_msgs::LaneArray&amp; lane_array){ for (auto &amp;el : lane_array.lanes) { //重规划路标点速度 replanner_.replanLaneWaypointVel(el); }} ⑥ replanLaneWaypointVel函数​ lanLaneWaypointVel函数用于重规轨迹点的速度。 1234567891011121314151617181920212223242526272829303132333435363738394041void replanLaneWaypointVel(autoware_msgs::Lane&amp; lane){ //...(上略) unsigned long last = lane.waypoints.size() - 1; limitVelocityByRange(0, last, config_.velocity_max, lane); if (config_.resample_mode) { //重采样路标点 resampleLaneWaypoint(config_.resample_interval, lane, dir); last = lane.waypoints.size() - 1; } // 根据每个航路点的曲率设置速度 if (config_.replan_curve_mode) { std::vector&lt;double&gt; curve_radius; createRadiusList(lane, curve_radius); setVelocityByRange(0, last, config_.velocity_max, lane); for (unsigned long i = 0; i &lt; curve_radius.size(); i++) { lane.waypoints[i].twist.twist.linear.x = std::fmin(lane.waypoints[i].twist.twist.linear.x, std::sqrt(config_.lateral_accel_limit * std::fmax(curve_radius[i], config_.radius_min))); } limitVelocityByRange(0, last, config_.velocity_max, lane); } // 设置车道末端的速度 if (config_.replan_endpoint_mode) { // 将最后一个航点的速度置0 setVelocityByRange(last - 1, last, 0.0, lane); // 为除最后一个航点之外的其他航点设置最小速度 raiseVelocityByRange(0, last - 1, config_.velocity_min, lane); // 再次平滑速度 limitVelocityByRange(0, last, config_.velocity_max, lane); } if (dir == LaneDirection::Backward) { changeVelSign(lane, false); }} ⑦ limitVelocityByRange函数​ 代码略，通过加速度与速度之间的关系进一步对速度进行修正。 ​ 其中，a为最大加速度，x为距离（根据前后两个轨迹点的位置算得）。由此可以计算处在最大加速度的限制条件下，下一轨迹点的速度最大/最小值。据此进行修正。 ⑧ resampleLaneWaypoint函数​ 重采样轨迹点 123456789101112131415161718192021222324252627282930void resampleLaneWaypoint(const double resample_interval, autoware_msgs::Lane&amp; lane, LaneDirection dir){ if (lane.waypoints.size() &lt; 2) { return; } autoware_msgs::Lane original_lane(lane); ... for (unsigned long i = 1; i &lt; original_lane.waypoints.size(); i++) { //采样三个轨迹点 //[0] = previous point, [1] = target point, [2] = next point CbufGPoint curve_point = getCrvPointsOnResample(lane, original_lane, i); const std::vector&lt;double&gt; curve_param = calcCurveParam(curve_point); lane.waypoints.back().twist.twist = original_lane.waypoints[i - 1].twist.twist; lane.waypoints.back().wpstate = original_lane.waypoints[i - 1].wpstate; lane.waypoints.back().change_flag = original_lane.waypoints[i - 1].change_flag; // 如果直行 if (curve_param.empty()) { resampleOnStraight(curve_point, lane, dir); } // 如果转弯 else { resampleOnCurve(curve_point[1], curve_param, lane, dir); } } ...} ⑨getCrvPointsOnResample函数​ 在lane和original_lane上选择三个点作为圆弧上的点 1234567891011121314151617const CbufGPoint getCrvPointsOnResample( const autoware_msgs::Lane&amp; lane, const autoware_msgs::Lane&amp; original_lane, unsigned long original_index) const{ unsigned long id = original_index; CbufGPoint curve_point(3); const unsigned int n = (config_.lookup_crv_width - 1) / 2; const autoware_msgs::Waypoint cp[3] = { (lane.waypoints.size() &lt; n) ? lane.waypoints.front() : lane.waypoints[lane.waypoints.size() - n], original_lane.waypoints[id], (id &lt; original_lane.waypoints.size() - n) ? original_lane.waypoints[id + n] : original_lane.waypoints.back() }; for (int i = 0; i &lt; 3; i++) { curve_point.push_back(cp[i].pose.pose.position); } return curve_point;} ⑩calcCurveParam函数​ 计算圆的三个参数[center_x , center_y, radius]，首先根据轨迹点p0, p1, p2，计算下面各式： 由上面各式，进一步计算得到曲线的中心点和曲率 ”根据圆上三点求圆心和半径”这一问题有多种解法，主流的有两种：（1）分别通过其中两点的中垂线交点求圆心；（2）通过三个点到圆心距离相等联立方程求解。 12345678910111213141516171819202122const std::vector&lt;double&gt; WaypointReplanner::calcCurveParam(CbufGPoint p) const{ for (int i = 0; i &lt; 3; i++, p.push_back(p.front())) // if exception occured, change points order { //根据向量叉乘的模的值判断是否在一条直线上，如过模值小于1e-8则近似认为三点在一条直线上，圆的参数为空 const double d = 2 * ((p[0].y - p[2].y) * (p[0].x - p[1].x) - (p[0].y - p[1].y) * (p[0].x - p[2].x)); if (fabs(d) &lt; 1e-8) { continue; } const std::vector&lt;double&gt; x2 = { p[0].x * p[0].x, p[1].x * p[1].x, p[2].x * p[2].x }; const std::vector&lt;double&gt; y2 = { p[0].y * p[0].y, p[1].y * p[1].y, p[2].y * p[2].y }; const double a = y2[0] - y2[1] + x2[0] - x2[1]; const double b = y2[0] - y2[2] + x2[0] - x2[2]; std::vector&lt;double&gt; param(3); const double cx = param[0] = ((p[0].y - p[2].y) * a - (p[0].y - p[1].y) * b) / d; const double cy = param[1] = ((p[0].x - p[2].x) * a - (p[0].x - p[1].x) * b) / -d; param[2] = sqrt((cx - p[0].x) * (cx - p[0].x) + (cy - p[0].y) * (cy - p[0].y)); return param; } return std::vector&lt;double&gt;(); // error} 4.3 节点lane_navi​ 节点lane_navi的主要作用：根据路由请求在矢量地图中寻找通往目的地的各条可行路径，并发布至话题“/lane_waypoints_array”。 4.3.1 程序路径1src/autoware/core_planning/lane_planner/nodes/lane_navi 代码略。 4.4 节点lane_rule​ 节点lane_rule的主要作用：对话题“/lane_waypoints_array”上轨迹点的速度方面进一步修正，为红灯时在停车线内减速停车等场景提供支持，发布话题“/traffic_waypoints_array”。 4.4.1 程序路径1src/autoware/core_planning/lane_planner/nodes/lane_rule 代码略。 4.5 节点lane_select​ 节点lane_select的主要作用：判断当前车道，同时规划从当前车道切换至其他车道的轨迹，接着根据话题“state”中的驾驶状态（是否需要换道）发布当前车道数据/换到轨迹数据至话题“base_waypoints”供其他节点继续规划。 4.5.1 启动方法 终端启动: roslaunch lane_planner lane_select.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方computing 选项卡 -&gt; mission_planning -&gt;lane_planner-&gt;lane_select，单击 [app] 按钮可更改设置等参数。 4.5.2 程序路径1src/autoware/core_planning/lane_planner/nodes/lane_select 4.5.3 代码注解① main函数​ main函数在lane_select_node.cpp中。节点lane_select启动时新建LaneSelectNode对象，其构造函数中首先对一些成员变量进行赋值，接着调用initForROS函数设置订阅者/发布者，设置参数。 12345678int main(int argc, char **argv){ ros::init(argc, argv, &quot;lane_select&quot;); lane_planner::LaneSelectNode lsn; lsn.run(); return 0;} ② initForRos函数​ 该函数设置参数，设置订阅者和发布者 123456789101112131415161718void LaneSelectNode::initForROS(){ // setup subscriber sub1_ = nh_.subscribe(&quot;traffic_waypoints_array&quot;, 1, &amp;LaneSelectNode::callbackFromLaneArray, this); sub2_.subscribe(nh_, &quot;current_pose&quot;, 1); sub3_.subscribe(nh_, &quot;current_velocity&quot;, 1); ... // setup publisher pub1_ = nh_.advertise&lt;autoware_msgs::Lane&gt;(&quot;base_waypoints&quot;, 1, true); pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 1); ... // get from rosparam ... // Kick off a timer to publish base_waypoints, closest_waypoint, change_flag, current_lane_id, and vehicle_location timer_ = nh_.createTimer(ros::Duration(1.0/update_rate_), &amp;LaneSelectNode::processing, this);} ③ callbackFromLaneArray函数​ 主要功能构建tuple_vec_成员变量，使用tuple_vec_ 来存储laneArray相关变量。 tuple_vec_ 数据类型为std::vector&lt;std::tuple&lt;autoware_msgs::Lane, int32_t, ChangeFlag&gt;&gt; tuple元素的定义依次为：lane, closest_waypoint on the lane to ego-vehicle, lane change flag 123456789101112131415161718void LaneSelectNode::callbackFromLaneArray(const autoware_msgs::LaneArrayConstPtr &amp;msg){ tuple_vec_.clear(); tuple_vec_.shrink_to_fit(); tuple_vec_.reserve(msg-&gt;lanes.size()); for (const auto &amp;el : msg-&gt;lanes) { auto t = std::make_tuple(el, -1, ChangeFlag::unknown); tuple_vec_.push_back(t); } lane_array_id_ = msg-&gt;id; current_lane_idx_ = -1; right_lane_idx_ = -1; left_lane_idx_ = -1; is_new_lane_array_ = true; is_lane_array_subscribed_ = true;} ④ processing函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667void LaneSelectNode::processing(const ros::TimerEvent&amp; e){ //检查相关话题是否订阅成功 if (!isAllTopicsSubscribed()) return; // 更新每条lane距离自车最近路标点,更新tuple_vec_中closest_waypoint元素的值 if (!updateClosestWaypointNumberForEachLane()) { publishClosestWaypoint(-1); publishVehicleLocation(-1, lane_array_id_); resetLaneIdx(); return; } if (current_lane_idx_ == -1) { // 寻找距离自车最近的车道，更新current_lane_idx_ findCurrentLane(); } //寻找相邻车道更新left_lane_idx_, right_lane_idx_ findNeighborLanes(); if (current_state_ == &quot;LANE_CHANGE&quot;) { try { //根据current_lane_idx_确定tuple_vec_中的元组，并根据该元组中change_flag值更新current_lane_idx_ //然后调用findNeighborLanes更新left_lane_idx_, right_lane_idx_ changeLane(); //更新change lane中最近路标点及change flag std::get&lt;1&gt;(lane_for_change_) = getClosestWaypointNumber(std::get&lt;0&gt;(lane_for_change_), current_pose_.pose, current_velocity_.twist, std::get&lt;1&gt;(lane_for_change_), distance_threshold_, search_closest_waypoint_minimum_dt_); std::get&lt;2&gt;(lane_for_change_) = static_cast&lt;ChangeFlag&gt;( std::get&lt;0&gt;(lane_for_change_).waypoints.at(std::get&lt;1&gt;(lane_for_change_)).change_flag); //发布change lane 相关信息 publishLane(std::get&lt;0&gt;(lane_for_change_)); publishClosestWaypoint(std::get&lt;1&gt;(lane_for_change_)); publishChangeFlag(std::get&lt;2&gt;(lane_for_change_)); publishVehicleLocation(std::get&lt;1&gt;(lane_for_change_), lane_array_id_); } catch (std::out_of_range) { ROS_WARN_THROTTLE(2, &quot;Failed to get closest waypoint num&quot;); } } else { //更新tuple_vec_中每个元组内的change flag数据 updateChangeFlag(); //更新lane_for_change_ createLaneForChange(); if (is_new_lane_array_ || prev_lane_idx_ != current_lane_idx_) { publishLane(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))); prev_lane_idx_ = current_lane_idx_; is_new_lane_array_ = false; } //根据元组tuple_vec_.at(current_lane_idx_)中的信息发布消息到各个话题 publishClosestWaypoint(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_))); publishChangeFlag(std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_))); publishVehicleLocation(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)), lane_array_id_); } publishVisualizer(); resetSubscriptionFlag();} 4.6 节点 astar_avoid​ 节点astar_avoid的主要作用：基于几点“lane_select”发布在话题“base_waypoints”上的轨迹， 利用A*算法规划壁障轨迹并发布至话题“safety_waypoints”。 4.6.1 启动方法 终端启动: roslaunch waypoint_planner astar_avoid.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方computing 选项卡 -&gt; motion_planner -&gt;waypoint_planner-&gt;astar_avoid，单击 [app] 按钮可更改设置等参数。 4.6.2 程序路径1src/autoware/core_planning/waypoint_planner/src/astar_avoid 4.6.3 参数详情 参数名(astar_avoid) 类型 说明 enable_avoidance bool 启用避障功能 avoid_waypoints_velocity double 避障时最大速度（km/h) avoid_start_velocity double 开始避障速度阈值（km/h) replan_interval double 重规划时间间隔（s) search_waypoints_delta int 路标点下标搜索增量 参数名(astar_search) 类型 说明 robot_length double 机器人长度 robot_width double 机器人宽度 robot_base2back double 质心到车尾距离 minimum_turning_radius double 最小转弯半径 theta_size int 决定机器人移动时航向角变化步长,移动一步航向角变化360/theta_size 度 angle_goal_range double 距离目标点角度范围 lateral_goal_range double 距离目标点横向距离范围 longitudinal_goal_range double 距离目标点纵向距离范围 obstacle_threshold double 障碍物阈值 4.6.4 算法介绍-A*搜索算法​ planAvoidWaypoints函数内调用A 搜索算法，下面简单介绍下A搜索算法。 ​ A*搜索算法时一个被广泛应用于路径优化领域的算法，它的寻路能力基于启发式的代价函数。 ① 栅格化地图​ A*算法第一步时栅格化地图，具体来说是将连续的地图离散化，用一个大型的二位列表存储地图数据。 ② 评估函数​ A*算法的核心是一个评估函数： ​ 其中，G(n)为代价函数，在该环境中G的值代表从起点移动到该方格n的距离代价。H(n)为启发式代价函数，在该环境中H的值代表该方格n到终点的距离代价。 ③ 搜索步骤​ A*涉及两个重要的列表，openList（开放列表，存储候选节点）和closeList(关闭列表，存储已经走过的节点）。算法先把起点放入openList中，然后重复下面的步骤。 ​ 遍历openlist，找到F值最小的节点当做当前搜索的起点，用P表示； ​ 将P放入closelist中， 作为已经走过的节点。 ​ 探索P周围相邻节点，计算他们的H值、G值和F值，并把P设置为这些节点的父节点，将这些节点当做探索节点放到Q中。 ​ 如果Q中的节点不在openlist或closelist中，则将其加入到openlist中；Q中节点已经存在于openlist中的，比较这些节点的F值和他们在openlist中的F值哪个更小（F越小说明路径更优），如果openlist中的F值更小或者二者相等，不做任何改变，否则用Q中的节点替换openlist中的节点； Q中节点已经存在于closelist中的，比较这些节点的F值和他们在closelist中的F值哪个更小，如果closelist中的F值更小或者相等，不做任何改变，否则将其加入到openlist。 ​ 如果终点在openlist中，则退出搜索，最优路径可以从终点开始，沿着父节点逆向溯源直至起点而获得；如果openlist是空的，则退出，意味着起点到终点没有任何一条可行驶路径。 4.6.5 代码注解① main函数​ main函数在astar_avoid_node.cpp中，节点的主要功能通过AstarAvoid对象的run函数实现。 12345678int main(int argc, char** argv){ ros::init(argc, argv, &quot;astar_avoid&quot;); AstarAvoid node; node.run(); return 0;} ② AstarAvoid构造函数​ 构造函数主要功能为设置变量，发布者，订阅者。 123456789101112131415161718AstarAvoid::AstarAvoid() : nh_() , private_nh_(&quot;~&quot;){ //...(下略) //设置变量 private_nh_.param&lt;int&gt;(&quot;closest_search_size&quot;, closest_search_size_, 30); //...(下略) //设置发布者 safety_waypoints_pub_ = nh_.advertise&lt;autoware_msgs::Lane&gt;(&quot;safety_waypoints&quot;, 1, true); //...(下略) //设置订阅者 base_waypoints_sub_ = nh_.subscribe(&quot;base_waypoints&quot;, 1, &amp;AstarAvoid::baseWaypointsCallback, this); //...(下略) } ③ run函数​ run函数是astar_avoid的功能主体。run函数实际上是一个有限状态机，根据条件切换state_ ，在特定状态更新avoid_waypoints_。 ​ 函数内AstarAvoid::STATE的定义如下： 12345678typedef enum STATE { INITIALIZING = -1, RELAYING = 0, STOPPING = 1, PLANNING = 2, AVOIDING = 3 } State; ​ run函数代码及状态转移关系如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111void AstarAvoid::run(){ state_ = AstarAvoid::STATE::INITIALIZING; while (ros::ok()) { ros::spinOnce(); // 检查各回调函数是否正确接收到对应话题的消息 if (checkInitialized()) { break; } ros::Duration(1.0).sleep(); } //主循环 int end_of_avoid_index = -1; ros::WallTime start_plan_time = ros::WallTime::now(); ros::WallTime start_avoid_time = ros::WallTime::now(); // 重置障碍物坐标 obstacle_waypoint_index_ = -1; // 启动时设置为中继模式 state_ = AstarAvoid::STATE::RELAYING; // 启动定时器发布话题 timer_ = nh_.createTimer(ros::Duration(1.0/update_rate_), &amp;AstarAvoid::publishWaypoints, this); while (ros::ok()) { ros::spinOnce(); // 判断是否开启避障模式 if (!enable_avoidance_) { rate_-&gt;sleep(); continue; } bool found_obstacle = (obstacle_waypoint_index_ &gt;= 0); //avoid_star_velocity_(km/h)是开始避让时自车车速阈值 bool avoid_velocity = (current_velocity_.twist.linear.x &lt; avoid_start_velocity_ / 3.6); // 更新状态state_ if (state_ == AstarAvoid::STATE::RELAYING) { avoid_waypoints_ = base_waypoints_; //发现障碍物，从中继模式转为停车模式 if (found_obstacle) { ROS_INFO(&quot;RELAYING -&gt; STOPPING, Decelerate for stopping&quot;); state_ = AstarAvoid::STATE::STOPPING; } } else if (state_ == AstarAvoid::STATE::STOPPING) { //检查重规划时间间隔条件 bool replan = ((ros::WallTime::now() - start_plan_time).toSec() &gt; replan_interval_); //障碍物消失，重新回到中继模式 if (!found_obstacle) { ROS_INFO(&quot;STOPPING -&gt; RELAYING, Obstacle disappers&quot;); state_ = AstarAvoid::STATE::RELAYING; } //障碍物仍然存在，且满足重规划时间间隔和速度要求，从停车模式转为规划模式 else if (replan &amp;&amp; avoid_velocity) { ROS_INFO(&quot;STOPPING -&gt; PLANNING, Start A* planning&quot;); state_ = AstarAvoid::STATE::PLANNING; } } else if (state_ == AstarAvoid::STATE::PLANNING) { start_plan_time = ros::WallTime::now(); //确定规避路线并相应添加到avoid_waypoints_, //同时更新传入函数的end_of_avoid_index //避障路线规划成功则从规划模式转为避障模式，否则切换为停车模式 if (planAvoidWaypoints(end_of_avoid_index)) { ROS_INFO(&quot;PLANNING -&gt; AVOIDING, Found path&quot;); state_ = AstarAvoid::STATE::AVOIDING; start_avoid_time = ros::WallTime::now(); closest_waypoint_index_ = -1; } else { ROS_INFO(&quot;PLANNING -&gt; STOPPING, Cannot find path&quot;); state_ = AstarAvoid::STATE::STOPPING; } } else if (state_ == AstarAvoid::STATE::AVOIDING) { updateClosestWaypoint(avoid_waypoints_, current_pose_global_.pose, closest_search_size_); //如果自车位置超过避障路线终点，则从避障模式转为中继模式 if (closest_waypoint_index_ &gt; end_of_avoid_index) { ROS_INFO(&quot;AVOIDING -&gt; RELAYING, Reached goal&quot;); state_ = AstarAvoid::STATE::RELAYING; closest_waypoint_index_ = -1; } else if (found_obstacle &amp;&amp; avoid_velocity) { bool replan = ((ros::WallTime::now() - start_avoid_time).toSec() &gt; replan_interval_); if (replan) { ROS_INFO(&quot;AVOIDING -&gt; STOPPING, Abort avoiding&quot;); state_ = AstarAvoid::STATE::STOPPING; } } } rate_-&gt;sleep(); }} ④ planAvoidWaypoints函数​ 逐步更新目标位姿，并执行从当前位姿到目标位姿的基于A*算法的增量搜索，确定避障路线并相应添加进avoid_waypoints_。另外，更新传入函数的end_of_avoid_index。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061bool AstarAvoid::planAvoidWaypoints(int&amp; end_of_avoid_index){ bool found_path = false; //获得avoid_waypoints_中的“距离最近轨迹点”的下标 updateClosestWaypoint(avoid_waypoints_, current_pose_global_.pose, closest_search_size_); if (closest_waypoint_index_ == -1) { return false; } // 逐步更新目标位姿并执行A*搜索 // search_waypoints_size用于跳过轨迹点以进行增量搜索 for (int i = search_waypoints_delta_; i &lt; static_cast&lt;int&gt;(search_waypoints_size_); i += search_waypoints_delta_) { // 更新目标下标goal_waypoint_index int goal_waypoint_index = closest_waypoint_index_ + obstacle_waypoint_index_ + i; if (goal_waypoint_index &gt;= static_cast&lt;int&gt;(avoid_waypoints_.waypoints.size())) { break; } // 更新目标位姿 goal_pose_global_ = avoid_waypoints_.waypoints[goal_waypoint_index].pose; goal_pose_local_.header = costmap_.header /*指定goal_pose_local_和goal_pose_global_各自的frame_id, *就可以通过transformPose函数获得位姿goal_pose_global_.pose_ *从global坐标系下转换到costmap_坐标系下的新位姿goal_pose_local_.pose */ goal_pose_local_.pose = transformPose(goal_pose_global_.pose, getTransform(costmap_.header.frame_id, goal_pose_global_.header.frame_id)); // astar_的定义是 AstarSearch astar_ // 根据costmap_的信息初始化astar_内A*搜索的代价地图nodes_ astar_.initialize(costmap_); // 启动A*搜索 found_path = astar_.makePlan(current_pose_local_.pose, goal_pose_local_.pose); static ros::Publisher pub = nh_.advertise&lt;nav_msgs::Path&gt;(&quot;debug&quot;, 1, true); if (found_path) { pub.publish(astar_.getPath()); end_of_avoid_index = goal_waypoint_index; //将用于避障的轨迹astar_.getPath()合并进avoid_waypoints //并更新end_of_avoid_index mergeAvoidWaypoints(astar_.getPath(), end_of_avoid_index); if (avoid_waypoints_.waypoints.size() &gt; 0) { ROS_INFO(&quot;Found GOAL at index = %d&quot;, goal_waypoint_index); astar_.reset(); return true; } else { found_path = false; } } astar_.reset(); } ROS_ERROR(&quot;Can't find goal...&quot;); return false;} ⑤ search函数​ search函数启动基于A*算法的搜索过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119bool AstarSearch::search(){ ros::WallTime begin = ros::WallTime::now(); // 开始A*搜索 // 如果openlist为空，搜索失败img while (!openlist_.empty()) { // 检查时间并在搜索时间到达限制时终止 ros::WallTime now = ros::WallTime::now(); double msec = (now - begin).toSec() * 1000.0; if (msec &gt; time_limit_) { ROS_DEBUG(&quot;Exceed time limit of %lf [ms]&quot;, time_limit_); return false; } // 从openlist中弹出最低代价节点 SimpleNode top_sn = openlist_.top(); openlist_.pop(); AstarNode* current_an = &amp;nodes_[top_sn.index_y][top_sn.index_x][top_sn.index_theta]; //将该节点状态设为CLOSED，即将该节点放入closelist中 current_an-&gt;status = STATUS::CLOSED; //目标检查 if (isGoal(current_an-&gt;x, current_an-&gt;y, current_an-&gt;theta)) { ROS_DEBUG(&quot;Search time: %lf [msec]&quot;, (now - begin).toSec() * 1000.0); setPath(top_sn); return true; } // 拓展节点 for (const auto&amp; state : state_update_table_[top_sn.index_theta]) { //下一个节点 double next_x = current_an-&gt;x + state.shift_x; double next_y = current_an-&gt;y + state.shift_y; double next_theta = modifyTheta(current_an-&gt;theta + state.rotation); double move_cost = state.step; double move_distance = current_an-&gt;move_distance + state.step; // 增加反向代价 if (state.back != current_an-&gt;back) move_cost *= reverse_weight_; // 计算下一个状态的下标 SimpleNode next_sn; geometry_msgs::Point next_pos; next_pos.x = next_x; next_pos.y = next_y; pointToIndex(next_pos, &amp;next_sn.index_x, &amp;next_sn.index_y); next_sn.index_theta = top_sn.index_theta + state.index_theta; // 避免下标无效 next_sn.index_theta = (next_sn.index_theta + theta_size_) % theta_size_; // 检查下标是否有效 if (isOutOfRange(next_sn.index_x, next_sn.index_y) || detectCollision(next_sn)) { continue; } AstarNode* next_an = &amp;nodes_[next_sn.index_y][next_sn.index_x][next_sn.index_theta]; double next_gc = current_an-&gt;gc + move_cost; double next_hc = nodes_[next_sn.index_y][next_sn.index_x][0].hc; // wavefront 或距离变换启发式 // 增加欧式距离成本 if (use_potential_heuristic_) { next_gc += nodes_[next_sn.index_y][next_sn.index_x][0].hc; next_hc += calcDistance(next_x, next_y, goal_pose_local_.pose.position.x, goal_pose_local_.pose.position.y); distance_heuristic_weight_; } //...(下略) // 下一个节点状态为STATUS::NONE if (next_an-&gt;status == STATUS::NONE) { next_an-&gt;status = STATUS::OPEN; next_an-&gt;x = next_x; next_an-&gt;y = next_y; next_an-&gt;theta = next_theta; next_an-&gt;gc = next_gc; next_an-&gt;hc = next_hc; next_an-&gt;move_distance = move_distance; next_an-&gt;back = state.back; next_an-&gt;parent = current_an; next_sn.cost = next_an-&gt;gc + next_an-&gt;hc; openlist_.push(next_sn); continue; } // 下一个节点在openlist或closelist中 if (next_an-&gt;status == STATUS::OPEN || next_an-&gt;status == STATUS::CLOSED) { if (next_gc &lt; next_an-&gt;gc) { next_an-&gt;status = STATUS::OPEN; next_an-&gt;x = next_x; next_an-&gt;y = next_y; next_an-&gt;theta = next_theta; next_an-&gt;gc = next_gc; next_an-&gt;hc = next_hc; // already calculated ? next_an-&gt;move_distance = move_distance; next_an-&gt;back = state.back; next_an-&gt;parent = current_an; next_sn.cost = next_an-&gt;gc + next_an-&gt;hc; openlist_.push(next_sn); continue; } } } // 状态更新 } // 寻路失败 ROS_DEBUG(&quot;Open list is empty...&quot;); return false;} 4.7 节点velocity_set​ 节点velocity_set的主要作用：在节点astar_avoid发布在话题“safety_waypoints”上的轨迹基础上，修正无人车靠近障碍物或停车线的速度。 4.7.1 启动方法 终端启动: roslaunch waypoint_planner velocity_set_option.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方computing 选项卡 -&gt; motion_planner -&gt;waypoint_planner-&gt;velocity_set，单击 [app] 按钮可更改设置等参数。 4.7.2 程序路径1src/autoware/core_planning/waypoint_planner/src/velocity_set 4.7.3 参数详情 参数名 类型 说明 remove_points_upto double 删除点范围 stop_distance_obstacle double 障碍物前停车距离 stop_distance_stopline double 停止线前停车距离 detection_range double 障碍物检测范围 deceleration_range double 减速检测范围 points_threshold int 点云个数阈值 deceleration_obstacle double 前方存在障碍物时减速度值 deceleration_stopline double 前方存在停止线时减速度值 velocity_change_limit double 速度变化限制（km/h) 4.7.4 代码注解① main函数首先是main函数，main函数在velocity_set.cpp中，主要功能为： ​ 1.Crosswalk: 人行横道检测 ​ 2.obstacleDetection: 检测障碍物位于当前轨迹路标点索引值，并根据距离信息判断当前需要减速还是停车（EControl::STOP、DECELERATE） changeWaypoints: 根据障碍物信息修改waypoints中的速度信息，进而在pure_pursuit节点形成减速或者停车的效果 发布路径及障碍物信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112int main(int argc, char** argv){ //...(下略) //类对象 CrossWalk crosswalk; VelocitySetPath vs_path; VelocitySetInfo vs_info; // 速度设定路径订阅器 ros::Subscriber waypoints_sub = nh.subscribe(&quot;safety_waypoints&quot;, 1, &amp;VelocitySetPath::waypointsCallback, &amp;vs_path); ros::Subscriber current_vel_sub = nh.subscribe(&quot;current_velocity&quot;, 1, &amp;VelocitySetPath::currentVelocityCallback, &amp;vs_path); // 速度设定信息订阅器 ros::Subscriber config_sub = nh.subscribe(&quot;config/velocity_set&quot;, 1, &amp;VelocitySetInfo::configCallback, &amp;vs_info); // 点云订阅器 ros::Subscriber points_sub = nh.subscribe(points_topic, 1, &amp;VelocitySetInfo::pointsCallback, &amp;vs_info); //...(下略) // 矢量地图订阅器 if (enable_crosswalk_detection) { crosswalk.setMultipleDetectionFlag(enable_multiple_crosswalk_detection); ros::Subscriber sub_dtlane = nh.subscribe(&quot;vector_map_info/cross_walk&quot;, 1, &amp;CrossWalk::crossWalkCallback, &amp;crosswalk); ros::Subscriber sub_area = nh.subscribe(&quot;vector_map_info/area&quot;, 1, &amp;CrossWalk::areaCallback, &amp;crosswalk); ros::Subscriber sub_line = nh.subscribe(&quot;vector_map_info/line&quot;, 1, &amp;CrossWalk::lineCallback, &amp;crosswalk); ros::Subscriber sub_point = nh.subscribe(&quot;vector_map_info/point&quot;, 1, &amp;CrossWalk::pointCallback, &amp;crosswalk); } // TF监听 tf2_ros::Buffer tfBuffer;obstacleDetection tf2_ros::TransformListener tfListener(tfBuffer); //发布器 ros::Publisher detection_range_markers_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;detection_range&quot;, 1); ros::Publisher obstacle_marker_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;obstacle&quot;, 1); ros::Publisher obstacle_waypoint_pub = nh.advertise&lt;std_msgs::Int32&gt;(&quot;obstacle_waypoint&quot;, 1, true); ros::Publisher stopline_waypoint_pub = nh.advertise&lt;std_msgs::Int32&gt;(&quot;stopline_waypoint&quot;, 1, true); ros::Publisher final_waypoints_pub = nh.advertise&lt;autoware_msgs::Lane&gt;(&quot;final_waypoints&quot;, 1, true); ros::Rate loop_rate(update_rate); while (ros::ok()) { ros::spinOnce(); try { geometry_msgs::TransformStamped map_to_lidar_tf = tfBuffer.lookupTransform( &quot;map&quot;, &quot;velodyne&quot;, ros::Time::now(), ros::Duration(2.0)); vs_info.setLocalizerPose(map_to_lidar_tf); } catch(tf2::TransformException &amp;ex) { ROS_WARN(&quot;Failed to get map-&gt;lidar transform. skip computation: %s&quot;, ex.what()); continue; } // 因为safety_waypoints的第一个元素为距离自车最近轨迹点，所以设置current_closest_waypoint 为0 int32_t current_closest_waypoint = 0; int32_t closest_crosswalk_waypoint = -1; if (!vs_info.getSetPose() || !vs_path.getSetPath() || vs_path.getPrevWaypointsSize() == 0) { loop_rate.sleep(); continue; } if (enable_crosswalk_detection) { //更新crosswalk内的bdID_,detection_points_和set_points if (crosswalk.loaded_all &amp;&amp; !crosswalk.set_points) { crosswalk.setCrossWalkPoints(); } // 如果 crosswalk.loaded_all为false, 设置 closest_crosswalk_waypoint为 -1. closest_crosswalk_waypoint = crosswalk.findClosestCrosswalk(current_closest_waypoint, vs_path.getPrevWaypoints(), STOP_SEARCH_DISTANCE); } crosswalk.setDetectionWaypoint(closest_crosswalk_waypoint); int32_t traffic_waypoint_idx = -1; //障碍物检测并可视化障碍物 EControl detection_result = obstacleDetection(current_closest_waypoint, vs_path.getPrevWaypoints(), crosswalk, vs_info,detection_range_markers_pub, obstacle_marker_pub, &amp;traffic_waypoint_idx); // 根据前方障碍物/停车线情况更新vs_path中的轨迹点速度，并从vs_path中截取部分轨迹发布到话题“final_waypoints”. changeWaypoints(vs_info, detection_result, current_closest_waypoint, traffic_waypoint_idx, &amp;vs_path); vs_path.setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), current_closest_waypoint, vs_info.getControlPose()); final_waypoints_pub.publish(vs_path.getTemporalWaypoints()); // 发布障碍物和停止线信息 std_msgs::Int32 obstacle_waypoint_index; std_msgs::Int32 stopline_waypoint_index; if (detection_result == EControl::STOP) { obstacle_waypoint_index.data = traffic_waypoint_idx; stopline_waypoint_index.data = -1; } else if (detection_result == EControl::STOPLINE) { obstacle_waypoint_index.data = -1; stopline_waypoint_index.data = traffic_waypoint_idx; } else { obstacle_waypoint_index.data = -1; stopline_waypoint_index.data = -1; } obstacle_waypoint_pub.publish(obstacle_waypoint_index); stopline_waypoint_pub.publish(stopline_waypoint_index); //重置vs_path内的set_path_;清空vs_info中的points_ vs_path.resetFlag(); vs_info.clearPoints(); loop_rate.sleep(); } return 0;} ② VelocitySetPath类中的回调函数waypointsCallback和currentVelocityCallback​ waypointCallback函数和currentVelocityCallback函数分别是话题“safety_waypoints”和“current_velocity”的回调函数。waypointCallback函数更新vs_path内的 autoware_msgs::Lane类型变量original_waypoints_ 和updated_waypoints_ 以及bool型变量set_path_ 。currentVelocityCallback函数更新vs_path内的current_velocity_变量。 ③ VelocitySetInfo类中的回调函数configCallback12345678910111213141516171819202122void VelocitySetInfo::configCallback(const autoware_config_msgs::ConfigVelocitySetConstPtr &amp;config){ //相距障碍物的停车距离（m) stop_distance_obstacle_ = config-&gt;stop_distance_obstacle; //相距停止线的停车距离 (m) stop_distance_stopline_ = config-&gt;stop_distance_stopline; //如果障碍物在此范围内，停车 stop_range_ = config-&gt;detection_range; //判断为障碍物的阈值 points_threshold_ = config-&gt;threshold_points; detection_height_top_ = config-&gt;detection_height_top; detection_height_bottom_ = config-&gt;detection_height_bottom; //遇到障碍物时减速的加速度 deceleration_obstacle_ = config-&gt;deceleration_obstacle; //遇到停止线时减速的加速度 deceleration_stopline_ = config-&gt;deceleration_stopline; //速度变化的限制 velocity_change_limit_ = config-&gt;velocity_change_limit / 3.6; // kmph -&gt; mps //如果障碍物在此范围内，减速 deceleration_range_ = config-&gt;deceleration_range; temporal_waypoints_size_ = config-&gt;temporal_waypoints_size;} ④ obstacleDetection函数​ obstacleDetection函数主要功能为检测障碍物， 其中包含pointsDetection() 这个函数，而pointsDetection()又包含了detectStopObstacle() 和 detectDecelerateObstacle() 两个重要的函数 ​ detectStopObstacle() 函数功能为障碍物检测，需停车， detectDecelerateObstacle() 函数功能为障碍物检测，需减速， ​ ​ detectStopObstacle函数：从车辆位置开始，向后遍历一定数量的路径点(蓝色点)，对每个路径点，遍历所有的点云，如果该路径点stop_range半径内不存在点云，则切换到下一个路径点，再次遍历所有点云； ​ 当在某一路径点B的stop_range范围内检测到了点云，且点云数量在合理范围内（大于points_threshold)， 则将障碍物判定为stop_obstacle，需要停车处理。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//对当前位置后的路径点，进行障碍物检测，如果出现points_no_ground点云聚集则视为障碍物点。int detectStopObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const autoware_msgs::Lane&amp; lane, const CrossWalk&amp; crosswalk, double stop_range, double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points, EObstacleType* obstacle_type, const int wpidx_detection_result_by_other_nodes){ int stop_obstacle_waypoint = -1; *obstacle_type = EObstacleType::NONE; // start search from the closest waypoint for (int i = closest_waypoint; i &lt; closest_waypoint + STOP_SEARCH_DISTANCE; i++)//STOP_SEARCH_DISTANCE默认是60M,沿着当前位置向后搜索 { //... // waypoint seen by localizer geometry_msgs::Point waypoint = calcRelativeCoordinate(lane.waypoints[i].pose.pose.position, localizer_pose.pose);//计算定位点和路径点的相对坐标 tf::Vector3 tf_waypoint = point2vector(waypoint); tf_waypoint.setZ(0); //不考虑z轴数据，只计算平面距离 int stop_point_count = 0; for (const auto&amp; p : points)//遍历points_no_ground(去除地面后的点云图)中所有的点 { tf::Vector3 point_vector(p.x, p.y, 0); // 2D distance between waypoint and points (obstacle) double dt = tf::tfDistance(point_vector, tf_waypoint);//计算障碍物点云与路径点之间的距离 if (dt &lt; stop_range)//dt范围内的点云均视为障碍物stop_obstacle { stop_point_count++; geometry_msgs::Point point_temp; point_temp.x = p.x; point_temp.y = p.y; point_temp.z = p.z; obstacle_points-&gt;setStopPoint(calcAbsoluteCoordinate(point_temp, localizer_pose.pose));//把所有的点云放到容器中， } } // there is an obstacle if the number of points exceeded the threshold if (stop_point_count &gt; points_threshold)//如果障碍物过于庞大，则视为不可通过，把ObstacleType状态设置为ON_WAYPOINTS。 { stop_obstacle_waypoint = i; *obstacle_type = EObstacleType::ON_WAYPOINTS; break; } obstacle_points-&gt;clearStopPoints(); // check next waypoint... }} ​ pointsDetection函数调用detectStopObstacle() 和 detectDecelerateObstacle()两个函数，用来检测障碍物及判断控制指令是STOP还是DECELERATION，不考虑人行横道的情况下，流程图及代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263EControl pointsDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; pcl_points, const int closest_waypoint, const autoware_msgs::Lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo&amp; vs_info, int* obstacle_waypoint, ObstaclePoints* obstacle_points){ // no input for detection || no closest waypoint if ((pcl_points.empty() &amp;&amp; vs_info.getDetectionResultByOtherNodes() == -1) || closest_waypoint &lt; 0) return EControl::KEEP; EObstacleType obstacle_type = EObstacleType::NONE; int stop_obstacle_waypoint = detectStopObstacle(pcl_points, closest_waypoint, lane, crosswalk, vs_info.getStopRange(), vs_info.getPointsThreshold(), vs_info.getLocalizerPose(), obstacle_points, &amp;obstacle_type, vs_info.getDetectionResultByOtherNodes()); // skip searching deceleration range if (vs_info.getDecelerationRange() &lt; 0.01) { *obstacle_waypoint = stop_obstacle_waypoint; if (stop_obstacle_waypoint &lt; 0) return EControl::KEEP; else if (obstacle_type == EObstacleType::ON_WAYPOINTS || obstacle_type == EObstacleType::ON_CROSSWALK) return EControl::STOP; else if (obstacle_type == EObstacleType::STOPLINE) return EControl::STOPLINE; else return EControl::OTHERS; } int decelerate_obstacle_waypoint = detectDecelerateObstacle(pcl_points, closest_waypoint, lane, vs_info.getStopRange(), vs_info.getDecelerationRange(), vs_info.getPointsThreshold(), vs_info.getLocalizerPose(), obstacle_points); // stop obstacle was not found if (stop_obstacle_waypoint &lt; 0) { *obstacle_waypoint = decelerate_obstacle_waypoint; return decelerate_obstacle_waypoint &lt; 0 ? EControl::KEEP : EControl::DECELERATE; } // stop obstacle was found but decelerate obstacle was not found if (decelerate_obstacle_waypoint &lt; 0) { *obstacle_waypoint = stop_obstacle_waypoint; return EControl::STOP; } // about 5.0 meter double waypoint_interval = getPlaneDistance(lane.waypoints[0].pose.pose.position, lane.waypoints[1].pose.pose.position); int stop_decelerate_threshold = 5 / waypoint_interval; // both were found if (stop_obstacle_waypoint - decelerate_obstacle_waypoint &gt; stop_decelerate_threshold) { *obstacle_waypoint = decelerate_obstacle_waypoint; return EControl::DECELERATE; } else { *obstacle_waypoint = stop_obstacle_waypoint; return EControl::STOP; }} ​ obstacleDetection函数调用pointsDetection函数实现障碍物检测功能。 12345678910111213141516171819EControl obstacleDetection(int closest_waypoint, const autoware_msgs::Lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo vs_info, const ros::Publisher&amp; detection_range_pub, const ros::Publisher&amp; obstacle_pub, int* obstacle_waypoint){ ObstaclePoints obstacle_points; EControl detection_result = pointsDetection(vs_info.getPoints(), closest_waypoint, lane, crosswalk, vs_info, obstacle_waypoint, &amp;obstacle_points); //... // stop or decelerate because we found obstacles if (detection_result == EControl::STOP || detection_result == EControl::STOPLINE || detection_result == EControl::DECELERATE) { displayObstacle(detection_result, obstacle_points, obstacle_pub); prev_detection = detection_result; false_count = 0; prev_obstacle_waypoint = *obstacle_waypoint; return detection_result; } //...} ④ changeWaypoints函数​ 根据前方障碍物/停车线情况，更新vs_path内的update_waypoints_中的轨迹点速度 1234567891011121314151617181920212223242526272829303132void changeWaypoints(const VelocitySetInfo&amp; vs_info, const EControl&amp; detection_result, int closest_waypoint,int obstacle_waypoint, VelocitySetPath* vs_path){ double deceleration = 0.0; double velocity_change_limit = vs_info.getVelocityChangeLimit(); if (detection_result == EControl::STOP || detection_result == EControl::STOPLINE) { // 在障碍物/停止线前停车 // stop_waypoint大约距离障碍物/停车线stop_distance米远 int stop_distance = (detection_result == EControl::STOP) ? vs_info.getStopDistanceObstacle() : vs_info.getStopDistanceStopline(); deceleration = (detection_result == EControl::STOP) ? vs_info.getDecelerationObstacle() : vs_info.getDecelerationStopline(); //确定与obstacle_waypoint的距离为stop_distance相对应轨迹点下标 int stop_waypoint = calcWaypointIndexReverse(vs_path-&gt;getPrevWaypoints(), obstacle_waypoint, stop_distance); //基于上述信息更新update_waypoints_中的轨迹点速度 vs_path-&gt;changeWaypointsForStopping(stop_waypoint, obstacle_waypoint, closest_waypoint, deceleration); } else { // 在障碍物前减速 vs_path-&gt;initializeNewWaypoints(); deceleration = vs_info.getDecelerationObstacle(); if (detection_result == EControl::DECELERATE) { vs_path-&gt;changeWaypointsForDeceleration(deceleration, closest_waypoint, obstacle_waypoint); } } //避免急加速和急减速 vs_path-&gt;avoidSuddenAcceleration(deceleration, closest_waypoint); vs_path-&gt;avoidSuddenDeceleration(velocity_change_limit, deceleration, closest_waypoint);} 4.8 参考文献 [1] 李柏，张友民，邵之江. 自动驾驶车辆运动规划方法综述[J]：控制与信息技术，2018(6)：1-6. [2] 靳岚，赵莉，谢黎明．基于三次Bezier三角样条插值的工业机器人连续路径轨迹规划[J]. 机械设计与制造工程,2019,48(4)：35-39. [3] 杜卓洋，无人驾驶车辆轨迹规划算法研究[D]. 杭州：浙江大学，2019. [4] 创客智造. autoware 入门教程一使用rosbag数据生成路径点[DB/OLJ.[2020-04-11].https://www.ncnynl.com/archives/201910/3413.html. [5] 创客智造. autoware 入门教程一使用rosbag数据进行路径规划[DB/OL].[2020-04-11].https://www.ncnynl.com/archives/201910/3414.html. [6] 何武. 室内服务机器人的导航研究[D]. 合肥：中国科学技术大学,2011. [7] 邓鹏，张杭，申有吉．基于改进 Dijkstra 算法在智能导航中的应用[J]. 新型工业化，2019,9 (12) : 91-95. [8] 顾青，豆风铅，马飞. 基于改进A*算法的电动车能耗最优路径规划[J]. 农业机械学报，2013,46 (12): 321-327. [9] 徐磊. 基于 EPS 的自动泊车路径规划及跟综控制研究[D]. 合肥：合肥工业大学,2017. 五、Autoware 控制模块解析​ Autoware控制模块的主要作用为获取车辆路径规划的结果，在车辆运动学和动力学约束下计算相应的控制指令，包括速度角速度等，接着发布控制指令到车辆底盘执行。 ​ 在当前场景下主要讲解纯跟踪控制算法。 5.1 节点pure_pursuit​ 节点pure_pursuit主要作用：接收velocity_set节点发布的“final_waypoints”，计算自车下一时刻的速度、角速度指令并发布“twist_raw”话题 5.1.1 启动方法 终端启动: roslaunch pure_pursuit pure_pursuit.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方computing 选项卡 -&gt; motion_planner -&gt;waypoint_follower-&gt;pure_pursuit，单击 [app] 按钮可更改设置等参数。 5.1.2 程序路径1src/autoware/core_planning/pure_pursuit 5.1.3 参数详情 参数名 类型 说明 lookahead_ratio double 预瞄距离系数 minimum_lookahead_distance double 最小预瞄距离 5.1.4 代码注解① main函数​ main函数在pure_pursuit_node.cpp中，主要功能为创建PurePursuitNode对象的实例ppn，ppn的构造函数里配置相关参数，确定相关订阅者和发布者，ppn.run函数实现主要功能。 123456789#include &lt;pure_pursuit/pure_pursuit_core.h&gt;int main(int argc, char** argv){ ros::init(argc, argv, &quot;pure_pursuit&quot;); waypoint_follower::PurePursuitNode ppn; ppn.run(); return 0;} ② run函数​ 函数首先检测节点所需消息输入是否正常接收，If函数中的判断条件时回调函数中的是否成功接收消息的标志，在这里要求三个标志必须为true程序才能继续往下进行，否则提示必要的话题没有接收成功，并在此等待。if函数对纯跟踪节点的运行条件做了筛查，以确保输入正确。 ​ 接着通过setLookaheadDistance函数对预瞄距离lookahead_distance_进行设置，其值根据computeLookaheadDistance函数获得。 ​ 随后调用canGetCurvature函数寻找下一目标点与当前位置是否可以得到合理运动曲线并计算出相应的曲率。 ​ 最终把得到的曲率计算出相应的指令发布出去。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061void PurePursuitNode::run(){ ros::Rate loop_rate(update_rate_); while (ros::ok()) { ros::spinOnce(); //判断消息是否正常接收 if (!is_pose_set_ || !is_waypoint_set_ || !is_velocity_set_) { if (!is_pose_set_) { ROS_WARN_THROTTLE(5, &quot;Waiting for current_pose topic ...&quot;); } if (!is_waypoint_set_) { ROS_WARN_THROTTLE(5, &quot;Waiting for final_waypoints topic ...&quot;); } if (!is_velocity_set_) { ROS_WARN_THROTTLE(5, &quot;Waiting for current_velocity topic ...&quot;); } loop_rate.sleep(); continue; } //设置预瞄距离 pp_.setLookaheadDistance(computeLookaheadDistance()); pp_.setMinimumLookaheadDistance(minimum_lookahead_distance_); //寻找下一目标点并计算曲率判断是否是有效曲线 double kappa = 0; bool can_get_curvature = pp_.canGetCurvature(&amp;kappa); //发布控制命令 publishControlCommands(can_get_curvature, kappa); health_checker_ptr_-&gt;NODE_ACTIVATE(); health_checker_ptr_-&gt;CHECK_RATE(&quot;topic_rate_vehicle_cmd_slow&quot;, 8, 5, 1, &quot;topic vehicle_cmd publish rate slow.&quot;); // Rviz中可视化 pub11_.publish(displayNextWaypoint(pp_.getPoseOfNextWaypoint())); pub13_.publish(displaySearchRadius(pp_.getCurrentPose().position, pp_.getLookaheadDistance())); pub12_.publish(displayNextTarget(pp_.getPoseOfNextTarget())); pub15_.publish(displayTrajectoryCircle( waypoint_follower::generateTrajectoryCircle(pp_.getPoseOfNextTarget(), pp_.getCurrentPose()))); if (add_virtual_end_waypoints_) { pub18_.publish(displayExpandWaypoints(pp_.getCurrentWaypoints(), expand_size_)); } std_msgs::Float32 angular_gravity_msg; //计算横向加速并发布 angular_gravity_msg.data = computeAngularGravity(computeCommandVelocity(), kappa); pub16_.publish(angular_gravity_msg); //计算自车与跟踪路径曲线的横向误差 publishDeviationCurrentPosition(pp_.getCurrentPose().position, pp_.getCurrentWaypoints()); is_pose_set_ = false; is_velocity_set_ = false; loop_rate.sleep(); }} ③ computeLookaheadDistance函数​ computeLookaheadDistance函数利用车速的倍数作为预瞄距离，速度越大预瞄距离越远，速度越小预瞄准距离越近。在最小预瞄距离，参考值，最大预瞄距离中的中间值作为返回值。 12345678910111213double PurePursuitNode::computeLookaheadDistance() const{ if (velocity_source_ == enumToInteger(Mode::dialog)) { return const_lookahead_distance_; } const double maximum_lookahead_distance = current_linear_velocity_ * 10; const double ld = current_linear_velocity_ * lookahead_distance_ratio_; return ld &lt; minimum_lookahead_distance_ ? minimum_lookahead_distance_ : ld &gt; maximum_lookahead_distance ? maximum_lookahead_distance : ld;} ④ canGetCurvature函数123456789101112131415161718192021222324252627282930313233343536373839404142434445bool PurePursuit::canGetCurvature(double* output_kappa){ // 寻找下一个跟踪路径点 getNextWaypoint(); if (next_waypoint_number_ == -1) { ROS_INFO(&quot;lost next waypoint&quot;); return false; } // 遍历路径点序列中的每一个点到当前位置的距离是否大于预瞄距离从而判断曲线是否合理 bool is_valid_curve = false; for (const auto&amp; el : current_waypoints_) { if (getPlaneDistance(el.pose.pose.position, current_pose_.position) &gt; minimum_lookahead_distance_) { is_valid_curve = true; break; } } if (!is_valid_curve) { return false; } // 检查是否是第一个点、最后一个点或者不能线性插值的情况 if (!is_linear_interpolation_ || next_waypoint_number_ == 0 || next_waypoint_number_ == (static_cast&lt;int&gt;(current_waypoints_.size() - 1))) { next_target_position_ = current_waypoints_.at(next_waypoint_number_).pose.pose.position; *output_kappa = calcCurvature(next_target_position_); return true; } // 线性插值 const bool interpolation = interpolateNextTarget(next_waypoint_number_, &amp;next_target_position_); if (!interpolation) { ROS_INFO(&quot;lost target!&quot;); return false; } //计算曲率 *output_kappa = calcCurvature(next_target_position_); return true;} ⑤ calcCurvature函数 1234567891011121314151617double PurePursuit::calcCurvature(const geometry_msgs::Point&amp; target) const{ double kappa; const geometry_msgs::Point pt = calcRelativeCoordinate(target, current_pose_); const double denominator = pt.x * pt.x + pt.y * pt.y; const double numerator = 2.0 * pt.y; if (denominator != 0.0) { kappa = numerator / denominator; } else { kappa = numerator &gt; 0.0 ? KAPPA_MIN_ : -KAPPA_MIN_; } return kappa;} ⑥ publishTwistStamped函数​ publishTwistStamped函数用来发布twist_cmd话题，发布消息主要包含线速度（linear.x)和角速度（angular.z），其值分别为computeCommandVelocity函数的结果和曲率与速度的乘积。 123456789101112131415161718void PurePursuitNode::publishTwistStamped(const bool&amp; can_get_curvature, const double&amp; kappa) const{ geometry_msgs::TwistStamped ts; ts.header.stamp = ros::Time::now(); //计算速度和角速度的值 ts.twist.linear.x = can_get_curvature ? computeCommandVelocity() : 0; ts.twist.angular.z = can_get_curvature ? kappa * ts.twist.linear.x : 0; pub1_.publish(ts);}double PurePursuitNode::computeCommandVelocity() const{ if (velocity_source_ == enumToInteger(Mode::dialog)) { return getSgn() * kmph2mps(const_velocity_); } return command_linear_velocity_;} 5.2 节点twist_filter​ 节点twist_filter的主要作用：对pure_pursuit节点发布的速度进行滤波处理。 5.2.1 启动方法 终端启动: roslaunch twist_filter twist_filter.launch 从Runtime Manager启动: ​ 打开Runtime Manager，上方computing 选项卡 -&gt; motion_planner -&gt;waypoint_follower-&gt;twist_filter，单击 [app] 按钮可更改设置等参数。 5.2.2 程序路径1src/autoware/core_planning/twist_filter 5.2.3 代码注解① main函数​ main函数在twist_filter_node.cpp中,主要作用为构造TwistFilterNode对象node。 1234567int main(int argc, char** argv){ ros::init(argc, argv, &quot;twist_filter&quot;); twist_filter_node::TwistFilterNode node; ros::spin(); return 0;} ② TwistFilterNode构造函数1234567891011121314151617TwistFilterNode::TwistFilterNode() : nh_(), pnh_(&quot;~&quot;), health_checker_(nh_, pnh_){ // 设置参数 twist_filter::Configuration twist_filter_config; nh_.param(&quot;vehicle_info/wheel_base&quot;, twist_filter_config.wheel_base, 2.7); //...(下略) // 订阅者 twist_sub_ = nh_.subscribe(&quot;twist_raw&quot;, 1, &amp;TwistFilterNode::twistCmdCallback, this); //...(下略) // 发布者 twist_pub_ = nh_.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;twist_cmd&quot;, 5); ctrl_pub_ = nh_.advertise&lt;autoware_msgs::ControlCommandStamped&gt;(&quot;ctrl_cmd&quot;, 5); //...(下略)} ③ twistCmdCallback函数​ 接收的消息包含速度v和角速度Omega,根据v和Omega进行横向加速度的约束限制，接着对输出的速度和角速度进行一阶低通滤波处理并发布。 123456789101112131415161718192021222324252627282930313233343536void TwistFilterNode::twistCmdCallback(const geometry_msgs::TwistStampedConstPtr&amp; msg){ const twist_filter::Twist twist = { msg-&gt;twist.linear.x, msg-&gt;twist.angular.z }; ros::Time current_time = ros::Time::now(); static ros::Time last_callback_time = current_time; static twist_filter::Twist twist_prev = twist; double time_elapsed = (current_time - last_callback_time).toSec(); health_checker_.NODE_ACTIVATE(); checkTwist(twist, twist_prev, time_elapsed); twist_filter::Twist twist_out = twist; // 横向加速度限制 auto twist_limit_result = twist_filter_ptr_-&gt;lateralLimitTwist(twist, twist_prev, time_elapsed); if (twist_limit_result) { twist_out = twist_limit_result.get(); } //...(下略) if (enable_smoothing_) { // 平滑处理 twist_out = twist_filter_ptr_-&gt;smoothTwist(twist_out); } // 发布滤波后的twist指令 geometry_msgs::TwistStamped out_msg = *msg; out_msg.twist.linear.x = twist_out.lx; out_msg.twist.angular.z = twist_out.az; twist_pub_.publish(out_msg); //...(下略) // 记录当前指令和时间 twist_prev = twist_out; last_callback_time = current_time;} 5.3 节点listener_car_drive​ listener_car_drive节点主要作用：将Autoware发布的速度信息发送给底盘单片机，控制底盘运动。 5.3.1 启动方法 终端启动: python3 listener_car_drive.py 5.3.2 程序路径1~/car_av/listener_car_drive.py 5.3. 通信协议​ 电脑与底盘通信时，电脑上位机发送14位16进制数据。 ​ 帧头为a5 11 01，帧尾为0d 0a，第10位为控制位，01为刹车，02为前进，03为电机初始化。第11、12位为校验位，采用crc16校验。 1'a5 11 01 ' + speed_direction + speed + angle_direction + angle + '02' + check_1 + check_2 + ' 0d 0a' ① 速度方向控制​ 速度方向控制speed_direction代表线速度方向，01为前进，00为后退。共1位。 ② 速度控制​ 速度控制speed代表线速度(车速)，原始单位为m/s，此处将电脑控制端发送的速度值乘以100，便于单片机以int形式接收。共两位。 ③ 角速度方向控制​ 角速度方向控制angle_direction代表角速度方向，01为正向，00为反向。共1位。 ④角速度控制​ 角速度控制angle代表车辆角速度，原始单位为rad/s,此处将电脑控制端发送的角速度值乘以100，便于单片机以int形式接收。共两位。 通信协议demo： 1a5 11 01 01 1f ff 01 0f ff 02 check_1 check_2 0d 0a 5.3.3 代码注解① main函数​ main函数启动了三个独立的线程来接收转换过的控制命令、获取车辆速度、将速度发送给底盘单片机控制线控底盘运动。 123456789101112if __name__ == '__main__': rosrun_start = Thread(target=start_rosrun) speed_angle = Thread(target=get_value) car = Thread(target=car_control) rosrun_start.start() speed_angle.start() car.start() rosrun_start.join() speed_angle.join() car.join() ② start_rosrun函数​ start_rosrun函数相当于在终端启动了rosrun vehicle_ctl vehicle_cmd_命令来转换速度消息。 123# 启动控制命令转换节点def start_rosrun(): os.system('rosrun vehicle_ctl vehicle_cmd_') ③ get_value函数​ get_value函数初始化了ros节点，并定义了callback回调函数接收车辆速度及角速度信息。 12345678910111213141516def get_value(): global break_f time.sleep(0.5) def callback(data): global angle global speed global break_f value = data.v_cmd speed = value[0] speed = round(float(speed), 4) angle = value[1] angle = round(float(angle), 4) rospy.init_node('listener', anonymous=True, disable_signals=True) rospy.Subscriber('speed_pub', cmd, callback) rospy.spin() ④ car_control函数​ car_control函数打开名为/dev/car的串口，将速度、角速度信息发送给线控底盘单片机，控制车辆运动。 12345678910111213141516171819def car_control(): global speed global angle global break_f ser = car_drive() # 打开串口 ret = ser.open_car('/dev/car', 115200) # 判断串口是否打开，当串口成功打开，则将接收到Autoware反馈的速度信息发送给串口 if ret == 1: while True: print('速度=', speed) print('角速度=', angle) if break_f == 0: ret = ser.write_car(run(speed, angle)) if ret == 1: print('write ok') else: print('write error') time.sleep(0.033) 5.4 参考文献 [1] 龚建伟，姜岩，徐威. 无人驾驶车辆模型预测控制[M]，北京：北京理工大学出版社，2014. [2] 田大新,段续庭等. Autoware与自动驾驶技术，北京：科学出版社，2020. [3] Jarrod M S. Automatic steering methods for autonomous automobile path tracking[R]. Pittsburgh: Catnegie Mellon University, 2009. [4] 陈宁，周志峰，王永泉，等. 一种纯追踪模型改进算法. 轻工机械[J] ,2014,32(4):69-72. [5] 韩亚奇. 高速公路环境中智能车辆路径规划与跟踪[D]. 南宁：广西大学，2019. [6] ShinpeiKato.Autoware_TierIV_Academy_v1.1[DB/OLJ.[2020-04-22]]. https://github.com/CPFL/Autoware-Manuals/blob/master/en/Autoware_TierIV_Academy_v1.1.pdf.","link":"/posts/15d39967/"},{"title":"【论文阅读】清华&amp;理想汽车 DriveVLM :自动驾驶与VLM大模型的融合","text":"1、背景与方法简介清华大学交叉信息院赵行老师研究组MARS Lab与理想汽车合作，提出了一种基于大模型的高阶自动驾驶的全新方案DriveVLM。DriveVLM以视觉语言大模型为基础，并与端到端模型实现双系统，在复杂和驾驶场景中表现出色。模型在理想Mega上部署运行，是首个部署上车的自动驾驶大模型。 城市环境中自动驾驶的主要障碍是理解复杂的 Long-tail 场景，例如具有挑战性的道路条件和微妙的人类行为。DriveVLM 集成了用于场景描述、场景分析和分层规划的推理模块的独特组合。此外，认识到 VLM 在空间推理和繁重计算要求方面的局限性，提出一种混合系统 DriveVLM-Dual，可选择将 DriveVLM 与传统 3D 感知和规划模块集成，例如 3D 物体检测器、占用网络和运动规划器，使系统能够实现 3D 接地和高频规划能力。这种双系统设计类似于人脑的慢速和快速思维过程，可以有效地适应驾驶场景中不同的复杂性。 在 nuScenes 数据集和 SUP-AD 数据集上的实验证明了 DriveVLM 和 DriveVLM-Dual 在处理复杂且不可预测的驾驶条件方面的功效。最后，将 DriveVLM-Dual 部署在量产车辆上，验证其在现实自动驾驶环境中的有效性。 2、DriveVLM实现DriveVLM 的整体流程如下图所示。图像序列由视觉语言模型（VLM）处理，以执行特殊的思想链（CoT）推理，从而得出驾驶规划结果。 DriveVLM 的架构涉及视觉转换器编码器和大型语言模型 ( LLM )。视觉编码器产生图像标记；然后基于注意力的提取器将这些标记与LLM对齐。推理过程可以分为三个模块：场景描述、场景分析和分层路径规划（Hierarchical Planning）。而 DriveVLM-Dual 进一步融合了传统的3D感知和轨迹规划模块，实现空间推理能力和实时轨迹规划。 2.1、Scene Description场景描述模块用于识别驾驶环境和关键对象。 1、环境描述。 天气、路况等驾驶环境对驾驶难度的影响比较大。因此，模型首先描述驾驶环境 E ，包括几个条件： 其中，Weather 涵盖从晴天到下雪的各种条件，影响能见度和牵引力。Time 区分白天和夜间，因能见度变化而影响驾驶策略。Road ，道路类型，例如城市或高速公路，根据道路类型选择不同驾驶策略。Lane，车道条件，关注当前车道定位和可能的操作，这对于安全驾驶决策至关重要。 2、关键对象识别。 除了环境条件外，自动驾驶场景中的各种物体也会显著影响驾驶行为。 与传统的自动驾驶感知模块检测特定范围内的所有物体不同，作者受到人类驾驶过程中认知过程的启发，只专注于识别最有可能影响当前场景的关键物体。 每个关键对象，表示为 Oc ，包含两个属性：对象类别 c 及其图像上的近似边界框坐标 b⁢(x⁢1,y⁢1,x⁢2,y⁢2) 。 类别和坐标被映射到大模型模态中相应的 language 𝑡𝑜𝑘𝑒𝑛_𝑖𝑑，能够无缝集成到模块中。 此外，利用预训练的视觉编码器，DriveVLM 可以识别传统 3D 物体探测器无法识别的长尾关键物体，如道路中不明物体的碎片或动物等。 2.2、Scene Analysis在传统的自动驾驶流程中，预测模块通常专注于预测物体的未来轨迹。先进视觉语言模型的出现使作者能够对当前场景进行更全面的分析。场景级分析总结了所有关键对象以及环境描述。该摘要提供了对场景的全面了解，并输入到以下规划模块中。 关键对象分析。 DriveVLM 在三个方面表征关键对象：静态属性 Cs ，运动状态 Cm ，以及特定的行为 Cb 。 静态属性 Cs 描述物体的固有属性，例如路边广告牌或装载超标货物的卡车，这对于预防和引导潜在危险至关重要。 运动状态 Cm 描述物体在一段时间内的动态，包括位置、方向和动作——这些特征对于预测物体的未来轨迹以及与自我车辆的潜在交互至关重要。 特殊行为 Cb 指的是可能直接影响自我车辆的下一次驾驶决策的物体的特殊动作或手势。 现实中，不需要模型分析所有对象的所有三个特征。实际上，只有一个或两个特征适用于关键对象就足够了。最后，DriveVLM 根据上述特征，预测每个关键物体对自我车辆的潜在影响 I。 2.3、Hierarchical Planning上述 Scene-Level 摘要与路线、自我姿势和速度相结合，形成规划 Prompt。 最后，DriveVLM 分三个阶段逐步生成驾驶计划：Meta-Actions、决策描述和轨迹航点。 Meta-Actions A 。 Meta-Actions，表示为 ，代表驾驶策略的短期决策。这些动作分为17类，包括但不限于加速、减速、左转、变道、轻微位置调整和等待。为了计划自我车辆在特定时期内的未来机动，生成一系列Meta-Actions。 决策描述 D 。 决策描述 D 阐明了自车应采用的更细粒度的驾驶策略。它包含三个要素： 动作 𝒜 ， 主体 𝒮 、和持续时间 𝒟 。动作 𝒜 与 Meta-Actions A 有关，例如“转弯”、“等待”或“加速”。主体 𝒮 指交互对象，例如行人、交通信号灯或特定车道。持续时间 𝒟 指操作时间，指定应执行多长时间或应开始的时间。 轨迹航点 W 。 建立决策描述 D 后，下一阶段生成相应的轨迹航点。这些航点，表示为： ， 它们描绘了车辆在未来某个时间段内的路径，并有预定的时间间隔 Δ𝑡。 将这些航点数字映射为 language tokens，用于自回归生成。 2.4、DriveVLM-Dual为了缓解 VLM 中高延迟以及不精确的空间和运动理解的挑战，作者提出了 DriveVLM-Dual，这是 DriveVLM 与传统自动驾驶系统之间的合作。这种新颖的方法涉及两个关键策略：结合 3D 感知进行关键对象分析，以及高频轨迹细化。 集成 3D 感知。 用来表示三维检测器检测到的物体，其中 表示第𝑖个bbox，表示其类别。 然后将这些三维边界框反投影到二维图像上，得出相应的二维边界框。 作者在这些二维边界框和之间进行 IoU 匹配。 是先前确定的临界物体的边界框。 作者将符合某个近似 IoU 阈值并与匹配的临界对象 属于同一类别的临界对象进行分类，其定义为 在 3D 数据中没有相应匹配的关键对象被标记为 。 在场景分析模块中，对于 ，将对应3D物体的中心坐标、方向和历史轨迹作为模型的语言提示，辅助物体分析。反之，对于 ，分析仅依赖于从图像派生的语言标记。这种设计使 DriveVLM-Dual 能够更准确地了解关键物体的位置和运动，从而提高整体性能。 高频轨迹细化。 为了实现实时、高频的推理能力，将其与传统规划器集成，形成慢速双系统，将 DriveVLM 的先进功能与传统规划方法的效率相结合。 从 DriveVLM 获得低频轨迹后，表示为 ，作者将其作为经典规划器高频轨迹细化的参考轨迹。 对于基于优化的规划器， 作为优化求解器的初始解。 对于基于神经网络的规划器， 用作输入查询，与附加输入特征相结合 f ，然后解码为新的规划轨迹，表示为 。 该过程的表述可以描述为： 此细化步骤确保 DriveVLM-Dual 生成的轨迹能够实现更高的轨迹质量，并且可以满足实时要求。两个分支以慢-快的方式异步运行，其中传统自动驾驶分支中的规划器模块可以选择性地接收来自VLM分支的轨迹作为附加输入。 3、数据集为便于场景标注，研究组还开发了一个视频标注工具，能够比较方便的针对特定标注内容进行对应的标注和检查。SUP-AD数据集中某个场景关键帧的标注结果如下图所示： 在人工智能的三驾马车中，数据是生产原料，算力是基础设施，算法则是大模型的逻辑表示。为提升数据质量和DriveVLM大模型准确度，研究组提出了一个全面的数据挖掘和标注流水线，并构建了包含超40个场景类别的自动驾驶数据集SUP-AD（scene understanding for planning-autonomous driving）。下面的流程图解释了构建场景理解和规划数据集的数据挖掘和标注方法。列举了一些从数据集中随机抽取的场景示例图片，展示出了数据集的多样性和复杂性。 4、实验使用 Qwen-VL 作为默认的大型视觉语言模型，它在问答、视觉定位和文本识别等任务中表现出卓越的性能。它总共包含 9.6B 参数，包括视觉编码器（1.9B）、Vision-Language Adapter（0.08B）和大型语言模型（Qwen，7.7B）。图像大小调整为分辨率 448×448 在被视觉编码器编码之前。在训练过程中，作者随机选择当前时间的图像序列 T s, T−1 s, T−2，T−3 s 作为输入。所选图像确保包含当前时间范围并遵循升序时间顺序。 DriveVLM 的定性结果如下图所示。在下面的第一张图中，DriveVLM 可准确预测当前的场景条件，并针对接近作者的骑车人做出深思熟虑的规划决策。在第二张图中，DriveVLM有效地理解了前方交警的手势，向本车发出继续前进的信号，并且还考虑了右侧骑三轮车的人，从而做出明智的驾驶决策。这些定性结果证明了该大模型具有理解复杂场景并制定合适驾驶计划的卓越能力。图片中的橙色曲线代表模型在接下来 3 秒内计划的未来轨迹。 5、最终部署在配备两个 OrinX 处理器的理想 Mega 自动驾驶车辆上部署 DriveVLM-Dual，在 OrinX-1 上配备高频端到端驱动系统，在 OrinX-2 上配备 DriveVLM。这两个系统异步运行和协作。此外，根据 Orin 优化了 DriveVLM，在 OrinX 上实现了 410 毫秒的平均推理速度。 Base LLM：由于车辆硬件的内存和带宽有限，无法使用过大的LLMs来维持实时推理。因此，选择参数少于40亿的模型。实验表明，在Orin架构上，“宽而浅”的Qwen系列（更宽和更少的层）模型在推理速度上优于“窄和深”模型（更窄和更多的层）。 Visual Encoder：高分辨率图像对于自动驾驶中的细粒度视觉理解至关重要。与用作视觉编码器的基本ViT模型相比，作者探索了几种选择，包括不同的GridPatch策略和PE（位置嵌入）插值。最终，为了实时推理，选择了更简单的带 PE 插值的 SigLIP-L-384 模型，通过原始 384 分辨率 PE 插值和附加卷积层微调参数来实现高分辨率输入。 Vision Token Compression：为了解决高分辨率图像增加的计算负载，实现了 LDPNetv2，以在不影响性能的情况下将图像标记的数量减少 75%。此外，通过在 LDPNetv2 中用卷积层替换平均池化层来增强性能。 Video Input：在自动驾驶场景中，需要更多的时间上下文来准确评估物体运动变化。作者采用短期记忆库策略，将历史帧中的视觉特征临时存储在特征队列中。在映射到LLM之前，仅提取当前时刻的特征并将其与多个历史帧融合。除了基本的时空Pooling之外，还添加了 SE 块来执行多个时间帧的加权融合。 Speculative Sampling：推测采样通过抢先生成可能的输出来加速推理。 这种方法减少了生成预测的延迟，在不大幅降低准确性的情况下显著提高了速度。作者测试了两种推测采样方法： Medusa 和与作者专为 OrinX 芯片设计的 Eagle 推理框架。 与 Medusa 的 2.17 倍解码延迟相比，Eagle 的解码延迟速度提高了 2.7 倍，使车辆的实时部署变得可行。 部署结果： 下图中，DriveVLM 识别前方缓慢移动的车辆，并提供变道超车的驾驶决策。 下图中，DriveVLM准确识别了非常规车辆的类型和倒下的树木，展示了其识别长尾物体的能力 下图展示出DriveVLM 准确捕捉到了交警示意继续行驶的手势。","link":"/posts/a11b1e0f/"},{"title":"【踩坑笔记】Nvidia T4计算卡在Windows服务器使用docker","text":"1、背景业务上有个需求，希望在 Windows Server 2022 内通过 wsl2 部署 docker 运行类似 Ollama 的 GPU 服务。但 T4 计算卡使用通用方案直接安装官网下载的 GPU 驱动 + docker desktop 无法在 docker 内调用 GPU。 具体表现为：wsl 内nvidia-smi命令正常；nvcc -V命令正常，docker 内nvidia-smi命令异常。网上找到修改注册表可以强启WDDM模式，尝试后，docker 内能看到 GPU，但程序无法调用。 2、解决方法T4计算卡修改注册表强启WDDM时，驱动不全。需要下载专有带授权的 NVIDIA RTX 虚拟工作站（NVIDIA GRID）驱动。Windows系统538.67驱动链接 安装完成并重启服务器之后，在Windows终端测试nvidia-smi命令，显示 WDDM 即为成功（官网驱动此处显示TCC）。 12345678910111213+---------------------------------------------------------------------------------------+| NVIDIA-SMI 537.70 Driver Version: 537.70 CUDA Version: 12.2 ||-----------------------------------------+----------------------+----------------------+| GPU Name TCC/WDDM | Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. ||=========================================+======================+======================|| 0 Tesla T4 WDDM | 00000000:3D:00.0 Off | 0 || N/A 26C P0 26W / 70W | 8MiB / 15360MiB | 0% Default |+-----------------------------------------+----------------------+----------------------+| 1 Tesla T4 WDDM | 00000000:3E:00.0 Off | 0 || N/A 25C P8 9W / 70W | 0MiB / 15360MiB | 0% Default |+-----------------------------------------+----------------------+----------------------+...... 注意： 如果你的计算卡是 T4 或 L4 且 安装了 NVIDIA 510 或更高版本的驱动程序，则需要停用 GSP 固件。请参阅 Nvidia 文档中的停用 GSP 固件。 对于在 Compute Engine 上运行的 L4、T4、P4 和 P100 NVIDIA RTX 虚拟工作站 (vWS)，建议根据应用所需的 NVIDIA 虚拟 GPU 软件使用以下 NVIDIA 驱动程序版本： 对于 NVIDIA 虚拟 GPU 软件版本 17，建议使用以下最低 NVIDIA 驱动程序： 对于 Linux 虚拟机：550.90.07 对于 Windows 虚拟机：552.55 对于 NVIDIA 虚拟 GPU 软件版本 16，建议使用以下最低 NVIDIA 驱动程序： 对于 Linux 虚拟机：535.183.01 对于 Windows 虚拟机：538.67 3、后续步骤驱动安装妥当之后，正常安装docker即可。 ！！！注意： 对于4卡以上的机器，同一个容器内仅支持4张及以下GPU，需要在docker-compose时 限定可见GPU数量【必选项】。具体原因未知，猜测可能是驱动不支持？ 限定方法：环境变量中添加 - CUDA_VISIBLE_DEVICES=0,1,2,3 (docker compose启动) 或 --env CUDA_VISIBLE_DEVICES=0,1,2,3（docker run启动）","link":"/posts/11f6a109/"}],"tags":[{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"系统问题","slug":"系统问题","link":"/tags/%E7%B3%BB%E7%BB%9F%E9%97%AE%E9%A2%98/"},{"name":"激光雷达","slug":"激光雷达","link":"/tags/%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE/"},{"name":"感知算法","slug":"感知算法","link":"/tags/%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95/"},{"name":"自动驾驶","slug":"自动驾驶","link":"/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"NVIDIA","slug":"NVIDIA","link":"/tags/NVIDIA/"},{"name":"Sophon算能","slug":"Sophon算能","link":"/tags/Sophon%E7%AE%97%E8%83%BD/"},{"name":"ROS","slug":"ROS","link":"/tags/ROS/"},{"name":"摄像头","slug":"摄像头","link":"/tags/%E6%91%84%E5%83%8F%E5%A4%B4/"},{"name":"环境部署","slug":"环境部署","link":"/tags/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"},{"name":"系统安装","slug":"系统安装","link":"/tags/%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/"},{"name":"ROG","slug":"ROG","link":"/tags/ROG/"},{"name":"网络设备","slug":"网络设备","link":"/tags/%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/"},{"name":"外设","slug":"外设","link":"/tags/%E5%A4%96%E8%AE%BE/"},{"name":"存储设备","slug":"存储设备","link":"/tags/%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87/"},{"name":"LLM","slug":"LLM","link":"/tags/LLM/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Autoware","slug":"Autoware","link":"/tags/Autoware/"}],"categories":[{"name":"写点笔记","slug":"写点笔记","link":"/categories/%E5%86%99%E7%82%B9%E7%AC%94%E8%AE%B0/"},{"name":"写点教程","slug":"写点教程","link":"/categories/%E5%86%99%E7%82%B9%E6%95%99%E7%A8%8B/"},{"name":"来点干货","slug":"来点干货","link":"/categories/%E6%9D%A5%E7%82%B9%E5%B9%B2%E8%B4%A7/"},{"name":"玩物有志","slug":"玩物有志","link":"/categories/%E7%8E%A9%E7%89%A9%E6%9C%89%E5%BF%97/"}],"pages":[{"title":"个人简介","text":"Hi There！","link":"/about/index.html"}]}